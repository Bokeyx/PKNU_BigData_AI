{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine Running library install\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### 선형, 다중, 다항 회귀모델 라이브러리 정의\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### 앙상블 모델\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "### visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definition of the NumPy library\n",
    "import numpy as np\n",
    "\n",
    "### Definition of Library (Preprocessing Library)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### 평가 라이브러리 정의\n",
    "# 평균절대오차(MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# 평균제곱오차(MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 결정계수(R2-score)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# - 변환기 모델(클래스) 라이브러리 정의하기\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "### 라이브러리 정의\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "### 라이브러리 정의\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "### 하이퍼파라미터 튜닝 모델(클래스) 정의하기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "### 경고 메시지 없애기\n",
    "# - 사이킷런 버전에 따라 오류가 아니니 안내(경고)메시지가 자주 나타남\n",
    "# - 안내(경고) 메시지 없이 실행할 수 있도록 처리\n",
    "from sklearn import set_config\n",
    "set_config(display=\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<분류분석>\n",
    " - 종속변수 범주의 갯수에 따라 이진분류와 다중분류로 구분됨\n",
    " - 이진분류: 종속변수가 2개인 경우(둘 중 하나 예측하기)\n",
    " - 다중분류: 종속변수가 3개 이상인 경우(여러개 중 하나 예측하기)\n",
    "           : (일부 다중분류 라이브러리에서는 종속변수가 2개 이상인 경우도 포함됨)\n",
    " - 분류분석 모델: KNN, 로지스틱레그레이션, 결정트리, 앙상블모델들\n",
    "                : 주로 사용되는 모델 -> 앙상블 모델\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Species   159 non-null    object \n",
      " 1   Weight    159 non-null    float64\n",
      " 2   Length    159 non-null    float64\n",
      " 3   Diagonal  159 non-null    float64\n",
      " 4   Height    159 non-null    float64\n",
      " 5   Width     159 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 7.6+ KB\n",
      "None\n",
      "            Weight      Length    Diagonal      Height       Width\n",
      "count   159.000000  159.000000  159.000000  159.000000  159.000000\n",
      "mean    398.326415   28.415723   31.227044    8.970994    4.417486\n",
      "std     357.978317   10.716328   11.610246    4.286208    1.685804\n",
      "min       0.000000    8.400000    8.800000    1.728400    1.047600\n",
      "25%     120.000000   21.000000   23.150000    5.944800    3.385650\n",
      "50%     273.000000   27.300000   29.400000    7.786000    4.248500\n",
      "75%     650.000000   35.500000   39.650000   12.365900    5.584500\n",
      "max    1650.000000   63.400000   68.000000   18.957000    8.142000\n",
      "  Species  Weight  Length  Diagonal  Height   Width\n",
      "0   Bream   242.0    25.4      30.0   11.52  4.0200\n",
      "1   Bream   290.0    26.3      31.2   12.48  4.3056\n"
     ]
    }
   ],
   "source": [
    "### 생선분류 데이터셋.csv 데이터 불러들이기\n",
    "# - 변수명: fish 사용\n",
    "\n",
    "file_path = \"./data/05_생선_분류_데이터셋.csv\"\n",
    "fish = pd.read_csv(file_path)\n",
    "print(fish.info())\n",
    "print(fish.describe())\n",
    "print(fish.head(2))\n",
    "\n",
    "### 무게 데이터의 최소값(min)에 이상치로 보이는 0값이 있음\n",
    "# - 이상치 처리를 선행해야 함.\n",
    "# - 단, 분류모델을 한번 리뷰하기 위해 결측, 이상, 중복 처리가 되었다는 가정하에 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* 특성 설명\n",
    " - Species: 생선 종류\n",
    " - Weight: 생선 무게 (g)\n",
    " - Length: 생선 길이 (cm)\n",
    " - Diagonal: 생선 대각선 길이 (cm)\n",
    " - Height: 생선 높이 (cm)\n",
    " - Width: 생선 두께 (cm)\n",
    " \n",
    "* 분석 주제\n",
    " - 생선의 무게, 길이, 대각선길이, 높이, 두께 데이터를 이용하여\n",
    " - 생선의 종류 분류하기\n",
    " \n",
    "* 분석을 위한 데이터\n",
    " - 독립변수: 무게, 길이, 대각선길이, 높이, 두께\n",
    " - 종속변수: 생선 종류\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 독립변수와 종속변수로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 5)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "### 변립변수명: fish_input, 종속변수명: fish_target\n",
    "# - numpy의 array 타입으로 처리해 주세요.\n",
    "\n",
    "fish_input = fish.iloc[:, 1:].to_numpy()\n",
    "\n",
    "fish_target = fish[\"Species\"].to_numpy()\n",
    "\n",
    "print(fish_input.shape)\n",
    "print(fish_target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 : 테스트 = 7.5 : 2.5로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 5) (119,)\n",
      "(40, 5) (40,)\n"
     ]
    }
   ],
   "source": [
    "### 변수명: train_input, train_target, test_input, test_target\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, test_size=0.25, random_state=42, \n",
    "    ### 종속변수의 범주 비율을 편향을 최소화하여 비율대비 섞도록 처리\n",
    "    stratify=fish_target\n",
    ")\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard 스케일링 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 5) (119,)\n",
      "(40, 5) (40,)\n"
     ]
    }
   ],
   "source": [
    "### 독립변수명: train_scaled, test_scaled\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_input)\n",
    "\n",
    "train_scaled = scaler.transform(train_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "\n",
    "print(train_scaled.shape, train_target.shape)\n",
    "print(test_scaled.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN(최근접이웃) 분류모델로 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도0.773109243697479, 테스트 정확도: 0.7, 과적합 여부: 0.07310924369747906\n"
     ]
    }
   ],
   "source": [
    "### KNN 분류모델을 이용하여 분류하기\n",
    "# - 모델 변수명: k\n",
    "# - 이웃의 갯수: 3개 사용\n",
    "# - 과적합 여부 확인\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "kn.fit(train_scaled, train_target)\n",
    "\n",
    "train_score = kn.score(train_scaled, train_target)\n",
    "test_score = kn.score(test_scaled, test_target)\n",
    "\n",
    "print(f\"훈련 정확도{train_score}, 테스트 정확도: {test_score}, 과적합 여부: {train_score - test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### KNN 모델이 사용한 종속변수 확인하기\n",
    "# - 모델이 사용하는 종속변수 범주의 순서\n",
    "#   ['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish']\n",
    "kn.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Perch', 'Perch', 'Perch', 'Roach', 'Parkki'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 테스트 데이터 상위 5개 데이터로 예측하기\n",
    "test_pred = kn.predict(test_scaled[:5])\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Roach', 'Perch', 'Perch', 'Parkki', 'Parkki'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 실제 정답 확인하기\n",
    "test_target[:5]\n",
    "\n",
    "# - 예측: ['Perch', 'Perch', 'Perch', 'Roach', 'Parkki']\n",
    "# - 정답: ['Roach', 'Perch', 'Perch', 'Parkki', 'Parkki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.66666667, 0.        , 0.33333333,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.77777778, 0.        , 0.22222222,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.55555556, 0.        , 0.44444444,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.33333333, 0.22222222, 0.        , 0.44444444,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.44444444, 0.22222222, 0.        , 0.33333333,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### KNN 모델이 분류한 확률 확인하기\n",
    "kn.predict_proba(test_scaled[:5])\n",
    "\n",
    "# - 모델이 사용하는 종속변수 범주의 순서\n",
    "#   ['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish']\n",
    "#       0         1        2        3       4        5          6 \n",
    " \n",
    "# - 예측: ['Perch', 'Perch', 'Perch', 'Roach', 'Parkki']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 리그레이션(LogisticRegression) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<로지스틱 리그레이션 모델>\n",
    " - 이름은 회귀이지만, 분류분석에서 사용되는 모델임\n",
    " - 내부적으로 사용되는 산술식은 \"다항회귀\" 모델의 알고리즘을 사용함\n",
    " - 분류분석에서 -> 이진분류 및 다중분류에서 모두 사용됨\n",
    " - 분류모델 중 초기에 사용되었던 모델임\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진분류 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<이진분류>\n",
    " - 종속변수의 범주의 갯수는 2개만 허용됨\n",
    "\n",
    "<이진분류 데이터 구성>\n",
    " - 생선의 종류 Bream 및 Smelt 값에 대해서만 분류해보기\n",
    " - 데이터 재가공이 필요함\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 5) (36,)\n",
      "(13, 5) (13,)\n"
     ]
    }
   ],
   "source": [
    "### 현재 기준 독립변수 및 종속변수 원보: *_scaled, *_target\n",
    "\n",
    "### 훈련 독립변수명: train_scaled_bream_smelt, train_scaled_bream_smelt_target\n",
    "### 테스트 독립변수명: test_scaled_bream_smelt, test_scaled_bream_smelt_target\n",
    "\n",
    "### 종속변수를 이용하여 Bream 및 Smelt의 index 위치 확인\n",
    "train_index = (train_target == \"Bream\") | (train_target == \"Smelt\")\n",
    "test_index  = (test_target == \"Bream\")  | (test_target == \"Smelt\")\n",
    "\n",
    "### 훈련 독립 및 종속변수 추출하기\n",
    "train_scaled_bream_smelt        = train_scaled[train_index]\n",
    "train_scaled_bream_smelt_target = train_target[train_index]\n",
    "\n",
    "### 테스트 독립 및 종속변수 추출하기\n",
    "test_scaled_bream_smelt        = test_scaled[test_index]\n",
    "test_scaled_bream_smelt_target = test_target[test_index]\n",
    "\n",
    "print(train_scaled_bream_smelt.shape, train_scaled_bream_smelt_target.shape)\n",
    "print(test_scaled_bream_smelt.shape, test_scaled_bream_smelt_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 리그레이션 모델로 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " - 사용 패키지: sklearn.linear_model\n",
    " - 사용 모델  : LogisticRegression\n",
    " \n",
    " - 모델 변수명: lr\n",
    " - 과적합 여부 확인\n",
    " - 예측: 상위 5개 데이터로 예측\n",
    " - 정답과 비교해보기\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도1.0, 테스트 정확도: 1.0, 과적합 여부: 0.0\n",
      "예측결과: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
      "실제정답: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
      "[[0.97463552 0.02536448]\n",
      " [0.9953484  0.0046516 ]\n",
      " [0.99562915 0.00437085]\n",
      " [0.99870965 0.00129035]\n",
      " [0.99476359 0.00523641]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_scaled_bream_smelt, train_scaled_bream_smelt_target)\n",
    "\n",
    "train_score = lr.score(train_scaled_bream_smelt, train_scaled_bream_smelt_target)\n",
    "test_score  = lr.score(test_scaled_bream_smelt, test_scaled_bream_smelt_target)\n",
    "\n",
    "print(f\"훈련 정확도{train_score}, 테스트 정확도: {test_score}, 과적합 여부: {train_score - test_score}\")\n",
    "\n",
    "test_pred = lr.predict(test_scaled_bream_smelt[:5])\n",
    "print(f\"예측결과: {test_pred}\")\n",
    "print(f\"실제정답: {test_scaled_bream_smelt_target[:5]}\")\n",
    "\n",
    "# - 예측: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
    "# - 정답: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
    "\n",
    "print(lr.predict_proba(test_scaled_bream_smelt[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱리그레이션 모델 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<하이퍼파라미터>\n",
    " - 튜닝에 사용되는 기본적인 속성: C(규제강도), max_iter(훈련 반복횟수)\n",
    " - C(규제강도)\n",
    "  : 릿지 또는 라쏘에서 사용한 alpha의 규제강도와 동일한 개념\n",
    "  : 복잡도를 높이거나 낮추어서 과적합 해소\n",
    "  : 기본값(default): 1\n",
    "  : 값의 범위: 0 이상~\n",
    "  : C의 값이 커질수록 강도가 약해짐\n",
    "  \n",
    " - max_iter(훈련 반복횟수)\n",
    "  : 훈련을 여러번 반복하여 훈련의 정확도를 높임\n",
    "  : 기본값(default): 100\n",
    "  : 값의 범위: 1 이상~\n",
    "  \n",
    " ***** 하이퍼파라미터 튜닝 이후 좋아질수도 or 그렇지 않을수도 있습니다.\n",
    "       !!! 꼭~ 좋아진다는 편견 위험\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도0.9722222222222222, 테스트 정확도: 0.9230769230769231, 과적합 여부: 0.04914529914529908\n",
      "예측결과: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
      "실제정답: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
      "[[0.77774007 0.22225993]\n",
      " [0.83290025 0.16709975]\n",
      " [0.83488237 0.16511763]\n",
      " [0.86743928 0.13256072]\n",
      " [0.82962258 0.17037742]]\n"
     ]
    }
   ],
   "source": [
    "### 규제강도는 0.5로, 훈련 반복횟수는 100번\n",
    "# 과적합여부 확인까지 수행해주세요\n",
    "lr = LogisticRegression(C=0.014, max_iter=100)\n",
    "\n",
    "lr.fit(train_scaled_bream_smelt, train_scaled_bream_smelt_target)\n",
    "\n",
    "train_score = lr.score(train_scaled_bream_smelt, train_scaled_bream_smelt_target)\n",
    "test_score  = lr.score(test_scaled_bream_smelt, test_scaled_bream_smelt_target)\n",
    "\n",
    "print(f\"훈련 정확도{train_score}, 테스트 정확도: {test_score}, 과적합 여부: {train_score - test_score}\")\n",
    "\n",
    "test_pred = lr.predict(test_scaled_bream_smelt[:5])\n",
    "print(f\"예측결과: {test_pred}\")\n",
    "print(f\"실제정답: {test_scaled_bream_smelt_target[:5]}\")\n",
    "\n",
    "# - 예측: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
    "# - 정답: ['Bream' 'Bream' 'Bream' 'Bream' 'Bream']\n",
    "\n",
    "print(lr.predict_proba(test_scaled_bream_smelt[:5]))\n",
    "\n",
    "###(해석)\n",
    "# - 이진분류 수행시 규제강도는 0.014, 훈련 반복횟수는 100회 일 때\n",
    "# - 일반화가 되었으며, 훈련 정확도 0.97 매우 높은 성능을 발휘하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 종속변수의 범주 7개 모두 포함된 데이터 사용\n",
    "# - train_scaled, test_scaled, train_target, test_target\n",
    "# - 1. 하이퍼파라미터 튜닝 없이 과적합 여부 확인\n",
    "# - 2. 하이퍼파라미터 튜닝 이후 과적합 여부 확인\n",
    "#    -> 하이퍼파라미터 훈련횟수는 100번, 규제강도는 찾아주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도0.8151260504201681, 테스트 정확도: 0.825, 과적합 여부: -0.009873949579831898\n",
      "예측결과: ['Perch' 'Perch' 'Perch' 'Parkki' 'Parkki']\n",
      "실제정답: ['Roach' 'Perch' 'Perch' 'Parkki' 'Parkki']\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "train_score = lr.score(train_scaled, train_target)\n",
    "test_score  = lr.score(test_scaled, test_target)\n",
    "\n",
    "print(f\"훈련 정확도{train_score}, 테스트 정확도: {test_score}, 과적합 여부: {train_score - test_score}\")\n",
    "\n",
    "test_pred = lr.predict(test_scaled[:5])\n",
    "print(f\"예측결과: {test_pred}\")\n",
    "print(f\"실제정답: {test_target[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도0.9915966386554622, 테스트 정확도: 0.975, 과적합 여부: 0.016596638655462237\n",
      "예측결과: ['Roach' 'Perch' 'Perch' 'Parkki' 'Parkki']\n",
      "실제정답: ['Roach' 'Perch' 'Perch' 'Parkki' 'Parkki']\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1000, max_iter=150)\n",
    "\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "train_score = lr.score(train_scaled, train_target)\n",
    "test_score  = lr.score(test_scaled, test_target)\n",
    "\n",
    "print(f\"훈련 정확도{train_score}, 테스트 정확도: {test_score}, 과적합 여부: {train_score - test_score}\")\n",
    "\n",
    "test_pred = lr.predict(test_scaled[:5])\n",
    "print(f\"예측결과: {test_pred}\")\n",
    "print(f\"실제정답: {test_target[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_202503_kernel",
   "language": "python",
   "name": "pk_dl_202503"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
