"""
<오차행렬(혼동행렬)>
 - 어떠한 유형의 오류가 발생하고 있는지를 나타내는 값
 - 이를 시각화한 것을 오차행렬도(혼동행렬도)라고 칭합니다.
 - 정확도(score)의 값과 오차행렬도의 시각화 결과로 모델을 최종 선정하게 됩니다.
 
<해석 방법>
 - 긍정(Positive)적 오류인지, 부정(Negative)적 오류인지로 해석됩니다.
   (긍정은 1, 부정은 0 입니다.)
   
 - 오류의 종류 : 긍정적(Positive) 오류, 부정적(Negative) 오류로 구분합니다.
 
<오류 해석>
 * 긍정적(Positive) 오류
  - *** 0(부정)을 1(긍정)로 예측한 경우 ***
  - 예측 결과가 맞지는 않음(False)
  - 위험하지 않은 오류라고도 표현합니다.
  - 이론에서는 "FP(False Positive)"라고 칭합니다.
  
 * 부정적(Negative) 오류
  - *** 1(긍정)을 0(부정)으로 예측한 경우 ***
  - 예측 결과가 맞지는 않음(False)
  - 위험한 오류라고도 표현 합니다.
  - 이론에서는 "FN(False Negative)"라고 칭합니다.
  - 정확도가 높더라도, FN의 값이 큰 경우에는 재현율 값이 낮아지기에,
    예측 모델로 사용하는데 신중해야 합니다.(보통 제외)
    
<예측이 잘된 경우>
 * TP(True Positive)
   - 1(긍정)을 1(긍정)로 잘(True) 예측한 경우
   
 * TN(True Negative)
   - 0(부정)을 0(부정)으로 잘(True) 예측한 경우
"""

--------------------------------------------------------------

"""
<평가에 사용되는 값>
 - 정확도, 정밀도, 재현율, f1-score
 
 * 정확도(Accuracy)
  - 분류 모델에서 score의 값과 동일함
  - 사용패키지 : sklearn.metrics
  - 사용라이브러리 : accuracy_score
  - 예측결과가 실제값을 얼마나 정확하게 예측했는지를 나타낸 값
  - Accuracy = (TP + TN) / (TP + TN + FP + FN)
  
 * 정밀도(Precision)
  - 1(긍정)로 예측한 데이터 중에 실제 1(긍정)로 잘 예측한 값
  - Precision = TP / (TP + FP)
  - 긍정적오류(FP)가 높을 수록 정밀도는 낮아집니다.
  - 사용패키지 : sklearn.metrics
  - 사용라이브러리 : precision_score
  
 * 재현율(Recall)
  - 실제 1(긍정)을 1(긍정)로 잘 예측한 값
  - Recall = TP / (TP + FN)
  - 부정적오류(FN)가 높을 수록 재현율은 낮아집니다.
  - 사용패키지 : sklearn.metrics
  - 사용라이브러리 : recall_score
  
 * f1-score
  - 정밀도와 재현율을 조합하여 하나의 통계치로  반환한 값
  - f1-score = (정밀도 * 재현율) / (정밀도 + 재현율)
  - 사용패키지 : sklearn.metrics
  - 사용라이브러리 : f1_score
  
<최종 모델 선정 방법>
 - 과소 및 과대 적합이 일어나지 않아야 함
 - 재현율과 f1-score가 모두 높으면 우수한 모델로 평가할 수 있음
 - 재현율이 현저히 낮은 경우에는 모델 선정 시 고민 필요
 - 일반화되고, 정확도 높고, 재현율 높고, f1-score가 높은 모델을 선정
   (여러가지 종합적으로 고려하여 판단해야 함)
"""