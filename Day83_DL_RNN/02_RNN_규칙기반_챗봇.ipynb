{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72121c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Dropout, SimpleRNN, Embedding, LSTM, GRU, RepeatVector, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "### 텍스트 길이 정규화 라이브러리\n",
    "# - 텍스트의 길이가 긴 경우에는 자르고, 길이가 짧은 경우에는 채움\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "### 말뭉치 사전 처리를 위한 라이브러리\n",
    "# - 텍스트 데이터를 수자(인덱스번호)로 변환하는 라이브러리\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56a88652",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 질문\n",
    "questions = [\n",
    "    \"전기요금 어때?\",\n",
    "    \"전기요금 알려줘\",\n",
    "    \"안녕하세요\",\n",
    "    \"안녕\",\n",
    "    \"너 이름이 뭐니?\",\n",
    "    \"이름이 뭐야\",\n",
    "    \"어떻게 지내세요?\",\n",
    "    \"프랑스의 수도는 어디인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 무엇인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"전기요금 어때?\",\n",
    "    \"안녕하세요\",\n",
    "    \"너 이름이 뭐니?\",\n",
    "    \"어떻게 지내세요?\",\n",
    "    \"프랑스의 수도는 어디인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 무엇인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\"\n",
    "]\n",
    "\n",
    "### 답변\n",
    "answers = [\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"저는 잘 지내고 있어요, 감사합니다!\",\n",
    "    \"프랑스의 수도는 파리에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"저는 잘 지내고 있어요, 감사합니다!\",\n",
    "    \"프랑스의 수도는 파리에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cb6ecf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 52)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 질문/답변 갯수 확인하기\n",
    "len(questions), len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9a4e6",
   "metadata": {},
   "source": [
    "### 단어사전(말뭉치) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d9f8549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<말뭉치 사전>\\n - 데이터셋에 있는 모든 문장(질문+답변) 내에 단어들을 추출하여\\n - 빈도가 가장 높은 단어 순으로 번호(인덱스)를 부여하여 관리함\\n - 고유한 단어들만으로 구성된 사정을 의미합니다\\n - 문장에서 단어를 추출하여 번호를 부여하는 것을 --> 토큰화(tokenizer) 하고 칭합니다.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<말뭉치 사전>\n",
    " - 데이터셋에 있는 모든 문장(질문+답변) 내에 단어들을 추출하여\n",
    " - 빈도가 가장 높은 단어 순으로 번호(인덱스)를 부여하여 관리함\n",
    " - 고유한 단어들만으로 구성된 사정을 의미합니다\n",
    " - 문장에서 단어를 추출하여 번호를 부여하는 것을 --> 토큰화(tokenizer) 하고 칭합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa683a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x152a7d2a670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 텍스트 문장 데이터를 토큰화 (단어로 분리하여 숫자 인덱스화)를 위한 클래스 생성\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ad75114",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 토큰화 함수 : fit_on_texts\n",
    "# - 텍스트에서 단어 추출 및 인덱스화\n",
    "# - 질문 및 답변의 모든 문장 내에 단어들을 인덱스화 해야합니다.\n",
    "#  -> 질문과 답변의 각각의 리스트를 더하기 연산하여 하나의 리스트로 사용\n",
    "# - 문장내 단어들을 모두 추출하여 빈도가 가장 높은 순서대로 1부터 인덱스 번호가 부여됩니다.\n",
    "# - 문장내 단어의 분리는 -> 띄워쓰기 기준으로 분리함\n",
    "tokenizer.fit_on_texts(questions+answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd6e8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 전체 분리된 단어들의 갯수 확인하기\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1db96b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가장': 1,\n",
       " '좋아하는': 2,\n",
       " '무엇인가요': 3,\n",
       " '있어요': 4,\n",
       " '음식은': 5,\n",
       " '일을': 6,\n",
       " '좋아해요': 7,\n",
       " '색깔은': 8,\n",
       " '기억에': 9,\n",
       " '남는': 10,\n",
       " '여행은': 11,\n",
       " '주말에는': 12,\n",
       " '동물은': 13,\n",
       " '제가': 14,\n",
       " '어때': 15,\n",
       " '감명': 16,\n",
       " '깊게': 17,\n",
       " '본': 18,\n",
       " '영화는': 19,\n",
       " '저는': 20,\n",
       " '안녕하세요': 21,\n",
       " '프랑스의': 22,\n",
       " '수도는': 23,\n",
       " '뭐': 24,\n",
       " '해': 25,\n",
       " '오늘': 26,\n",
       " '날씨': 27,\n",
       " '뭐에요': 28,\n",
       " '무슨': 29,\n",
       " '어디에요': 30,\n",
       " '뭐하고': 31,\n",
       " '시간을': 32,\n",
       " '보내나요': 33,\n",
       " '음악': 34,\n",
       " '장르가': 35,\n",
       " '있나요': 36,\n",
       " \"'인셉션'이에요\": 37,\n",
       " '일하고': 38,\n",
       " '오늘은': 39,\n",
       " '맑아요': 40,\n",
       " '피자에요': 41,\n",
       " '하는': 42,\n",
       " '것을': 43,\n",
       " '파란색이에요': 44,\n",
       " '파리에': 45,\n",
       " '다녀온': 46,\n",
       " '것이에요': 47,\n",
       " '쉬면서': 48,\n",
       " '책을': 49,\n",
       " '읽거나': 50,\n",
       " '친구들과': 51,\n",
       " '만나요': 52,\n",
       " '다양한': 53,\n",
       " '음악을': 54,\n",
       " '즐겨듣습니다': 55,\n",
       " '강아지에요': 56,\n",
       " '전기요금': 57,\n",
       " '이름이': 58,\n",
       " '전기요금이': 59,\n",
       " '계속': 60,\n",
       " '인상되고': 61,\n",
       " '반가워요': 62,\n",
       " '제': 63,\n",
       " '이름은': 64,\n",
       " '챗봇이에요': 65,\n",
       " '너': 66,\n",
       " '뭐니': 67,\n",
       " '어떻게': 68,\n",
       " '지내세요': 69,\n",
       " '어디인가요': 70,\n",
       " '잘': 71,\n",
       " '지내고': 72,\n",
       " '감사합니다': 73,\n",
       " '파리에요': 74,\n",
       " '알려줘': 75,\n",
       " '안녕': 76,\n",
       " '뭐야': 77}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 단어들의 순서 확인하기\n",
    "# - 딕셔너리 타입으로 정의되어 있습니다. (사전의 의미임)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c31dd",
   "metadata": {},
   "source": [
    "### 훈련 시 사용할 말뭉치 갯수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1b418e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 말뭉치에 포함되지 않은 단어의 경우를 처리하기 위하여\n",
    "# - 토큰화한 결과의 갯수에 1을 더하여 사용합니다.\n",
    "\n",
    "### 훈련시 사용할 말뭉치 갯수\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ade2e",
   "metadata": {},
   "source": [
    "### 데이터셋의 텍스트를 말뭉치의 인덱스번호와 매핑하여 숫자화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55ad4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "### 텍스트를 말뭉치의 인덱스번호로 숫자화하는 함수\n",
    "# - texts_to_sequences(텍스트데이터) 사용\n",
    "\n",
    "### 질문 데이터를 인덱스화 하기\n",
    "questions_sequences = tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "print(len(questions_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb027f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[57, 15],\n",
       " [57, 75],\n",
       " [21],\n",
       " [76],\n",
       " [66, 58, 67],\n",
       " [58, 77],\n",
       " [68, 69],\n",
       " [22, 23, 70],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 3],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [57, 15],\n",
       " [21],\n",
       " [66, 58, 67],\n",
       " [68, 69],\n",
       " [22, 23, 70],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 3],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 37]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 인덱스화된 질문데이터\n",
    "# - 2차원 데이터 입니다.\n",
    "questions_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10857d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "1\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "### 질문에 대한 최대값, 최소값, 중앙값 확인하기\n",
    "# 52개 각각의 문장 내에 단어 갯수 확인하기\n",
    "question_lengths = np.array([len(i) for i in questions_sequences])\n",
    "\n",
    "print(np.max(question_lengths))\n",
    "print(np.min(question_lengths))\n",
    "print(np.median(question_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2401a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "answers_sequences = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "print(len(questions_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "327383a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "2\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "answer_lengths = np.array([len(i) for i in answers_sequences])\n",
    "\n",
    "print(np.max(answer_lengths))\n",
    "print(np.min(answer_lengths))\n",
    "print(np.median(answer_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6aec0",
   "metadata": {},
   "source": [
    "### 질문 및 답변 데이터 각각에 대해 데이터 스케일링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9977ca0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 15,  0,  0,  0,  0],\n",
       "       [57, 75,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0,  0],\n",
       "       [76,  0,  0,  0,  0,  0],\n",
       "       [66, 58, 67,  0,  0,  0],\n",
       "       [58, 77,  0,  0,  0,  0],\n",
       "       [68, 69,  0,  0,  0,  0],\n",
       "       [22, 23, 70,  0,  0,  0],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19,  3],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [57, 15,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0,  0],\n",
       "       [66, 58, 67,  0,  0,  0],\n",
       "       [68, 69,  0,  0,  0,  0],\n",
       "       [22, 23, 70,  0,  0,  0],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19,  3],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 질문 데이터 데이터 스케일링 하기(최대 길이로 스케일링)\n",
    "# - c최대 단어 길이로 스케일링하기에, 자르는 값 없음, 채우는 값만 존재함\n",
    "# - maxlen 속성은 6, maxlen을 생략하면 -> 전체 데이터의 길이중 최대값을 사용하게됨\n",
    "questions_padded = pad_sequences(questions_sequences, padding=\"post\")\n",
    "questions_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68876821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 60, 61,  4,  0,  0,  0],\n",
       "       [59, 60, 61,  4,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [20, 71, 72,  4, 73,  0,  0],\n",
       "       [22, 23, 74,  0,  0,  0,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [59, 60, 61,  4,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [20, 71, 72,  4, 73,  0,  0],\n",
       "       [22, 23, 74,  0,  0,  0,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 답변 데이터 데이터 스케일링 하기(최대 길이로 스케일링)\n",
    "answers_padded = pad_sequences(answers_sequences, padding=\"post\")\n",
    "answers_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05233ba4",
   "metadata": {},
   "source": [
    "### 훈련 : 테스트 = 8 : 2로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f3f3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 6) (41, 7)\n",
      "(11, 6) (11, 7)\n"
     ]
    }
   ],
   "source": [
    "# - 독립변수 = 질문 데이터\n",
    "# - 종속변수 = 답변 데이터\n",
    "# 변수명 : questions_train, answers_train, questions_val, answers_val\n",
    "questions_train, questions_val, answers_train, answers_val = train_test_split(\n",
    "    questions_padded, answers_padded,test_size=0.2, random_state=42)\n",
    "\n",
    "print(questions_train.shape, answers_train.shape)\n",
    "print(questions_val.shape, answers_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854ef63",
   "metadata": {},
   "source": [
    "### 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad326031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<계층 구조 - SimpleRNN먼저 사용>\\n - 입력계층 : 임베딩계층 사용\\n - 은닉계층 : SimpleRNN 사용()\\n - 은닉계층 : 답변 차원으로 변형하는 계층(RepeatVector 계층)\\n - 은닉계층 : 질문에 대한 답변과 일치성 계층(SimpleRNN)\\n - 출력계층 : 질문에 대한 답변에 대한 단어를 조합하는 계층 + 출력계층\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<계층 구조 - SimpleRNN먼저 사용>\n",
    " - 입력계층 : 임베딩계층 사용\n",
    " - 은닉계층 : SimpleRNN 사용()\n",
    " - 은닉계층 : 답변 차원으로 변형하는 계층(RepeatVector 계층)\n",
    " - 은닉계층 : 질문에 대한 답변과 일치성 계층(SimpleRNN)\n",
    " - 출력계층 : 질문에 대한 답변에 대한 단어를 조합하는 계층 + 출력계층\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e01e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               24704     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 7, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 7, 128)            32896     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 7, 78)            10062     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,654\n",
      "Trainable params: 72,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3592 - accuracy: 0.0000e+00 - val_loss: 4.2943 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.2933 - accuracy: 0.4216 - val_loss: 4.1219 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.1029 - accuracy: 0.4181 - val_loss: 3.5228 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.4410 - accuracy: 0.4181 - val_loss: 3.1182 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.9595 - accuracy: 0.4181 - val_loss: 3.2260 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0931 - accuracy: 0.4181 - val_loss: 2.7962 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.6391 - accuracy: 0.4181 - val_loss: 2.7767 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.5790 - accuracy: 0.4181 - val_loss: 2.7332 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5239 - accuracy: 0.4181 - val_loss: 2.7268 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.4788 - accuracy: 0.4181 - val_loss: 2.6820 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4338 - accuracy: 0.4181 - val_loss: 2.7059 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4019 - accuracy: 0.4181 - val_loss: 2.6604 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3795 - accuracy: 0.4181 - val_loss: 2.7066 - val_accuracy: 0.4156\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3490 - accuracy: 0.4425 - val_loss: 2.5830 - val_accuracy: 0.4156\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2643 - accuracy: 0.4425 - val_loss: 2.6155 - val_accuracy: 0.4156\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1955 - accuracy: 0.4460 - val_loss: 2.4997 - val_accuracy: 0.4156\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1203 - accuracy: 0.4634 - val_loss: 2.5486 - val_accuracy: 0.4156\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.0632 - accuracy: 0.4948 - val_loss: 2.4284 - val_accuracy: 0.4156\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0094 - accuracy: 0.4634 - val_loss: 2.5563 - val_accuracy: 0.2987\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9928 - accuracy: 0.4495 - val_loss: 2.3701 - val_accuracy: 0.4156\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.9736 - accuracy: 0.4634 - val_loss: 2.5677 - val_accuracy: 0.2987\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9625 - accuracy: 0.4634 - val_loss: 2.3023 - val_accuracy: 0.4156\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8281 - accuracy: 0.4634 - val_loss: 2.3765 - val_accuracy: 0.2987\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7556 - accuracy: 0.4669 - val_loss: 2.1546 - val_accuracy: 0.4156\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6633 - accuracy: 0.4669 - val_loss: 2.3222 - val_accuracy: 0.2987\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6639 - accuracy: 0.4913 - val_loss: 2.0921 - val_accuracy: 0.4545\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7608 - accuracy: 0.4983 - val_loss: 2.3898 - val_accuracy: 0.3766\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7595 - accuracy: 0.5017 - val_loss: 2.0383 - val_accuracy: 0.4416\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5903 - accuracy: 0.4843 - val_loss: 2.0439 - val_accuracy: 0.3896\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4905 - accuracy: 0.5575 - val_loss: 1.8241 - val_accuracy: 0.5065\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4095 - accuracy: 0.5366 - val_loss: 2.1180 - val_accuracy: 0.3636\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.4786 - accuracy: 0.5714 - val_loss: 1.7686 - val_accuracy: 0.4935\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.5364 - accuracy: 0.5470 - val_loss: 2.0441 - val_accuracy: 0.4805\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4856 - accuracy: 0.6341 - val_loss: 1.7085 - val_accuracy: 0.5455\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2870 - accuracy: 0.5993 - val_loss: 1.6244 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2071 - accuracy: 0.6585 - val_loss: 1.5912 - val_accuracy: 0.5325\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2300 - accuracy: 0.6167 - val_loss: 1.7554 - val_accuracy: 0.4935\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3649 - accuracy: 0.5540 - val_loss: 1.6491 - val_accuracy: 0.5065\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4641 - accuracy: 0.5784 - val_loss: 1.6794 - val_accuracy: 0.5065\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2432 - accuracy: 0.6167 - val_loss: 1.3626 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0087 - accuracy: 0.7387 - val_loss: 1.2017 - val_accuracy: 0.7013\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9035 - accuracy: 0.7456 - val_loss: 1.1573 - val_accuracy: 0.6753\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8266 - accuracy: 0.7805 - val_loss: 0.9823 - val_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8065 - accuracy: 0.7387 - val_loss: 1.3456 - val_accuracy: 0.5974\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9020 - accuracy: 0.7247 - val_loss: 1.0249 - val_accuracy: 0.6753\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8339 - accuracy: 0.7178 - val_loss: 1.1779 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8746 - accuracy: 0.7387 - val_loss: 1.2595 - val_accuracy: 0.6494\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8913 - accuracy: 0.7213 - val_loss: 0.9997 - val_accuracy: 0.7403\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8737 - accuracy: 0.7352 - val_loss: 0.9717 - val_accuracy: 0.7792\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6885 - accuracy: 0.8153 - val_loss: 0.7807 - val_accuracy: 0.7792\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5924 - accuracy: 0.8258 - val_loss: 0.7645 - val_accuracy: 0.8052\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5220 - accuracy: 0.8780 - val_loss: 0.6697 - val_accuracy: 0.7792\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4967 - accuracy: 0.8049 - val_loss: 0.6945 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4948 - accuracy: 0.8990 - val_loss: 0.7206 - val_accuracy: 0.8052\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5198 - accuracy: 0.8293 - val_loss: 0.6959 - val_accuracy: 0.7532\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4618 - accuracy: 0.8711 - val_loss: 0.8651 - val_accuracy: 0.8052\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5433 - accuracy: 0.8571 - val_loss: 0.6579 - val_accuracy: 0.8052\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3941 - accuracy: 0.9024 - val_loss: 0.6268 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3536 - accuracy: 0.9024 - val_loss: 0.5666 - val_accuracy: 0.8831\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3177 - accuracy: 0.9338 - val_loss: 0.6617 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3619 - accuracy: 0.9164 - val_loss: 0.6417 - val_accuracy: 0.8052\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3705 - accuracy: 0.8780 - val_loss: 0.8647 - val_accuracy: 0.7662\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5415 - accuracy: 0.8432 - val_loss: 0.7261 - val_accuracy: 0.7662\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4235 - accuracy: 0.8328 - val_loss: 0.5538 - val_accuracy: 0.8312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3770 - accuracy: 0.8780 - val_loss: 0.6900 - val_accuracy: 0.8442\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4136 - accuracy: 0.8920 - val_loss: 0.5670 - val_accuracy: 0.8831\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4225 - accuracy: 0.9059 - val_loss: 0.6223 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2558 - accuracy: 0.9617 - val_loss: 0.4627 - val_accuracy: 0.9351\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1909 - accuracy: 0.9686 - val_loss: 0.4668 - val_accuracy: 0.9091\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1617 - accuracy: 0.9756 - val_loss: 0.4467 - val_accuracy: 0.9091\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1454 - accuracy: 0.9756 - val_loss: 0.4608 - val_accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1367 - accuracy: 0.9756 - val_loss: 0.4447 - val_accuracy: 0.8831\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1441 - accuracy: 0.9582 - val_loss: 0.5487 - val_accuracy: 0.8831\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1957 - accuracy: 0.9373 - val_loss: 0.7068 - val_accuracy: 0.8052\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3717 - accuracy: 0.8885 - val_loss: 0.7333 - val_accuracy: 0.8052\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2762 - accuracy: 0.9059 - val_loss: 0.6762 - val_accuracy: 0.8831\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2783 - accuracy: 0.9373 - val_loss: 0.5111 - val_accuracy: 0.8831\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1344 - accuracy: 0.9791 - val_loss: 0.4565 - val_accuracy: 0.9351\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9351\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9351\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9351\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9221\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9351\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9351\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9221\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0572 - accuracy: 0.9895 - val_loss: 0.5567 - val_accuracy: 0.9091\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0924 - accuracy: 0.9791 - val_loss: 0.4767 - val_accuracy: 0.8961\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0746 - accuracy: 0.9791 - val_loss: 0.5596 - val_accuracy: 0.8961\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0879 - accuracy: 0.9721 - val_loss: 0.4530 - val_accuracy: 0.9221\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.5002 - val_accuracy: 0.9351\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0450 - accuracy: 0.9930 - val_loss: 0.4254 - val_accuracy: 0.9351\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9351\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9351\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9351\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9351\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9351\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9351\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9351\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9351\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9351\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : SimpleRNN, 출력:128, 활성화함수:relu\n",
    "    # - 질문을 담당하는 계층\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"relu\"\n",
    "    ),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.keras\n",
    "mc = ModelCheckpoint(\n",
    "    \"./model/best_RNN_chatbot.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_train,\n",
    "    answers_train,\n",
    "    validation_data=(questions_val,\n",
    "                     answers_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11f8878c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<시퀀스 기반의 훈련 성능의 좋음 정도>\\n - 질문/답변과 같은 시퀀스 기반의 훈련의 경우에는 일반적으로\\n  -> loss < 2 이면 학습이 어느정도 잘된 것으로 판다\\n  -> loss < 1 이면 매우 잘된 것으로 판단\\n  -> 정확도 고려하여 판단해야함\\n  \\n - 시퀀스 기반의 훈련은 데이터량이 성능에 큰 영향을 미침\\n - 시퀀스 기반의 훈련에서는 tanh 활성화 함수가 성능이 좋게 나오는 경우가 많음\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<시퀀스 기반의 훈련 성능의 좋음 정도>\n",
    " - 질문/답변과 같은 시퀀스 기반의 훈련의 경우에는 일반적으로\n",
    "  -> loss < 2 이면 학습이 어느정도 잘된 것으로 판다\n",
    "  -> loss < 1 이면 매우 잘된 것으로 판단\n",
    "  -> 정확도 고려하여 판단해야함\n",
    "  \n",
    " - 시퀀스 기반의 훈련은 데이터량이 성능에 큰 영향을 미침\n",
    " - 시퀀스 기반의 훈련에서는 tanh 활성화 함수가 성능이 좋게 나오는 경우가 많음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f96b73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4254 - accuracy: 0.9351\n",
      "훈련 데이터 | 손실율 : 0.03131641820073128, 정확도 : 1.0\n",
      "검증 데이터 | 손실율 : 0.4254414439201355, 정확도 : 0.9350649118423462\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc51b517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               98816     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 7, 128)            131584    \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,454\n",
      "Trainable params: 245,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3560 - accuracy: 0.0105 - val_loss: 4.3430 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.3401 - accuracy: 0.4181 - val_loss: 4.3242 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.3177 - accuracy: 0.4181 - val_loss: 4.2926 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.2800 - accuracy: 0.4181 - val_loss: 4.2306 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.2062 - accuracy: 0.4181 - val_loss: 4.0861 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.0339 - accuracy: 0.4181 - val_loss: 3.6561 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.5165 - accuracy: 0.4181 - val_loss: 2.9274 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.6967 - accuracy: 0.4181 - val_loss: 2.8986 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.6576 - accuracy: 0.4181 - val_loss: 2.8682 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6877 - accuracy: 0.4181 - val_loss: 3.0606 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.8127 - accuracy: 0.4181 - val_loss: 2.7948 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6099 - accuracy: 0.4181 - val_loss: 2.8545 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5927 - accuracy: 0.4181 - val_loss: 2.7587 - val_accuracy: 0.4026\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5432 - accuracy: 0.4181 - val_loss: 2.7879 - val_accuracy: 0.4026\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.5257 - accuracy: 0.4181 - val_loss: 2.7397 - val_accuracy: 0.4026\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.5044 - accuracy: 0.4181 - val_loss: 2.7611 - val_accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4904 - accuracy: 0.4181 - val_loss: 2.7241 - val_accuracy: 0.4026\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.4747 - accuracy: 0.4181 - val_loss: 2.7503 - val_accuracy: 0.4026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4652 - accuracy: 0.4181 - val_loss: 2.7122 - val_accuracy: 0.4026\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.4543 - accuracy: 0.4181 - val_loss: 2.7613 - val_accuracy: 0.4026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4592 - accuracy: 0.4181 - val_loss: 2.7100 - val_accuracy: 0.4026\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.4545 - accuracy: 0.4181 - val_loss: 2.7980 - val_accuracy: 0.4026\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.4864 - accuracy: 0.4181 - val_loss: 2.7009 - val_accuracy: 0.4026\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4431 - accuracy: 0.4181 - val_loss: 2.7770 - val_accuracy: 0.4026\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.4557 - accuracy: 0.4181 - val_loss: 2.6826 - val_accuracy: 0.4026\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4014 - accuracy: 0.4181 - val_loss: 2.7324 - val_accuracy: 0.4026\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3979 - accuracy: 0.4181 - val_loss: 2.6742 - val_accuracy: 0.4026\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3718 - accuracy: 0.4181 - val_loss: 2.7205 - val_accuracy: 0.4026\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3719 - accuracy: 0.4181 - val_loss: 2.6708 - val_accuracy: 0.4026\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.3582 - accuracy: 0.4181 - val_loss: 2.7324 - val_accuracy: 0.4026\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.3733 - accuracy: 0.4181 - val_loss: 2.6689 - val_accuracy: 0.4026\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3608 - accuracy: 0.4181 - val_loss: 2.7504 - val_accuracy: 0.4026\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3893 - accuracy: 0.4181 - val_loss: 2.6559 - val_accuracy: 0.4026\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3429 - accuracy: 0.4181 - val_loss: 2.7238 - val_accuracy: 0.4026\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3529 - accuracy: 0.4181 - val_loss: 2.6422 - val_accuracy: 0.4026\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3096 - accuracy: 0.4181 - val_loss: 2.6989 - val_accuracy: 0.4026\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3135 - accuracy: 0.4181 - val_loss: 2.6354 - val_accuracy: 0.4026\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2926 - accuracy: 0.4181 - val_loss: 2.7042 - val_accuracy: 0.4156\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3101 - accuracy: 0.4286 - val_loss: 2.6296 - val_accuracy: 0.4026\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2940 - accuracy: 0.4181 - val_loss: 2.7205 - val_accuracy: 0.4156\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3280 - accuracy: 0.4286 - val_loss: 2.6151 - val_accuracy: 0.4026\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2772 - accuracy: 0.4181 - val_loss: 2.6948 - val_accuracy: 0.4026\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2928 - accuracy: 0.4286 - val_loss: 2.6007 - val_accuracy: 0.4156\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2469 - accuracy: 0.4286 - val_loss: 2.6727 - val_accuracy: 0.4026\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2566 - accuracy: 0.4286 - val_loss: 2.5915 - val_accuracy: 0.4156\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2327 - accuracy: 0.4286 - val_loss: 2.6788 - val_accuracy: 0.3766\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2586 - accuracy: 0.4146 - val_loss: 2.5816 - val_accuracy: 0.4156\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2335 - accuracy: 0.4286 - val_loss: 2.6860 - val_accuracy: 0.3766\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2692 - accuracy: 0.4146 - val_loss: 2.5638 - val_accuracy: 0.4156\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2076 - accuracy: 0.4286 - val_loss: 2.6502 - val_accuracy: 0.3766\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2179 - accuracy: 0.4146 - val_loss: 2.5493 - val_accuracy: 0.4156\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1752 - accuracy: 0.4286 - val_loss: 2.6319 - val_accuracy: 0.3506\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1855 - accuracy: 0.4286 - val_loss: 2.5389 - val_accuracy: 0.4026\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1634 - accuracy: 0.4286 - val_loss: 2.6432 - val_accuracy: 0.3506\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1977 - accuracy: 0.4355 - val_loss: 2.5294 - val_accuracy: 0.4026\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1754 - accuracy: 0.4286 - val_loss: 2.6562 - val_accuracy: 0.3506\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2199 - accuracy: 0.4321 - val_loss: 2.5060 - val_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1374 - accuracy: 0.4286 - val_loss: 2.6026 - val_accuracy: 0.3506\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1390 - accuracy: 0.4390 - val_loss: 2.4880 - val_accuracy: 0.4026\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.0838 - accuracy: 0.4286 - val_loss: 2.5672 - val_accuracy: 0.3506\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0827 - accuracy: 0.4355 - val_loss: 2.4719 - val_accuracy: 0.4026\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.0614 - accuracy: 0.4286 - val_loss: 2.5825 - val_accuracy: 0.3506\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0971 - accuracy: 0.4704 - val_loss: 2.4789 - val_accuracy: 0.4156\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.1448 - accuracy: 0.4390 - val_loss: 2.6877 - val_accuracy: 0.3247\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2681 - accuracy: 0.4321 - val_loss: 2.4342 - val_accuracy: 0.4156\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.0531 - accuracy: 0.4425 - val_loss: 2.5252 - val_accuracy: 0.3896\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0310 - accuracy: 0.4704 - val_loss: 2.4083 - val_accuracy: 0.4156\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.9621 - accuracy: 0.4355 - val_loss: 2.4482 - val_accuracy: 0.4156\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9400 - accuracy: 0.4774 - val_loss: 2.3877 - val_accuracy: 0.4286\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.9132 - accuracy: 0.4739 - val_loss: 2.4239 - val_accuracy: 0.4286\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8946 - accuracy: 0.5157 - val_loss: 2.3627 - val_accuracy: 0.4416\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.8837 - accuracy: 0.4843 - val_loss: 2.4821 - val_accuracy: 0.3896\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9336 - accuracy: 0.4913 - val_loss: 2.4956 - val_accuracy: 0.4286\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.4153 - accuracy: 0.4530 - val_loss: 3.1262 - val_accuracy: 0.2727\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.7691 - accuracy: 0.2857 - val_loss: 2.3386 - val_accuracy: 0.4545\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9036 - accuracy: 0.4913 - val_loss: 2.3286 - val_accuracy: 0.4416\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.8657 - accuracy: 0.5017 - val_loss: 2.3082 - val_accuracy: 0.4416\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8401 - accuracy: 0.4878 - val_loss: 2.3001 - val_accuracy: 0.4416\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8179 - accuracy: 0.5017 - val_loss: 2.2883 - val_accuracy: 0.4416\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7961 - accuracy: 0.5017 - val_loss: 2.2777 - val_accuracy: 0.4416\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7740 - accuracy: 0.5017 - val_loss: 2.2647 - val_accuracy: 0.4675\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7506 - accuracy: 0.5087 - val_loss: 2.2532 - val_accuracy: 0.4675\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7255 - accuracy: 0.5157 - val_loss: 2.2354 - val_accuracy: 0.4675\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6978 - accuracy: 0.5192 - val_loss: 2.2238 - val_accuracy: 0.4935\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6700 - accuracy: 0.5610 - val_loss: 2.2459 - val_accuracy: 0.4805\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6729 - accuracy: 0.5157 - val_loss: 2.3915 - val_accuracy: 0.4416\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8325 - accuracy: 0.5401 - val_loss: 2.4237 - val_accuracy: 0.4675\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2189 - accuracy: 0.4774 - val_loss: 4.3061 - val_accuracy: 0.2078\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1809 - accuracy: 0.1812 - val_loss: 2.2403 - val_accuracy: 0.4935\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8385 - accuracy: 0.5470 - val_loss: 2.2020 - val_accuracy: 0.4935\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7465 - accuracy: 0.5470 - val_loss: 2.1590 - val_accuracy: 0.4805\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7112 - accuracy: 0.5366 - val_loss: 2.1287 - val_accuracy: 0.4805\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6825 - accuracy: 0.5366 - val_loss: 2.0953 - val_accuracy: 0.4805\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6537 - accuracy: 0.5366 - val_loss: 2.0642 - val_accuracy: 0.4805\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6249 - accuracy: 0.5575 - val_loss: 2.0317 - val_accuracy: 0.4805\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.5959 - accuracy: 0.5575 - val_loss: 2.0007 - val_accuracy: 0.4805\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5657 - accuracy: 0.5575 - val_loss: 1.9693 - val_accuracy: 0.4805\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5337 - accuracy: 0.5575 - val_loss: 1.9392 - val_accuracy: 0.5065\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4992 - accuracy: 0.5784 - val_loss: 1.9097 - val_accuracy: 0.5195\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4626 - accuracy: 0.5819 - val_loss: 1.8885 - val_accuracy: 0.5065\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : LSTM, 출력:128, 활성화함수:relu\n",
    "    # - 질문을 담당하는 계층\n",
    "    LSTM(\n",
    "        units=128,\n",
    "        activation=\"relu\"\n",
    "    ),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    LSTM(\n",
    "        units=128,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.keras\n",
    "mc = ModelCheckpoint(\n",
    "    \"./model/best_RNN_chatbot.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_train,\n",
    "    answers_train,\n",
    "    validation_data=(questions_val,\n",
    "                     answers_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38bb3b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4286 - accuracy: 0.5958\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8885 - accuracy: 0.5065\n",
      "훈련 데이터 | 손실율 : 1.4286280870437622, 정확도 : 0.595818817615509\n",
      "검증 데이터 | 손실율 : 1.8885213136672974, 정확도 : 0.5064935088157654\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9716151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               74496     \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 7, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,622\n",
      "Trainable params: 188,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3626 - accuracy: 0.0000e+00 - val_loss: 4.3373 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.3349 - accuracy: 0.4181 - val_loss: 4.3066 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3009 - accuracy: 0.4181 - val_loss: 4.2611 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.2497 - accuracy: 0.4181 - val_loss: 4.1862 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.1653 - accuracy: 0.4181 - val_loss: 4.0557 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.0175 - accuracy: 0.4181 - val_loss: 3.7985 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7270 - accuracy: 0.4181 - val_loss: 3.2505 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.1090 - accuracy: 0.4181 - val_loss: 2.9101 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.8497 - accuracy: 0.4181 - val_loss: 3.0898 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9187 - accuracy: 0.4181 - val_loss: 2.8057 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6597 - accuracy: 0.4181 - val_loss: 2.8293 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6347 - accuracy: 0.4181 - val_loss: 2.7905 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6106 - accuracy: 0.4181 - val_loss: 2.8103 - val_accuracy: 0.4026\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5907 - accuracy: 0.4181 - val_loss: 2.7771 - val_accuracy: 0.4026\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5722 - accuracy: 0.4181 - val_loss: 2.8037 - val_accuracy: 0.4026\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5572 - accuracy: 0.4181 - val_loss: 2.7654 - val_accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5438 - accuracy: 0.4181 - val_loss: 2.8111 - val_accuracy: 0.4026\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5379 - accuracy: 0.4181 - val_loss: 2.7601 - val_accuracy: 0.4026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5325 - accuracy: 0.4181 - val_loss: 2.8339 - val_accuracy: 0.4026\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5393 - accuracy: 0.4181 - val_loss: 2.7521 - val_accuracy: 0.4026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5187 - accuracy: 0.4181 - val_loss: 2.8223 - val_accuracy: 0.4026\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.5099 - accuracy: 0.4181 - val_loss: 2.7327 - val_accuracy: 0.4026\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4718 - accuracy: 0.4181 - val_loss: 2.7849 - val_accuracy: 0.4026\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.4539 - accuracy: 0.4181 - val_loss: 2.7176 - val_accuracy: 0.4026\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4268 - accuracy: 0.4181 - val_loss: 2.7618 - val_accuracy: 0.4026\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4119 - accuracy: 0.4181 - val_loss: 2.7058 - val_accuracy: 0.4026\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3930 - accuracy: 0.4181 - val_loss: 2.7537 - val_accuracy: 0.4026\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3832 - accuracy: 0.4181 - val_loss: 2.6936 - val_accuracy: 0.4026\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3696 - accuracy: 0.4181 - val_loss: 2.7607 - val_accuracy: 0.4156\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3703 - accuracy: 0.4425 - val_loss: 2.6817 - val_accuracy: 0.4026\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.3585 - accuracy: 0.4181 - val_loss: 2.7718 - val_accuracy: 0.4156\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3666 - accuracy: 0.4425 - val_loss: 2.6650 - val_accuracy: 0.4156\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.3350 - accuracy: 0.4425 - val_loss: 2.7523 - val_accuracy: 0.4156\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3317 - accuracy: 0.4425 - val_loss: 2.6433 - val_accuracy: 0.4156\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2893 - accuracy: 0.4425 - val_loss: 2.7177 - val_accuracy: 0.4156\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2785 - accuracy: 0.4425 - val_loss: 2.6233 - val_accuracy: 0.4156\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.2469 - accuracy: 0.4425 - val_loss: 2.7004 - val_accuracy: 0.4286\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2422 - accuracy: 0.4530 - val_loss: 2.6027 - val_accuracy: 0.4156\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2187 - accuracy: 0.4425 - val_loss: 2.7041 - val_accuracy: 0.3896\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2292 - accuracy: 0.4390 - val_loss: 2.5811 - val_accuracy: 0.4156\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2029 - accuracy: 0.4425 - val_loss: 2.7084 - val_accuracy: 0.3766\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2232 - accuracy: 0.4286 - val_loss: 2.5555 - val_accuracy: 0.4156\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.1721 - accuracy: 0.4425 - val_loss: 2.6786 - val_accuracy: 0.3636\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1804 - accuracy: 0.4216 - val_loss: 2.5282 - val_accuracy: 0.4156\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.1255 - accuracy: 0.4425 - val_loss: 2.6448 - val_accuracy: 0.3896\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1302 - accuracy: 0.4286 - val_loss: 2.5006 - val_accuracy: 0.4156\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0891 - accuracy: 0.4460 - val_loss: 2.6342 - val_accuracy: 0.4156\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1056 - accuracy: 0.4355 - val_loss: 2.4736 - val_accuracy: 0.4545\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0727 - accuracy: 0.4564 - val_loss: 2.6366 - val_accuracy: 0.4286\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1016 - accuracy: 0.4634 - val_loss: 2.4430 - val_accuracy: 0.4935\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0451 - accuracy: 0.4878 - val_loss: 2.6065 - val_accuracy: 0.4156\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0634 - accuracy: 0.4669 - val_loss: 2.4083 - val_accuracy: 0.4805\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0023 - accuracy: 0.4913 - val_loss: 2.5643 - val_accuracy: 0.4286\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0116 - accuracy: 0.4774 - val_loss: 2.3761 - val_accuracy: 0.4805\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.9704 - accuracy: 0.4913 - val_loss: 2.5460 - val_accuracy: 0.4026\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9867 - accuracy: 0.4774 - val_loss: 2.3460 - val_accuracy: 0.4545\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.9527 - accuracy: 0.4774 - val_loss: 2.5292 - val_accuracy: 0.4026\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9699 - accuracy: 0.4774 - val_loss: 2.3210 - val_accuracy: 0.4545\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.9286 - accuracy: 0.4913 - val_loss: 2.4901 - val_accuracy: 0.4416\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9288 - accuracy: 0.4983 - val_loss: 2.2924 - val_accuracy: 0.4416\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8828 - accuracy: 0.4913 - val_loss: 2.4643 - val_accuracy: 0.4416\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.8935 - accuracy: 0.4983 - val_loss: 2.2667 - val_accuracy: 0.4416\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8637 - accuracy: 0.4913 - val_loss: 2.4387 - val_accuracy: 0.3896\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8656 - accuracy: 0.5087 - val_loss: 2.2395 - val_accuracy: 0.4416\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8404 - accuracy: 0.4913 - val_loss: 2.3999 - val_accuracy: 0.4156\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8290 - accuracy: 0.5087 - val_loss: 2.2227 - val_accuracy: 0.4416\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7874 - accuracy: 0.4913 - val_loss: 2.3767 - val_accuracy: 0.4156\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7933 - accuracy: 0.5366 - val_loss: 2.2081 - val_accuracy: 0.4416\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7695 - accuracy: 0.4913 - val_loss: 2.3724 - val_accuracy: 0.4156\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7810 - accuracy: 0.5366 - val_loss: 2.1941 - val_accuracy: 0.4416\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7687 - accuracy: 0.4913 - val_loss: 2.3654 - val_accuracy: 0.4156\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7688 - accuracy: 0.5296 - val_loss: 2.1585 - val_accuracy: 0.4675\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7316 - accuracy: 0.4983 - val_loss: 2.3332 - val_accuracy: 0.4416\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7305 - accuracy: 0.5296 - val_loss: 2.1536 - val_accuracy: 0.4675\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7153 - accuracy: 0.4983 - val_loss: 2.3067 - val_accuracy: 0.4675\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7094 - accuracy: 0.5296 - val_loss: 2.1304 - val_accuracy: 0.4675\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6733 - accuracy: 0.4983 - val_loss: 2.2614 - val_accuracy: 0.4675\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6581 - accuracy: 0.5366 - val_loss: 2.1306 - val_accuracy: 0.4675\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6570 - accuracy: 0.4983 - val_loss: 2.2572 - val_accuracy: 0.4675\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6491 - accuracy: 0.5505 - val_loss: 2.1136 - val_accuracy: 0.4805\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6549 - accuracy: 0.5087 - val_loss: 2.2718 - val_accuracy: 0.4416\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6502 - accuracy: 0.5366 - val_loss: 2.0392 - val_accuracy: 0.4805\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6523 - accuracy: 0.5087 - val_loss: 2.1889 - val_accuracy: 0.4675\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5984 - accuracy: 0.5401 - val_loss: 2.0894 - val_accuracy: 0.4675\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5907 - accuracy: 0.5122 - val_loss: 2.1498 - val_accuracy: 0.4416\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5269 - accuracy: 0.5854 - val_loss: 1.9798 - val_accuracy: 0.4675\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5282 - accuracy: 0.5192 - val_loss: 2.1106 - val_accuracy: 0.4675\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5030 - accuracy: 0.5854 - val_loss: 2.1388 - val_accuracy: 0.4805\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5821 - accuracy: 0.5157 - val_loss: 2.3099 - val_accuracy: 0.4156\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.6101 - accuracy: 0.5366 - val_loss: 2.0001 - val_accuracy: 0.4805\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5933 - accuracy: 0.5157 - val_loss: 2.1340 - val_accuracy: 0.4675\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5380 - accuracy: 0.5714 - val_loss: 1.9659 - val_accuracy: 0.4935\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5176 - accuracy: 0.5296 - val_loss: 2.0631 - val_accuracy: 0.4545\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4358 - accuracy: 0.5679 - val_loss: 1.8234 - val_accuracy: 0.5065\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3572 - accuracy: 0.5366 - val_loss: 1.9382 - val_accuracy: 0.4545\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3109 - accuracy: 0.6132 - val_loss: 1.8057 - val_accuracy: 0.5065\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2879 - accuracy: 0.5854 - val_loss: 2.0199 - val_accuracy: 0.4675\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3147 - accuracy: 0.5993 - val_loss: 1.8754 - val_accuracy: 0.4935\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3540 - accuracy: 0.5470 - val_loss: 2.3239 - val_accuracy: 0.3896\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5889 - accuracy: 0.4774 - val_loss: 2.0576 - val_accuracy: 0.5065\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : GRU, 출력:128, 활성화함수:relu\n",
    "    # - 질문을 담당하는 계층\n",
    "    GRU(\n",
    "        units=128,\n",
    "        activation=\"relu\"\n",
    "    ),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    GRU(\n",
    "        units=128,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.keras\n",
    "mc = ModelCheckpoint(\n",
    "    \"./model/best_RNN_chatbot.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_train,\n",
    "    answers_train,\n",
    "    validation_data=(questions_val,\n",
    "                     answers_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da5bc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2880 - accuracy: 0.5854\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8057 - accuracy: 0.5065\n",
      "훈련 데이터 | 손실율 : 1.2879565954208374, 정확도 : 0.5853658318519592\n",
      "검증 데이터 | 손실율 : 1.8057223558425903, 정확도 : 0.5064935088157654\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c91cea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 128)               24704     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 7, 128)            32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,654\n",
      "Trainable params: 72,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.4324 - accuracy: 0.0000e+00 - val_loss: 3.8847 - val_accuracy: 0.3766\n",
      "Epoch 2/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8410 - accuracy: 0.4042 - val_loss: 3.1616 - val_accuracy: 0.4026\n",
      "Epoch 3/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0654 - accuracy: 0.4181 - val_loss: 2.8790 - val_accuracy: 0.4026\n",
      "Epoch 4/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.7562 - accuracy: 0.4181 - val_loss: 2.7651 - val_accuracy: 0.4026\n",
      "Epoch 5/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6701 - accuracy: 0.4251 - val_loss: 2.7204 - val_accuracy: 0.4026\n",
      "Epoch 6/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5913 - accuracy: 0.4216 - val_loss: 2.7037 - val_accuracy: 0.4545\n",
      "Epoch 7/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5206 - accuracy: 0.4634 - val_loss: 2.6423 - val_accuracy: 0.4286\n",
      "Epoch 8/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4743 - accuracy: 0.4286 - val_loss: 2.5586 - val_accuracy: 0.5065\n",
      "Epoch 9/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3540 - accuracy: 0.4843 - val_loss: 2.4239 - val_accuracy: 0.5065\n",
      "Epoch 10/80\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2643 - accuracy: 0.4564 - val_loss: 2.4012 - val_accuracy: 0.5455\n",
      "Epoch 11/80\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2272 - accuracy: 0.5052 - val_loss: 2.4041 - val_accuracy: 0.4805\n",
      "Epoch 12/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1762 - accuracy: 0.4564 - val_loss: 2.3397 - val_accuracy: 0.5195\n",
      "Epoch 13/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0894 - accuracy: 0.5540 - val_loss: 2.2439 - val_accuracy: 0.5195\n",
      "Epoch 14/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.0126 - accuracy: 0.5192 - val_loss: 2.1763 - val_accuracy: 0.5195\n",
      "Epoch 15/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9319 - accuracy: 0.5889 - val_loss: 2.0926 - val_accuracy: 0.5195\n",
      "Epoch 16/80\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.8823 - accuracy: 0.5610 - val_loss: 2.0977 - val_accuracy: 0.4935\n",
      "Epoch 17/80\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7968 - accuracy: 0.6341 - val_loss: 2.1571 - val_accuracy: 0.5584\n",
      "Epoch 18/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.8000 - accuracy: 0.5854 - val_loss: 1.9763 - val_accuracy: 0.5455\n",
      "Epoch 19/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6898 - accuracy: 0.6585 - val_loss: 1.8793 - val_accuracy: 0.5195\n",
      "Epoch 20/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6313 - accuracy: 0.5993 - val_loss: 1.8769 - val_accuracy: 0.5844\n",
      "Epoch 21/80\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5299 - accuracy: 0.6516 - val_loss: 1.8002 - val_accuracy: 0.5714\n",
      "Epoch 22/80\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5122 - accuracy: 0.6341 - val_loss: 1.7638 - val_accuracy: 0.6104\n",
      "Epoch 23/80\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4365 - accuracy: 0.6829 - val_loss: 1.8493 - val_accuracy: 0.6104\n",
      "Epoch 24/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4111 - accuracy: 0.6690 - val_loss: 1.7185 - val_accuracy: 0.6234\n",
      "Epoch 25/80\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3764 - accuracy: 0.6969 - val_loss: 1.8935 - val_accuracy: 0.6364\n",
      "Epoch 26/80\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3459 - accuracy: 0.7108 - val_loss: 1.6412 - val_accuracy: 0.5974\n",
      "Epoch 27/80\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2495 - accuracy: 0.7561 - val_loss: 1.5533 - val_accuracy: 0.6364\n",
      "Epoch 28/80\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2879 - accuracy: 0.6794 - val_loss: 1.6098 - val_accuracy: 0.6753\n",
      "Epoch 29/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1962 - accuracy: 0.7526 - val_loss: 1.5520 - val_accuracy: 0.6234\n",
      "Epoch 30/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1589 - accuracy: 0.7282 - val_loss: 1.4855 - val_accuracy: 0.6883\n",
      "Epoch 31/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1278 - accuracy: 0.7526 - val_loss: 1.6215 - val_accuracy: 0.6753\n",
      "Epoch 32/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1438 - accuracy: 0.7456 - val_loss: 1.4324 - val_accuracy: 0.7013\n",
      "Epoch 33/80\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0114 - accuracy: 0.8153 - val_loss: 1.4409 - val_accuracy: 0.7013\n",
      "Epoch 34/80\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9701 - accuracy: 0.8084 - val_loss: 1.3212 - val_accuracy: 0.7273\n",
      "Epoch 35/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9445 - accuracy: 0.8084 - val_loss: 1.3324 - val_accuracy: 0.7013\n",
      "Epoch 36/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9201 - accuracy: 0.8258 - val_loss: 1.2665 - val_accuracy: 0.7273\n",
      "Epoch 37/80\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9109 - accuracy: 0.8606 - val_loss: 1.4586 - val_accuracy: 0.6883\n",
      "Epoch 38/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9080 - accuracy: 0.8153 - val_loss: 1.2486 - val_accuracy: 0.7013\n",
      "Epoch 39/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8610 - accuracy: 0.8502 - val_loss: 1.2395 - val_accuracy: 0.7013\n",
      "Epoch 40/80\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8174 - accuracy: 0.8467 - val_loss: 1.1577 - val_accuracy: 0.7273\n",
      "Epoch 41/80\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7786 - accuracy: 0.8850 - val_loss: 1.1869 - val_accuracy: 0.7143\n",
      "Epoch 42/80\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7685 - accuracy: 0.8467 - val_loss: 1.1155 - val_accuracy: 0.7532\n",
      "Epoch 43/80\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7540 - accuracy: 0.8780 - val_loss: 1.1522 - val_accuracy: 0.7143\n",
      "Epoch 44/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7582 - accuracy: 0.8571 - val_loss: 1.1025 - val_accuracy: 0.7662\n",
      "Epoch 45/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6843 - accuracy: 0.9059 - val_loss: 1.0051 - val_accuracy: 0.7922\n",
      "Epoch 46/80\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6984 - accuracy: 0.8676 - val_loss: 1.0306 - val_accuracy: 0.7792\n",
      "Epoch 47/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6606 - accuracy: 0.8990 - val_loss: 0.9988 - val_accuracy: 0.7532\n",
      "Epoch 48/80\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6595 - accuracy: 0.8780 - val_loss: 0.9727 - val_accuracy: 0.7792\n",
      "Epoch 49/80\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5773 - accuracy: 0.9164 - val_loss: 0.9398 - val_accuracy: 0.7792\n",
      "Epoch 50/80\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5301 - accuracy: 0.9512 - val_loss: 0.9162 - val_accuracy: 0.8052\n",
      "Epoch 51/80\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5276 - accuracy: 0.9373 - val_loss: 0.9666 - val_accuracy: 0.7662\n",
      "Epoch 52/80\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5546 - accuracy: 0.8990 - val_loss: 1.0545 - val_accuracy: 0.7403\n",
      "Epoch 53/80\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5589 - accuracy: 0.9233 - val_loss: 1.0172 - val_accuracy: 0.7532\n",
      "Epoch 54/80\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5396 - accuracy: 0.9024 - val_loss: 0.8948 - val_accuracy: 0.8052\n",
      "Epoch 55/80\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5104 - accuracy: 0.9303 - val_loss: 0.9648 - val_accuracy: 0.7532\n",
      "Epoch 56/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4721 - accuracy: 0.9443 - val_loss: 0.8200 - val_accuracy: 0.8182\n",
      "Epoch 57/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4485 - accuracy: 0.9443 - val_loss: 0.7828 - val_accuracy: 0.8182\n",
      "Epoch 58/80\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4335 - accuracy: 0.9582 - val_loss: 0.7850 - val_accuracy: 0.8182\n",
      "Epoch 59/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4071 - accuracy: 0.9686 - val_loss: 0.7544 - val_accuracy: 0.8571\n",
      "Epoch 60/80\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4223 - accuracy: 0.9617 - val_loss: 0.7322 - val_accuracy: 0.8442\n",
      "Epoch 61/80\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3870 - accuracy: 0.9512 - val_loss: 0.7421 - val_accuracy: 0.8571\n",
      "Epoch 62/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3845 - accuracy: 0.9582 - val_loss: 0.7589 - val_accuracy: 0.8052\n",
      "Epoch 63/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3708 - accuracy: 0.9652 - val_loss: 0.7941 - val_accuracy: 0.8052\n",
      "Epoch 64/80\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3754 - accuracy: 0.9617 - val_loss: 0.7793 - val_accuracy: 0.8052\n",
      "Epoch 65/80\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3376 - accuracy: 0.9756 - val_loss: 0.6772 - val_accuracy: 0.8571\n",
      "Epoch 66/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3251 - accuracy: 0.9686 - val_loss: 0.6620 - val_accuracy: 0.9091\n",
      "Epoch 67/80\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3302 - accuracy: 0.9756 - val_loss: 0.6220 - val_accuracy: 0.8701\n",
      "Epoch 68/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2775 - accuracy: 0.9756 - val_loss: 0.6115 - val_accuracy: 0.9091\n",
      "Epoch 69/80\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2804 - accuracy: 0.9791 - val_loss: 0.6590 - val_accuracy: 0.8831\n",
      "Epoch 70/80\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2793 - accuracy: 0.9861 - val_loss: 0.5837 - val_accuracy: 0.9091\n",
      "Epoch 71/80\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2665 - accuracy: 0.9861 - val_loss: 0.5839 - val_accuracy: 0.8961\n",
      "Epoch 72/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2656 - accuracy: 0.9826 - val_loss: 0.5708 - val_accuracy: 0.9351\n",
      "Epoch 73/80\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2450 - accuracy: 0.9861 - val_loss: 0.5472 - val_accuracy: 0.9091\n",
      "Epoch 74/80\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2474 - accuracy: 0.9721 - val_loss: 0.5605 - val_accuracy: 0.9351\n",
      "Epoch 75/80\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2400 - accuracy: 0.9861 - val_loss: 0.5552 - val_accuracy: 0.9091\n",
      "Epoch 76/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2143 - accuracy: 0.9895 - val_loss: 0.5564 - val_accuracy: 0.9091\n",
      "Epoch 77/80\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2155 - accuracy: 0.9930 - val_loss: 0.5469 - val_accuracy: 0.8831\n",
      "Epoch 78/80\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2283 - accuracy: 0.9826 - val_loss: 0.5274 - val_accuracy: 0.9351\n",
      "Epoch 79/80\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2223 - accuracy: 0.9965 - val_loss: 0.6212 - val_accuracy: 0.8701\n",
      "Epoch 80/80\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2319 - accuracy: 0.9512 - val_loss: 0.6405 - val_accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : SimpleRNN, 출력:128, 활성화함수:tanh\n",
    "    # - 질문을 담당하는 계층\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"tanh\"\n",
    "    ),\n",
    "    Dropout(0.3),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"tanh\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    Dropout(0.2),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.keras\n",
    "mc = ModelCheckpoint(\n",
    "    \"./model/best_RNN_chatbot.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_train,\n",
    "    answers_train,\n",
    "    validation_data=(questions_val,\n",
    "                     answers_val),\n",
    "    epochs=80,\n",
    "    batch_size=64,\n",
    "    callbacks=[mc, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13029851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5274 - accuracy: 0.9351\n",
      "훈련 데이터 | 손실율 : 0.13875816762447357, 정확도 : 1.0\n",
      "검증 데이터 | 손실율 : 0.5273736715316772, 정확도 : 0.9350649118423462\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dd25dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 7, 128)            131584    \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,454\n",
      "Trainable params: 245,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.3579 - accuracy: 0.0035 - val_loss: 4.3242 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3212 - accuracy: 0.4181 - val_loss: 4.2644 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.2548 - accuracy: 0.4181 - val_loss: 4.1107 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.0804 - accuracy: 0.4181 - val_loss: 3.6573 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5537 - accuracy: 0.4181 - val_loss: 2.9352 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7496 - accuracy: 0.4181 - val_loss: 2.8581 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.6926 - accuracy: 0.4181 - val_loss: 2.8642 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6659 - accuracy: 0.4181 - val_loss: 2.7981 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.6372 - accuracy: 0.4181 - val_loss: 2.8265 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6144 - accuracy: 0.4181 - val_loss: 2.7609 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.5881 - accuracy: 0.4181 - val_loss: 2.7891 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5673 - accuracy: 0.4181 - val_loss: 2.7359 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.5470 - accuracy: 0.4181 - val_loss: 2.7620 - val_accuracy: 0.4026\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5307 - accuracy: 0.4181 - val_loss: 2.7176 - val_accuracy: 0.4026\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.5152 - accuracy: 0.4181 - val_loss: 2.7447 - val_accuracy: 0.4026\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5028 - accuracy: 0.4181 - val_loss: 2.7024 - val_accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.4910 - accuracy: 0.4181 - val_loss: 2.7350 - val_accuracy: 0.4026\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.4823 - accuracy: 0.4181 - val_loss: 2.6898 - val_accuracy: 0.4026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.4735 - accuracy: 0.4181 - val_loss: 2.7292 - val_accuracy: 0.4026\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4670 - accuracy: 0.4181 - val_loss: 2.6778 - val_accuracy: 0.4026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4571 - accuracy: 0.4181 - val_loss: 2.7166 - val_accuracy: 0.4286\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4475 - accuracy: 0.4251 - val_loss: 2.6629 - val_accuracy: 0.4286\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4338 - accuracy: 0.4251 - val_loss: 2.6956 - val_accuracy: 0.4286\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4216 - accuracy: 0.4251 - val_loss: 2.6484 - val_accuracy: 0.4026\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4083 - accuracy: 0.4181 - val_loss: 2.6756 - val_accuracy: 0.4286\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.3973 - accuracy: 0.4251 - val_loss: 2.6357 - val_accuracy: 0.4026\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3864 - accuracy: 0.4181 - val_loss: 2.6607 - val_accuracy: 0.4286\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3775 - accuracy: 0.4251 - val_loss: 2.6239 - val_accuracy: 0.4286\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3689 - accuracy: 0.4251 - val_loss: 2.6503 - val_accuracy: 0.4286\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3618 - accuracy: 0.4251 - val_loss: 2.6126 - val_accuracy: 0.4286\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3544 - accuracy: 0.4251 - val_loss: 2.6409 - val_accuracy: 0.4286\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.3474 - accuracy: 0.4251 - val_loss: 2.5999 - val_accuracy: 0.4286\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3388 - accuracy: 0.4251 - val_loss: 2.6276 - val_accuracy: 0.4286\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.3293 - accuracy: 0.4251 - val_loss: 2.5855 - val_accuracy: 0.4286\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3190 - accuracy: 0.4251 - val_loss: 2.6108 - val_accuracy: 0.4286\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3080 - accuracy: 0.4251 - val_loss: 2.5711 - val_accuracy: 0.4286\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.2978 - accuracy: 0.4251 - val_loss: 2.5948 - val_accuracy: 0.4286\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2875 - accuracy: 0.4251 - val_loss: 2.5572 - val_accuracy: 0.4286\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2785 - accuracy: 0.4251 - val_loss: 2.5815 - val_accuracy: 0.4416\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2694 - accuracy: 0.4495 - val_loss: 2.5432 - val_accuracy: 0.4286\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2618 - accuracy: 0.4251 - val_loss: 2.5699 - val_accuracy: 0.4416\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2529 - accuracy: 0.4495 - val_loss: 2.5280 - val_accuracy: 0.4286\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2458 - accuracy: 0.4251 - val_loss: 2.5570 - val_accuracy: 0.4416\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2354 - accuracy: 0.4495 - val_loss: 2.5110 - val_accuracy: 0.4416\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2275 - accuracy: 0.4495 - val_loss: 2.5409 - val_accuracy: 0.4545\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2153 - accuracy: 0.4599 - val_loss: 2.4927 - val_accuracy: 0.4416\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2069 - accuracy: 0.4495 - val_loss: 2.5233 - val_accuracy: 0.4545\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.1941 - accuracy: 0.4599 - val_loss: 2.4740 - val_accuracy: 0.4416\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1862 - accuracy: 0.4495 - val_loss: 2.5061 - val_accuracy: 0.4545\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1737 - accuracy: 0.4599 - val_loss: 2.4549 - val_accuracy: 0.4416\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1671 - accuracy: 0.4495 - val_loss: 2.4894 - val_accuracy: 0.4545\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1542 - accuracy: 0.4599 - val_loss: 2.4353 - val_accuracy: 0.4416\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1484 - accuracy: 0.4495 - val_loss: 2.4718 - val_accuracy: 0.4545\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.1342 - accuracy: 0.4599 - val_loss: 2.4150 - val_accuracy: 0.4416\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1286 - accuracy: 0.4495 - val_loss: 2.4523 - val_accuracy: 0.4545\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.1128 - accuracy: 0.4599 - val_loss: 2.3945 - val_accuracy: 0.4416\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1073 - accuracy: 0.4495 - val_loss: 2.4320 - val_accuracy: 0.4545\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.0908 - accuracy: 0.4564 - val_loss: 2.3746 - val_accuracy: 0.4416\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0861 - accuracy: 0.4495 - val_loss: 2.4126 - val_accuracy: 0.4286\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0697 - accuracy: 0.4564 - val_loss: 2.3554 - val_accuracy: 0.4416\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0665 - accuracy: 0.4495 - val_loss: 2.3941 - val_accuracy: 0.4286\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0496 - accuracy: 0.4564 - val_loss: 2.3364 - val_accuracy: 0.4416\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0476 - accuracy: 0.4495 - val_loss: 2.3754 - val_accuracy: 0.4286\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0295 - accuracy: 0.4564 - val_loss: 2.3173 - val_accuracy: 0.4416\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0281 - accuracy: 0.4495 - val_loss: 2.3560 - val_accuracy: 0.4286\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.0087 - accuracy: 0.4564 - val_loss: 2.2981 - val_accuracy: 0.4416\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.0077 - accuracy: 0.4495 - val_loss: 2.3365 - val_accuracy: 0.4286\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9877 - accuracy: 0.4704 - val_loss: 2.2792 - val_accuracy: 0.4545\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9878 - accuracy: 0.4599 - val_loss: 2.3176 - val_accuracy: 0.4286\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9674 - accuracy: 0.4704 - val_loss: 2.2606 - val_accuracy: 0.4675\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.9688 - accuracy: 0.4704 - val_loss: 2.2990 - val_accuracy: 0.4416\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9473 - accuracy: 0.4808 - val_loss: 2.2419 - val_accuracy: 0.4675\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9497 - accuracy: 0.4704 - val_loss: 2.2801 - val_accuracy: 0.4416\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9270 - accuracy: 0.4808 - val_loss: 2.2231 - val_accuracy: 0.4675\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9300 - accuracy: 0.4704 - val_loss: 2.2610 - val_accuracy: 0.4416\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.9064 - accuracy: 0.4808 - val_loss: 2.2043 - val_accuracy: 0.4675\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9101 - accuracy: 0.4704 - val_loss: 2.2422 - val_accuracy: 0.4416\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8860 - accuracy: 0.4808 - val_loss: 2.1857 - val_accuracy: 0.4675\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8905 - accuracy: 0.4704 - val_loss: 2.2235 - val_accuracy: 0.4545\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8659 - accuracy: 0.5087 - val_loss: 2.1671 - val_accuracy: 0.4675\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8709 - accuracy: 0.4704 - val_loss: 2.2049 - val_accuracy: 0.4545\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8458 - accuracy: 0.5087 - val_loss: 2.1483 - val_accuracy: 0.4675\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.8509 - accuracy: 0.4704 - val_loss: 2.1863 - val_accuracy: 0.4545\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.8256 - accuracy: 0.5087 - val_loss: 2.1296 - val_accuracy: 0.4675\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8309 - accuracy: 0.4843 - val_loss: 2.1677 - val_accuracy: 0.4805\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8057 - accuracy: 0.5226 - val_loss: 2.1109 - val_accuracy: 0.4805\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8112 - accuracy: 0.4948 - val_loss: 2.1494 - val_accuracy: 0.4935\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7860 - accuracy: 0.5331 - val_loss: 2.0923 - val_accuracy: 0.4805\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7915 - accuracy: 0.4948 - val_loss: 2.1313 - val_accuracy: 0.4935\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7665 - accuracy: 0.5331 - val_loss: 2.0738 - val_accuracy: 0.4805\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7721 - accuracy: 0.4948 - val_loss: 2.1133 - val_accuracy: 0.5065\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7472 - accuracy: 0.5575 - val_loss: 2.0552 - val_accuracy: 0.4805\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7527 - accuracy: 0.4948 - val_loss: 2.0955 - val_accuracy: 0.4935\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7281 - accuracy: 0.5575 - val_loss: 2.0368 - val_accuracy: 0.4805\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7334 - accuracy: 0.4948 - val_loss: 2.0778 - val_accuracy: 0.4935\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7091 - accuracy: 0.5575 - val_loss: 2.0185 - val_accuracy: 0.4805\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7141 - accuracy: 0.4948 - val_loss: 2.0602 - val_accuracy: 0.4935\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6902 - accuracy: 0.5714 - val_loss: 2.0002 - val_accuracy: 0.4805\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6951 - accuracy: 0.4948 - val_loss: 2.0427 - val_accuracy: 0.4935\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6715 - accuracy: 0.5714 - val_loss: 1.9822 - val_accuracy: 0.4805\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : LSTM, 출력:128, 활성화함수:tanh\n",
    "    # - 질문을 담당하는 계층\n",
    "    LSTM(\n",
    "        units=128,\n",
    "        activation=\"tanh\"\n",
    "    ),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    LSTM(\n",
    "        units=128,\n",
    "        activation=\"tanh\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.keras\n",
    "mc = ModelCheckpoint(\n",
    "    \"./model/best_RNN_chatbot.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_train,\n",
    "    answers_train,\n",
    "    validation_data=(questions_val,\n",
    "                     answers_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4591fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 11ms/step - loss: 1.6760 - accuracy: 0.4948\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9822 - accuracy: 0.4805\n",
      "훈련 데이터 | 손실율 : 1.6759955883026123, 정확도 : 0.4947735071182251\n",
      "검증 데이터 | 손실율 : 1.9821912050247192, 정확도 : 0.48051947355270386\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5996bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 1.6760 - accuracy: 0.4948\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9822 - accuracy: 0.4805\n",
      "훈련 데이터 | 손실율 : 1.6759955883026123, 정확도 : 0.4947735071182251\n",
      "검증 데이터 | 손실율 : 1.9821912050247192, 정확도 : 0.48051947355270386\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"./model/best_RNN_chatbot.keras\")\n",
    "\n",
    "train_score = best_model.evaluate(questions_train, answers_train) \n",
    "val_score = best_model.evaluate(questions_val, answers_val)\n",
    "\n",
    "print(f\"훈련 데이터 | 손실율 : {train_score[0]}, 정확도 : {train_score[1]}\")\n",
    "print(f\"검증 데이터 | 손실율 : {val_score[0]}, 정확도 : {val_score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4db7080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHYklEQVR4nO2dB3gU5fbG3/ReIJUWuvQuSJPeBBFULIgi9gL2rn+vhat4bVe99ooNURAUpXek995bQg8hJKSRuv/nfJNNNg1SZmd3J+/veYbZnZmdzPfOkD053yluFovFAkIIIYQQk+Du6AsghBBCCNETGjeEEEIIMRU0bgghhBBiKmjcEEIIIcRU0LghhBBCiKmgcUMIIYQQU0HjhhBCCCGmgsYNIYQQQkwFjRtCCCGEmAoaN4QQp8bNzQ2vvvqqbuc7evSoOueyZctgNH369FHL5WjQoAHGjRtnyDURYkZo3BDipEyePFl9CVsXT09P1KlTR33pnThxosTx8qUpxw0fPrzML/R33323YJt8uVvPvWnTphKfkZ8TGBh42eucM2eOrsYHIYRUFc8qn4EQYldef/11NGzYEBcvXsTatWuV0bNy5Urs3LkTvr6+JY7/+++/lbHSqVOncv8MMU7++uuvSl2fGDeffPKJ3QycjIwMZdgRQkh5oeeGECfnmmuuwe233457770XX3/9NZ5++mkcOnQIs2bNKnFsTEwMatSogddee63c52/fvr0yiDZv3gx7k5OTg6ysrAp9Rgw4GjeEkIpA44YQF+Pqq69WazFwihMUFIQnnnhCeWHKa6w88sgjyiCqjOdFpq7EayPYTqEVnwr74IMP0LhxY/j4+GD37t3KwPnXv/6lvEshISEICAhQ41q6dOllY27ktWw7ePCg+vmhoaHqHHfddRfS09OhF9deey0aNWpU6r5u3brhyiuvLHj/3XffoV+/foiMjFRjbNmyJT777DPoyeHDh3HTTTehZs2a8Pf3R9euXTF79uwSx/3vf/9Dq1at1DFyX+U6p0yZUrA/JSUFjz/+uIrrkWuVax44cKAhxi0hRsE/hwhxMcRoEOSLqzQee+wx/Pe//1VGQGneneIEBwcrg0iMDfmC69ixY7mv5YEHHsDJkyexcOFC/Pjjj6UeI1/8MqV2//33qy9T+XK+cOGC8kKNHj0a9913n/rC/eabbzB48GCsX79eeZMux80336ym6yZNmqSuW84nX9T/+c9/oAe33HILxo4diw0bNqBz584F22NjY9X04DvvvFOwTQwZMSiuu+465WUS4/Lhhx9GXl4exo8fX+VrOXPmDLp3766Mt0cffRRhYWH4/vvv1c+bPn06rr/+enXcV199pfaPGjVKPQei+/bt27Fu3Trcdttt6pgHH3xQfWbChAnKCDt37pya5tyzZ0+F7j0hTo2FEOKUfPfddxb5L7po0SLL2bNnLceOHbNMnz7dEhERYfHx8VHvbendu7elVatW6vVrr72mPrtp0yb1/siRI+r9O++8U3D80qVL1bZp06ZZkpKSLDVq1LBcd911BfvvvPNOS0BAwGWvc/z48eo8xbH+zODgYEt8fHyRfTk5OZbMzMwi286fP2+Jioqy3H333UW2yzleeeWVgvfyWrYVP+7666+3hIWFXfZ6rdcl478UycnJSuennnqqyPa3337b4ubmZomNjS3Ylp6eXuLzgwcPtjRq1KjEPZLlctSvX1/pb+Xxxx9X1/zPP/8UbEtJSbE0bNjQ0qBBA0tubq7aNmLEiIJnoCxCQkLUPSPEzHBaihAnZ8CAAYiIiEC9evXUX+QyhSMembp165b5GfmrvSKxNzKtI1MVct4tW7boePXAjTfeqK7fFg8PD3h7e6vX4t1ITExU8TgyhVLe6RHxQNgi01rihRCvkB6IR0vinX777Tex3Aq2//rrr2pKSOKbrPj5+RW8Tk5ORkJCAnr37q2mkuR9VZGg7S5duqBnz54F2ySTTbxh4smTqT5BpuiOHz+uvE1lIceIJ0c8boSYFRo3hDg5EtMi0z4ylTB06FD1xSnTO3obK2IQyRef3llPMnVUGjKt0rZtWxUwLNMsYgBJDEl5jQFb48J2mu78+fPQC5maOnbsGNasWVMQ5ySZaLLdllWrVikjVAxP0VDG8uKLL6p9ehg3MhXWrFmzEttbtGhRsF947rnnlNEjhlDTpk3VlJhcmy1vv/22yrQTY1mOk/stRhghZoLGDSFOjnwByReneEDEWGndurWKn0hNTS2XseJo742tV8PKTz/9pIKBJchYYm3mzZunDDgJyhVPTnkQ709p2HpZqorUDJLAXPHeCLJ2d3dXgb1WxODp37+/Mjrff/99ZaDJWCSOSSjvePRAjJ19+/Zh6tSpysvz+++/q/Urr7xSJFZJjBkJPK5du7aKHZJ4oblz5xp2nYTYGxo3hLgQ8oUuAbQypfDxxx+Xy1j5888/y22syPEVMYgEa3ZURRAvlGQizZgxA3fccYcKJBYDTgJgnQnxxEjW1LRp05SRIlNSMv0lRoEVCR7OzMxURqEEWIt3TcZSmlFXWerXr6+MluLs3bu3YL/tNYtnSQK54+LiMGzYMLzxxhtFtK1Vq5YKeP7jjz9w5MgR5TmTYwgxCzRuCHExpBKxeHMkvfpyxoDVWJFCgOXB1iDaunVruT4jX6ZCUlISyovV62LrZZE4EOv0jzMhhoIYk5KNtW3bthJTUqWNRaaixLjQCzGYJIvMVp+0tDR8+eWXKqVbsp4EiTmyReKaZJ9cW3Z2NnJzc0tMk0mGmRhrYqARYhaYCk6IC/LMM8+oqRGpVlw8sLa4sSLTUxXxxFhTyeWL3Gq4XAprJWRJQRYPjHzZ33rrrZf8jHhDxGsjKcziWRDvweeff66+iC833WY0YlhI/SApnihjk+lBWwYNGqSMCJnCEs+NXL+kZIvRcOrUKV2u4fnnn8cvv/yiApxFZ0mnl5gl0U2mnmSqzHot0dHR6NGjB6KiolR6t3j4RGMZgxigEogugent2rVT8TmLFi1SAcjvvfeeLtdKiDNAzw0hLsgNN9yg4lWkQJ78NX4pxBMjRk55EU+PfKYi1yKFACVuRqaYpHbN5ZB4mzfffFMZUPJlPX/+fBWHY1sYz1mQgGepJyO1ePr27auMFlsk0Fem2WR6TgwgMdIki0mMRL0QQ2X16tWq2J7EyrzwwgvKoJIpMWuNG8FqXEnsjwQTy7ST6CvaChI/JNNR4pWTOByJC5Lprk8//RRPPvmkbtdLiKNxk3xwR18EIYQYhaROSwaXVEMuT4duQojrQc8NIYQQQkwFjRtCCCGEmAoaN4QQQggxFYy5IYQQQoipoOeGEEIIIaaCxg0hhBBCTEW1K+InJdSl2qgUtKpM2XhCCCGEGI9E0Ui9KamobS1cWRbVzrgRw0a64RJCCCHE9Th27JiqtH0pqp1xIx4bqzjBwcG6njsnJwebNm1S5eg9PaudtIZCrY2DWhsHtTYOau16Wl+4cEE5J6zf45ei2t1R61SUGDZ6GzfSmC49PV0J7+Xlpeu5SVGotXFQa+Og1sZBrV1X6/KElDCgmBBCCCGmgsYNIYQQQkwFjRsd8fDwQPv27dWa2BdqbRzU2jiotXFQa3NrXe0qFEtAUkhICJKTk3WPuSGEEFK9kXIjWVlZjr4Ml0TicS5lAFXk+7vaBRTbOyJ8xYoV6NWrF6Pv7Qy1Ng5qbRzU2rW1FqPmyJEjysAhhYgPJTMzEz4+PpcNBg4NDUV0dHSV69Dxf48dCgxVM2eYQ6DWxkGtjYNau67Wcp5Tp04pz4OkK1+uyFx1Ii8vD6mpqQgMDCxTF9FPMqri4+PV+1q1alXpZ9K4IYQQQnTwBMmXs1TP9ff3d/TlOOVUna+v7yWNPj8/P7UWAycyMrJKMTo0LQkhhJAqkpubq9be3t6OvhSXxmoYSm2cqkDjRkfEyuzWrRuj7w2AWhsHtTYOau36WrNnYemaBAQElEsbvfTjtJSOiLtNXGnE/lBr46DWxkGtjYNaG4cYLEZXgabnRkfEjTZ79uwqu9PI5aHWxkGtjYNaGwe1tg8NGjTABx98UCLmJikpydAsMnpu7BBURoyBWhsHtTYOam0c1FqjT58+qshecaOkMmzYsEFNQTkaGjc68s/BBGSzvAEhhBATYbFYVMB0eeoBRUREwBngtJROzNxyHPf8sBnf7HNHZrYWNU8IIYQ4M+PGjcPy5cvx4YcfqtgYWSZPnqzWc+fORadOnVTxvZUrV+LQoUMYMWIEoqKiVM2azp07Y9GiRZeclpLzfP3117j99tvVZ5o2bYpZs2bZfVw0bnSiVogffD09sCfJHROmbkdmDg0ceyJ/QfTt25dVXA2AWhsHtTaP1qooXVaOQxZLBQoTilEjWWP33XefKkIoixQhFJ5//nm89dZb2LNnD9q2basK8Q0dOhSLFy/Gli1bMGTIEAwfPhxxcXGX/BkTJ07E6NGjsW3bNvX5MWPGIDExEfaE/4N0omujMHw77krcNXkDlu0/i4d+2ozPbu8IH0+mdNoLa8EnYn+otXFQa3NonZGdi5b/mg9HsPv1wfD3Lt/Xu/Rqkto8Ul9G2h4Ie/fuVevXX38dAwcOLDi2Zs2aaNeuXRGjZebMmcoTM2HChDJ/xp133qmMG/HivPnmm/joo4+wfv16ZRzZC3pudOTKSODBxinw9XLHkr3xePinzfTg2DEQcM6cOQwINABqbRzU2jio9eW58sori7wXz83TTz+NFi1aqB5QMs0kXp3LeW7atGmjml6KR0mCjaXppbXNgr2g50Yv9s6G51+PY1hAZ3QY8z7u/2kLFu+Nx/iftygPjpcH7UhCCKku+Hl5KA+Ko362HhTPehLDZuHChXj33XfRpEkT5fkaNWrUZbugF69xIx4ce6eF07jRDTe4pcWjcdo8NAh+Ed/c2Rn3fL8Bi/acwQ9rYnFPz4aOvkBCCCEGIV/g5Z0acjTe3t4F7SMuxapVq1QA8vXXX1/gyTl69CicEboT9KL5UOQ1HQx35MJj/rPo2SQM/xreUu3635IDSM5goShCCCHOR4MGDbBu3TplqCQkJJTpVZFMpxkzZmDr1q0qOPi2224ztDBfRaBxoyNu1/wHFk8/uMeuAnZMwy1X1kOTyEAkpWfjs2WHHH15pkIyHCTqnlkl9odaGwe1Ng5qXXS6SXpstWzZUtWpKSuG5v3330eNGjXQvXt3lSU1ePBgdOzYEeXxYkmcjZF9t9wsFckZMwES1CTR4cnJyUpsPREpMxe9Cd9VbwMBkcCEDVh0JBP3/rAR3p7uWPp0H9QJZSaEXlqnpKQgKCiIjersDLU2DmrtulpfvHgRR44cQcOGDeHr66vLNZpJ67y8PNXP63JaX0rHinx/03OjIxJ1vzC1GSw1GwNp8cDSN9G/RSSualgTWTl5eG/BPkdfoqm0Xrp0KTMdDIBaGwe1Ng5qbbwhaaQvhcaNzuS5eyF3yNvamw1fwe3UNrw4tIV6O3PLCew6mezYCySEEEJMDo0bO2Bp2BtofSNgyQNmP4l2dYIxvF1tiNH61lytOBIhhBBC7AONG50pCE4b9AbgHQSc2AQcWoJnBjWDl4cb/jmQgOX7zzr6Mk0BAwGNg1obB7U2DmptXmjc6IgUKho2bJhWsCi4FtBqhLbj6D+ICfPH2G4N1NuPFh9w7IWaTWtiV6i1cVBr46DWxiGBxFLRWNaG/UzDflI1QKLBpaR0Qd5/THdtHbdWre7qoRk3W48l4SI7h+urNbEb1No4qLVxUGvjkEDi7OxsBhS7KlLhcc2aNYWVHmO6auuTm4HsiyoNPDzQB7l5Fuw6ecGh12o6rYndoNbGQa2Ng1obhxg1aWlpNG5MQ81GQGAUkJulYm8kv79d3RC1a9uxJEdfHSGEEGJKaNzYEylWFNNNex23Rq3a1QtV6+3HadwQQggh9oDGjY6IZ6ZEtctixk1bq+fmOOvd6K41sQvU2jiotXFQa317U33wwQdl7heNy1OdWE+YB6dzWmG/fv2Kbqyfb9wcWw/k5aJdXc1zcyQhDcnp2QjxZ6S+bloTu0CtjYNaGwe1Ng5rbykjoedGRyTqPjY2tmj0fVRrwCcYyLwAnNmFGgHeiKnpr3ZtP8GpKV21JnaBWhsHtTYOam0cqu9iZiYDil0VibqXVvBFou/dPYB6XcqIu+HUlK5aE7tArY2DWhsHtdb48ssvUbt27RJG3ogRI3D33Xfj0KFD6nVUVBQCAwPRuXNnLFq0CBVBjJqMjAwaN6bDmhIeu1qtmDFFCCEmR77Is9Ics1jKb0TcdNNNOHfunGoiaiUxMRHz5s3DmDFjkJqaiqFDh2Lx4sXYsmULhgwZguHDhyMuLg7ODGNujMC2mJ/Fgrb5cTfbmDFFCCHmJDsdeLO2Y372iycB74ByHVqjRg1cc801mDJlCvr376+2TZ8+HeHh4ejbt68KBG7Xrl3B8RMnTsTMmTMxa9YsTJgwAc4KPTc6B01FRESUjAiv0wnw8AZSTwPnj6B1nWC4uwFnLmTidPJFR12uObUmukOtjYNaGwe1LkQ8NL///ruKixF+/vln3HrrrcqwEc/N008/jRYtWqgWCjI1tWfPngp5bkRjCeBmtpSLIjeve/d8L40tXr5A7Q7AsXXKe+PfvhGuiArC3tMpynsTHRLtiMs1p9ZEd6i1cVBrE2nt5a95UByBl5a0Ul5kmkniYWbPnq1iav755x/897//VfvEsFm4cCHeffddNGnSBH5+fhg1ahSysrLKfX4xasQoMhJ6bnREAtP27t1beoCatd5NQdwNi/nZTWuiK9TaOKi1ibQWL4VMDTlicauYh8TX1xc33HCD8tj88ssvaNasGTp27Kj2rVq1CuPGjcP111+PNm3aIDo6GkePHq3Q+RlQ7OJItPm+fftKTy2s371oMb961qBiZkzprjXRFWptHNTaOKh1yakp8dx8++236rWVpk2bYsaMGSqzbNu2bbjtttsqrBlTwc2MSgd3A84dBFLPFvHc5OUZd8MJIYSQ4khBw5o1ayqDTwwYK++//74KOpYpPJm+Gjx4cIFXx5lhzI1R+NUAIlsC8buU96ZZs2vh4+mOCxdzcPRcGhpFGDsfSQghhFiR4OGTJ0+W2lphyZIlRbaNHz++yPuKTlMZAT03Oj8cMTExal0q1lYMcWvg5eGOVrW1ctQs5mcHrYluUGvjoNbGQa2NQwKKvb29Dc2W4l3VEQ8PD3To0EGtS6WgieZatbLWu9nKYn76a010g1obB7U2DmptHGLU+Pv707hxVSTqXio4lhl9H36Ftk4+rlbt8oOKmTFlB62JblBr46DWxkGtjUMCidPT0xlQ7KpIBLkUNiozkjwgXFunn5ODC4KKd528gOxcRuzrqjXRDWptHNTaOKi1cYhRI3VxaNyYFf8wbW3JBTKT0SAsAEG+nsjMycO+0ymOvjpCCCFVxMgvcDNi0Uk/GjdG4ukDeAdpr9POwd3dDW3zm2juPnnBsddGCCGk0lhjdypSuZeURKavBC8vL1QFpoLriETdS2XHS0bfB4QBWSna1BSaIDrYT20+l8b/ELprTXSBWhsHtXZdraWdgwTNnj17Vn0x8x6W9MZIIb+ygoqtcTnx8fGqh1VVA71p3OiI3IzmzZtffmrq/FEgPUG9DfXXrNOkDBo3umtNdIFaGwe1dl2t5Uu7Vq1aOHLkCGJjY3U7b3UjNDRUtXioKjRudCQnJwfr169Hly5dlBVfKv42QcVyI/004yY5Pduw66w2WhNdoNbGQa1dW2up5SLtCjg1VVLrHTt2qN5Ul9JaPF56pebzf4+OiFtNXJKXDIiyBhWnaZ6bkHzPTXIGjRvdtSa6QK2Ng1q7vtYyHSWNKEkh2dnZarrJx8enyrE05YWTgkYjMTc2npuQfM9NEj03hBBCiLmMm7feekvNWT7++OOXPG7atGlqnlQsY3FxzZkzBy6F1XNjnZby91brJHpuCCGEEPMYNxs2bMAXX3yBtm3bXvK41atXY/To0bjnnntUZcmRI0eqZefOnXAGZK6wffv2l54ztMbcWKelCmJuOEeru9ZEF6i1cVBr46DW5tba4cZNamoqxowZg6+++kq1Vb8UH374IYYMGYJnnnkGLVq0wMSJE1Xr9Y8//hjOgMy11q9f/zKp4GUEFNNzo7/WRBeotXFQa+Og1ubW2uF3VVqnDxs2DAMGDLjssWvWrClx3ODBg9V2Z4kIl9bwsr78tFTRVPC0rFxk5bAMuK5aE12g1sZBrY2DWptba4dmS02dOhWbN29W01Ll4fTp04iKiiqyTd7L9rKQokGyWLlw4UJB9LYsgliT4i6TBmq2fUas2+WG2EbUyzbZV3y7fDYlJaVEDw1r6pu6sd4hEHPGIp4biwWBPoW34FxKOsIDtWhyOZdtQzeJR5LzlLW9rGuv6pis261alTqmcmzXe0yisVVrOd4MY3LW+yTHiNayzfZnuvKYnPU+2T7X8jkzjMlZ75Ncr2gt780yJttrz3GiMVl/h1if66qMyemNm2PHjuGxxx7DwoUL7Zo2N2nSJLz22mslti9YsEBVkxRiYmLQoUMHbN++XTVSsyLVKyV4WWohSMqgFZk7FBfbihUr1A2z0rlzZ7VeunRpkZvQt29f+Pn5qeBnz5w0DJObnpWG7IupyMi2wM/DgoxcN/w1fzHqBHkqT1ZCQkIRj1RQUBD69eundNu6dWvB9oiICHTv3h0HDhzAvn37CrbrNaZu3bohMjJS6VXWmGwZOnQoMjIylAZW5OG215jk+THbmJztPgUGBqr1iRMnVK0KM4zJWe+TPM+CdW2GMTnzfbJipjE54306dOhQkee6smNatWoVyoubxUEFFf744w9cf/31RQKMxIoTS08sNPG2FA8+EkGefPLJIhlVr7zyijrXtm3byu25qVevnro5wcHBuntu5s2bh4EDBxbJ5S9iActfY2/VglteDixP7AKC66DX20tx7HwGfr2vCzrGhNLaL8eY5J7KfxTRWmonmGFMznqf5Bj5hSjxbrZz5q48Jme9T/JlYn2u5brNMCZnvU9yvaK1fInL+cwwJme9TxcvXsT8+fMLnuvKjikxMRFhYWFITk4u+P52OuNGLMriJarvuusuZbU999xzaN26dYnP3HLLLar3xF9//VWwTaxCybL6/PPPy/VzxbgJCQkplzgVRW6SGE3h4eGXDpx69wog9QzwwAqgVjtc9/FKbD+ejG/uvBL9WxSddiNV1JpUGWptHNTaOKi162ldke9vh01LiRuruAETEBCgrDLr9rFjx6JOnTpqakmQaazevXvjvffeU64xidnZuHEjvvzySzgDctPE7XdZJB1cjJtihfyYMWUHrUmVodbGQa2Ng1qbW2unNldlLu7UqVNFvDRTpkxRxky7du0wffp0NSVVmpfHEYi7b/bs2SXcfiXwr6mt01il2O5akypDrY2DWhsHtTa31k7VW2rZsmWXfC/cdNNNanFWyhXNXVDrpnhncP4nqwhM4TQOam0c1No4qLV5tXZqz41pKdYZnFWKCSGEEP2gceMIinUGD/XT+ksx5oYQQgipOjRudERS3qRmgDWFrrwtGEI4LWU/rUmVodbGQa2Ng1qbW2saNzojxZAuizWguNi0FAOK7aA10QVqbRzU2jiotXm1pnGjc8CUVHm8bOCUf+nNMy/Qc6O/1qTKUGvjoNbGQa3NrTWNG2eIufHXYm44LUUIIYRUHRo3jsAac5ORKKUbixTxc1DBaEIIIcQ00LhxBH75MTeWPOBiUkGdm9w8C1Iz6SIlhBBCqoLDeks5Cnv2lhIpZU5RIsKlYdglmRQDZCYD4zcAEVeg2f/NRWZOHv55ti/q1dS6lROdtCZVglobB7U2DmrtelpX5Pubnhudka6+5SIgrGhQcb73hrVu7KA1qTLU2jiotXFQa/NqTeNGR8QyXbp0afkiwq1BxfktGNg8045akypBrY2DWhsHtTa31jRuHEWJdPD8jCnWuiGEEEKqBI0bJ0kHL6xSzP5ShBBCSFWgcaMz5S4vXRBzk6hWrFJccVg23TiotXFQa+Og1ubVmndWR7y8vDBs2LDyHVws5oZViu2oNakS1No4qLVxUGtza03PjY7k5eUhPj5erSscc2OdlqLnRn+tSZWg1sZBrY2DWptbaxo3OpKbm4s1a9aodbmrFFtjbqzTUoy50V9rUiWotXFQa+Og1ubWmsaNoyiYlsrvDJ7fX4qp4IQQQkjVoHHjJMaNNeaG01KEEEJI1aBxoyNSVjooKKh85aWtxk12OpCVziJ+9tSaVAlqbRzU2jiotbm1Zm8pRyGy/zsSyM0CHt+J2Nya6P3OMvh7e2D360Mcd12EEEKIE8LeUg5CIsFjY2PLFxEuFqxNOri1QnF6Vi4ycxjgpqvWpEpQa+Og1sZBrc2tNY0bHZFI8K1bt5Y/ItwmHTzIV7qlam85NWUHrUmlodbGQa2Ng1qbW2saN47Ev6a2TjsHd3c3BPvmx90wqJgQQgipNDRuHElA6YX86LkhhBBCKg+NGx2RSPCIiIjyR4QXTEsVbcHAdHA7aE0qDbU2DmptHNTa3Fqzt5TOjcG6d+9e6c7gwQVVimnc6K41qTTU2jiotXFQa3NrTc+Njkiw1N69e8sfNFXQGdw6LcUqxXbTmlQaam0c1No4qLW5taZxoyOS5rZv377yp7uVUaU4OZ39pXTXmlQaam0c1No4qLW5taZx40iKdQYvbJ5Jzw0hhBBSWWjcOJJiMTfMliKEEEKqDo0bHXF3d0dMTIxaVygVPOM8kJdb6LlhtpT+WpNKQ62Ng1obB7U2t9bMltIRDw8PdOjQofwf8KuR/8KiDBxOS9lRa1JpqLVxUGvjoNbm1pomq45IJPiWLVvKHxHu4QX4hmqv088VZEtdoHGjv9ak0lBr46DWxkGtza01jRsdkUjwuLi4ikWEW6em0hIKYm6SmC1lH61JpaDWxkGtjYNam1trGjeOpkhn8MKA4rw8i2OvixBCCHFRaNw4GptaN9YKxWLXpGTmOPa6CCGEEBeFxo2OSCR4s2bNKhYR7hOkrTNT4evlAV8v7bOMu7GD1qRSUGvjoNbGQa3NrTXvqs4R4c2bN1frcuMdqK2zUtUq1E8LKmY6uB20JpWCWhsHtTYOam1urWnc6EhOTg5Wr16t1uXGJ9+4ydSMm8J0cAYV6641qRTU2jiotXFQa3NrTeNGRywWC86ePavW5cY7f1oqK0WtQlil2H5ak0pBrY2DWhsHtTa31jRuHE0xz401Y4rTUoQQQkjloHHjaIrF3Finpei5IYQQQioHjRsdkWCp9u3bVyxoyuq5yUpTKzbPtKPWpFJQa+Og1sZBrc2tNXtL6YikudWvX79iH7LG3GRqMTfWFgysUnxpKqU1qRTU2jiotXFQa3NrTc+Njkgk+JIlSyqXLZU/LWUt5MeYGztoTSoFtTYOam0c1NrcWtO40RGJBE9JSalgtlRA6QHFnJbSX2tSKai1cVBr46DW5taaxo2jKV7ELz/mhhWKCSGEkMpB48bRWNsvZKcDebmsUEwIIYRUERo3OiKR4N26datc+wUhK5Wp4PbUmlQKam0c1No4qLW5tWa2lM4R4ZGRkRX7kKcP4O4J5OWouBt/n3C1OSM7F7l5Fni4u9nnYquj1qRSUGvjoNbGQa3NrTU9NzqSnZ2N2bNnq3W5cXMrEncT4F1ob4qBQ3TUmlQKam0c1No4qLW5tXaocfPZZ5+hbdu2CA4OVou4rebOnVvm8ZMnT4abm1uRxdfXF85EpVLdrHE3manw9XJX9o6QnsUUxUvBFE7joNbGQa2Ng1qbV2uHTkvVrVsXb731Fpo2bapSxL7//nuMGDECW7ZsQatWrUr9jBhB+/btK3gvBo7LU+C5SVHj8ffyQFpWLtIzc4F8u4cQQgghLmDcDB8+vMj7N954Q3lz1q5dW6ZxI1/+0dHRMBXFWjD4+3hqxk0Wp6UIIYQQlw0ozs3NxbRp05CWlqamp8oiNTVVlXHOy8tDx44d8eabb5ZpCAmZmZlqsXLhwgW1lrk/6/yfBDtJFLdcg5zXinW7uNNsiw/JNtlXfLts69u3r9pmO7fo6elZqlvOut3iFaDmB3PSk2DJzoa/txZRfiH9IrKz/QqMOjlerk+u04p1e1nXXtUxWbcXnyu93JiKb/fy8irz2iszJrnGq6++Wq3lvRnG5Kz3SZDnuvj5XXlMznqfbJ9rOcYMY3LW+yTr3r17q/OYZUy2157jRGOSte1zXZUxuYxxs2PHDmXMXLx4EYGBgZg5cyZatmxZ6rHNmjXDt99+q+J0kpOT8e6776J79+7YtWuXmuIqjUmTJuG1114rsX3BggXw9/dXr2NiYtChQwds374dcXFxRX5e8+bNsX79epw9e7ZguzQAEwNrxYoVquqila5du6JmzZrq3LY3Qb4Y/Pz8MGfOnCLXMHToUGRkZCA1MRW1AezavA7HT4XC3ztY7V++ai3O7NJucFBQEPr164djx45h69atBeeIiIhQGhw4cKDIdJ1eY5J7I1HuFR3T0qVLC7bJwz1s2DAkJCRgzZo1Bds5JtcZk/xikjFt27bNNGNyxvtUPObQDGNy5vvUpk0bhISEmGpMznqf9u/fX+UxrVq1CuXFzeLg2tNZWVlqcGKsTJ8+HV9//TWWL19epoFji1iALVq0wOjRozFx4sRye27q1aunbo7E7+hpGctn582bh4EDByrrttyemxkPwH3Hr8jt9y/kdXsUt369AZtiz+PjW9thcKuoamvtX2pMck8XLlyotPbx8THFmJz1Pskx8gtxyJAh6meYYUzOep/ky8T6XMt1m2FMznqf5HpFa/kSl/OZYUzOep8uXryI+fPnFzzXlR1TYmIiwsLClL1g/f52Ws+Nt7c3mjRpol536tQJGzZswIcffogvvvjisp8VkcT6O3jwYJnHyBefLKV91tYAsQpYWpEh602+3HbrQ1Paua3bS8PNV7tJHjkZ8PDyKpiWknji4p+RG2z7BXO5a6/qmC537RXZXta1V2ZM1vPL2nqMq4/JFe5Tace7+pic8T4V/x1ihjGVZzvHZN4xlfZc6zUml6hzI1acraflUojVJ9NatWrVgikCivObZwbk17pJZ50bQgghpMI41HPzwgsv4JprrlHzbzI3OGXKFCxbtky5r4SxY8eiTp06Km5GeP3111Vci3h6kpKS8M477yA2Nhb33nsvzJIKLlg9N+mZrMFACCGEuJRxEx8frwyYU6dOqaAuCRS2zssJEotj6+I6f/487rvvPpw+fRo1atRQ01irV68uV3yOEYjLTOZvK+I6K17ET/D3yTdumAquv9akwlBr46DWxkGtza21Q+/qN998c8n94sWx5b///a9anBkJCJTI8Qph035B8LdOS7FCsf5ak0pBrY2DWhsHtTav1k4Xc+PKSIS3pM1VuMx0sZgb67SUFPIjOmtNKgy1Ng5qbRzU2txa07hxBryLVSjON24yaNwQQgghFYbGjTNgjbkpCCjWpqXSGFBMCCGEVBgaNzpTqYAp72Kp4PkBxRlMBb8kDAQ0DmptHNTaOKi1ebV2eIVio5EKxZKZVZ4Kh4ZxPhb4sC3g6Qv83xnM23kaD/60CR1jQjHj4R6OvjpCCCHEpb6/6bnRuQChpLfblpOu0LRUzkUgN6fAc8NUcDtoTSoMtTYOam0c1NrcWtO40RGpmCzNxIp3VC73tJSQlVJYxI/Gjf5akwpDrY2DWhsHtTa31jRunAFPb8DDW3udmco6N4QQQkgVoHHjLNgU8gsoMG74FwUhhBBSUWjc6Ii0d5cKjLKuMDaF/PxspqXy8qpVvLcxWpMKQa2Ng1obB7U2t9bMlnIWPu0OxO8C7piJ9Hq90PJfWvPQXa8NRoAP0xUJIYRUby4wW8oxSCS4dCmvVES41XOTlQZfT81zI3Bqyg5akwpBrY2DWhsHtTa31jRudEQiwbdu3Vq5iHCbQn7u7m42GVMMKtZda1IhqLVxUGvjoNbm1prGjbPgU1ZncP7HI4QQQioCjRtnocBzY+0vRc8NIYQQUhlo3OiIRIJHRERULiLcJhXc1rhJy6TnRnetSYWg1sZBrY2DWptba6bh6NwYrHv37pX7sE0quMAqxXbUmlQIam0c1No4qLW5tabnRkckWGrv3r1VCyjO99xY0785LWUHrUmFoNbGQa2Ng1qbW2saNzoiaW779u2rZCp4UBkxN/yPp7vWpEJQa+Og1sZBrc2tNY0bZ6FEzA09N4QQQkhloHHjLJQRc8OAYkIIIaRi0LjREXd3d8TExKi1XtlSGdk0bnTXmlQIam0c1No4qLW5tWa2lI54eHigQ4cOlfuwNeam2LRUWianpXTXmlQIam0c1No4qLW5tabJqiMSCb5ly5Yqt18QAnzyPTcMKNZfa1IhqLVxUGvjoNbm1prGjY5IJHhcXFzlIsK9A4p4bvysnhsGFOuvNakQ1No4qLVxUGtza03jxtkCinOzgJwsBDAVnBBCCKkUNG6cBe/8mBshK5V1bgghhJBKQuNGRyQSvFmzZpWLCPfwBDx9tdeZKQwotqfWpEJQa+Og1sZBrc2tNbOldI4Ib968eeVPIEHFOReV5yYgP3uKqeB20pqUG2ptHNTaOKi1ubWmyaojOTk5WL16tVpXtZCfn5fVc0Pjxi5ak3JDrY2DWhsHtTa31jRudMRiseDs2bNqXaW4m6wUm1Rw/sezi9ak3FBr46DWxkGtza01jRtnwtZzYw0ozs5FXh7/8xFCCCHlhcaNM1HQgiENAfkBxWLoXszh1BQhhBBSXmjc6Bw01b59e7WukucmS2JuCs/BdHA7aE3KDbU2DmptHNTa3FozW0pHJM2tfv36lT+BtUpxZgrc3d2UgSPZUukSVJxv9xCdtCblhlobB7U2Dmptbq3pudERiQRfsmRJ5SPCCwKKi/aXSs9mULHuWpNyQ62Ng1obB7U2t9Y0bnREIsFTUlIqHxFuE1AsWIOKmQ5uB61JuaHWxkGtjYNam1trGjdOGVCc77nJDypOZzo4IYQQUm5o3DgTBZ6bFLUqSAdnQDEhhBBSbmjc6IhEgnfr1q3yEeHFY27oubGf1qTcUGvjoNbGQa3NrTWzpXSOCI+MjKz8CYrF3LAzuB21JuWGWhsHtTYOam1urem50ZHs7GzMnj1brfWIuSkwbhhQrL/WpNxQa+Og1sZBrc2tNY0bnalSqltxz41PfvNMTkuVClM4jYNaGwe1Ng5qbV6tadw4E8VibvzzqxRncFqKEEIIsa9x8/333ysXk5Vnn30WoaGh6N69O2JjYytzSmJboViMG4uFnhtCCCHEKOPmzTffhJ+fn3q9Zs0afPLJJ3j77bcRHh6OJ554AtUVT09P9O3bV62rNC2VlwPkZCKAAcX205qUG2ptHNTaOKi1ubWu1E86duwYmjRpol7/8ccfuPHGG3H//fejR48e6NOnD6ozVqOvSgHFQlYqA4rtqTWpENTaOKi1cVBr82pdKc9NYGAgzp07p14vWLAAAwcOVK99fX2RkZGB6hwwNWfOnMoHTrl7AF7+2uvMFPjn17nhtJQdtCblhlobB7U2Dmptbq0r5bkRY+bee+9Fhw4dsH//fgwdOlRt37VrFxo0aKD3NVYvxHuTnZ7vuQlXmxhQTAghhNjZcyMxNlJt8OzZs/j9998RFhamtm/atAmjR4+uzClJKenghQHFNG4IIYQQu3puJDPq448/LrH9tddeq8zpSBmF/KwBxRmcliKEEELs67mZN28eVq5cWcST0759e9x22204f/58uc/z2WefoW3btggODlaLeIPmzp17yc9MmzYNzZs3V/E9bdq0UfN4zoJEgssUXZUiwn3ya91kphQ0zqTnxk5ak3JBrY2DWhsHtTa31pUybp555hlcuHBBvd6xYweeeuopdeFHjhzBk08+We7z1K1bF2+99Zaaztq4cSP69euHESNGqNid0li9erWa9rrnnnuwZcsWjBw5Ui07d+6Es1DlgOoinpv8xpmZ9NyURnUOXjcaam0c1No4qLV5ta6UcSNGTMuWLdVribm59tprVe0b8eBczvNiy/Dhw5VR1LRpU1xxxRV44403VCbW2rVrSz3+ww8/xJAhQ5Rx1aJFC0ycOBEdO3YsdYrMEUgk+NKlS/VpwZCVVpgKnp0Li8Wi01WaA120JuWCWhsHtTYOam1urStl3Hh7eyM9PV29XrRoEQYNGqRe16xZs8CjU1Fyc3MxdepUpKWlqemp0pCCgQMGDCiybfDgwWq76aoU2wQUi11zMTvPsddFCCGEuAiVmgDr2bOnmn6Son3r16/Hr7/+qrZLWrhMNVUEmdYSY+bixYvKazNz5swCr1BxTp8+jaioqCLb5L1sL4vMzEy1WLEaX9Kd1NqhVNqxe3h4KAMrL6/QiLBuF2vT1nMi22Rf8e3WzxbvfGqdZyxutZa23d3TH+KvsWRegCcKr+VCRib8vP3Vz5DrtOLm5qbOU9a1V3VM1u1VGZPg5eVV5rVXZkzW65G1WcbkrPfJeoxstz2/K4/JWe+T7XNtljE5632yvV6zjMn22nOcbEyCHt+5djVuZBro4YcfxvTp01VQcJ06ddR2mZKSaaOK0KxZM2zduhXJycnqfHfeeSeWL19epoFTUSZNmlRqFpcUH/T31wrmxcTEqJo927dvR1xcXJFrk+BlMeAk7d2KBE/Xr18fK1asQEpKSsH2zp07qxtZ3P0mZaelOmPx4GeZkpN5SDneSosz8bhC5ieTE7Bw3lx4uXsgO88Ny/5ZjVuuHaCqQ4teViIiIlRPrwMHDmDfvn0F2/UakxiekZGRSq/Kjkk0GTZsGBISEop42YKCglScVVXGtHDhQtONydnuk/zRIftOnDih/hgxw5ic9T7J8yxY12YYkzPfJ/nCFMw0Jme8T4cOHSryXFd2TKtWrUJ5cbM4WTCHTDs1btwYX3zxRYl9Ioh4jB5//PGCba+88opqAbFt27Zye27q1aunbo5kaDmbZey+9mN4LH4VljY3I+e6T3HVW0uRmJaNOY90R8s6Naqdtc8xcUwcE8fEMXFM7u7uSExMVHX1xBli/f4ui0rnZclFiVGxZ88e9b5Vq1a47rrr1EVUBRmorTFii1ieixcvLmLciCVYVoyO4OPjo5biyA2SxRa59tKuv6z0teLb5drj4+NVA1HrXwTFf2ZpFNnuF6JWbllparu0YBDj5mL+8yLnLe3cZV17VcdUoWu/zPayrr0yY5L/NGKg2mrt6mNy1vtk+1yXdrwrjuly2x01Jjl38efa1cfkrPdJnmur1mYZU3m2ezlgTPL7WsrEFH+u9RqTbgHFBw8eVNlKY8eOxYwZM9Ry++23KwPH6n4qDy+88IJynR09elS5u+X9smXLMGbMGLVfzi/brDz22GOqxs57772HvXv34tVXX1Up5BMmTIAzIAafuOpsLdcK451f5yZLcycGFKSDs9aN7lqTckGtjYNaGwe1NrfWlTJuHn30UTV1JPNrmzdvVovMmzVs2FDtKy/y16AYMDLP1r9/f2zYsAHz588vaMQp5zx16lTB8TJ3N2XKFHz55Zdo166ditER71Hr1q1hxvYLgr9Pfjo4qxQTQggh5aJS01IS8Cu1aCT124rMg0lBPsmgKi/ffPPNJfeLF6c4N910k1pMi00RP6Gg1g2rFBNCCCH289xIDIttFLaV1NRUVQOnuiLzihI1LmvdPDfWaSkaN/prTcoFtTYOam0c1NrcWlfKuJGKxPfffz/WrVunIpplEU/Ogw8+qIKKqysS7CTpcFXqn2GNubmYBORm23huOC2lu9akXFBr46DWxkGtza11pYybjz76SMXcSJaSNLCUReJhmjRpgg8++ADVFYm+j42NLZLaVmFCY4CASCA7Hdj5e4HnJo0BxfprTcoFtTYOam0c1NrcWlfKuAkNDcWff/6pKhJLUK8s8lqqC8u+6opEgksBoypFhHt6A10f0l6v/C/8vTQ3Xno2PTe6a03KBbU2DmptHNTa3FqX20d0uW7ftlUM33///apdVXWn8z3KsMHZvWgbthpAHaaCE0IIIXobN1u2bCnXcQzO0gHfEKDzvcDK99H15PdSEYgBxYQQQojexo2tZ4aUbdhJLw1dDLyuDwNrP0XUhZ3o5r4b6Vm19LhE06Cr1uSSUGvjoNbGQa3NrbXT9ZayN9JbKiQkpFy9KRzO7KeBDV9hRW4bfN3wffxwdxdHXxEhhBDi9N/flQooJqUjwVLSFkK3oKnujyDPzQO9PHagVprWw4vYSWtSJtTaOKi1cVBrc2tN40ZHJM1NWtXrlu5Woz7i6w9XL4dfmFq4/WIycGwDcP4oqiu6a03KhFobB7U2Dmptbq1ZvcjJOdvuIUQf/QPds9cAP4wEEvYDF04UtmoYvw4IqevoyySEEEKcBnpunBy3yBZYkNsJ7rAAh5cWGjYePlr/qSX/dvQlEkIIIU4FPTc64u7ujpiYGLXWiwAfT7yUfTcOuDfC+Ot6AhEtgIhmQOIh4Kt+wLapWmZVrbaoTthDa1I61No4qLVxUGtza81sKSfnzIWLuOrNxXB3Aw69ObRoKt30u1WLBjTqA9zxh+TbOfJSCSGEELvBbCkHIZHgUuxQz4hwa+PMPAuQmVMsGKv/vwAPb+DwMuDg4pIf3jcX2DQZMKH9ag+tSelQa+Og1sZBrc2tNY0bHZFI8Li4OF0jwq2NM4USVYprNAC63K+9XvgykJe/PycT+PsJ4Jdbgb8e07w7JsMeWpPSodbGQa2Ng1qbW2saN06Oh7sbfDy125SWWUrzzF5PA76hQPxuYOvPQNIx4LtrgI3fFh6z6DUg+6KBV00IIYQ4Dho3LoAEFQul9pfyqwH0ekZ7vfh14MvewIlNmsFzy09AcB0gOQ5Y/4XBV00IIYQ4Bho3OiKR4M2aNdM9ItzPS4u7Sc8qxXMjdLkPCK0PpJ0F0s8BtdoBDywHWgwH+v2fdsyK94C0czAL9tKalIRaGwe1Ng5qbW6teVd1xMPDA82bN1drPQnwsRo3ZQRjefoAw97Tuol3vBO4e74WjyO0vQWIbgNkJgMr3i76OZmqmvsc8O0Q4HwsXAl7aU1KQq2Ng1obB7U2t9Y0bnQkJycHq1evVms9sQYVl2ncCE0HAs/FAtd9BHj5FW539wAG5Rf62/A1cO6Q9lpaN3w7CFj3ORC3BvjjYYn6QnXXmpSEWhsHtTYOam1urWnc6IiUDDp79qxa64k1HbzMaSkrZdW5kTo4TQcBeTnAoleA/QuAL3oDp7YB/mGAVwAQuxJY9xmqu9akJNTaOKi1cVBrc2tN48YFsHpu0jKrUCNg4OuAmzuw5y9gyk3AxSSgTifggRXAoImFWVVn95X8bPxeYMM3QFZ65X8+IYQQYhA0blyAcntuLkVkC6Dj2ML3ne8F7pqrNd288m6gcX8gNxOY+QCQm60dI1b22s+BL3oBs5/U9rnQ1BUhhJDqCY0bHZFgqfbt29stoPhCRr7RUVkGvKoV/btpshaALIHI1umsER9rAckntwD/vAekxgM/3wTMe04zeoQ9s0oGJVsRr87RlUBujktrTUpCrY2DWhsHtTa31uwt5QJ8u/IIXv97N8IDvbHoyd4I9fe2zw/aPg2YcS/g7qnVyUlP0LqPD34D8PQFZk3Qjrv5B6DliMLPnd4JTL8LSNgPtBwJjPpOcv9K/xlZaYB3gH2unxBCiGlhbykHIZHgS5Ys0T0ifEzXGDSJDERCahbenLMHdqPNKM1okcBjMWwiWwL3L9Pq6HS8Q+s+Lsx8EDi9Q5u22vgd8HV/zbARdv8BLHm95Lnl2EWvApPqAvNfKvsapIXEgYVAxnmHaE1KQq2Ng1obB7U2t9Y0bnREnGApKSm6R4T7eHrgrRvaqNe/bTyO1QcTYBdkemrYf4Hm1wI9HgPuWwJEtSzcP3Ai0KgvkJ0O/HKb5q35+3Eg5yLQZCAw5C3tuJX/BTZ9X/g5ieERg0i2W/KANR8Dm38o+fNFt1mPAj+P0mrvZGcYrjUpCbU2DmptHNTa3FrTuHERrmxQE7d3jVGvX5i5Axez7dRdNSAMuPVnLbvKtl6O4OEJ3PQdULOR1tJh10xtCkuOve03oOtDQK9ntWOlceehJUBmCjDlZmD7VMDNA2g2VNs/+yng2PrCc8tDv+D/gK0/ae/P7gUW/qv0a0w+AY9pY9Hw7EK7SEAIIcS1oXHjQjw7pDmig30Rey4dHy4+4JiLkF5Wo6cCARFAaIyWcSVeHmuMTd8XgTY3A5Zc4Lc7gW+v0YwcL3/gtl+BW37W2kLkZgG/3gFcOKV9Trw64tERJHtLWP+lNkVlS1oC8ONIuO+fg7bHf4Tb0X+MHD0hhBAXgAHFOiLt3BMSEhAeHm63HhoLdp3G/T9uUt3CZ03ogVa1Q+AQZMpIgo1LG2dOJvDDSCButfZeCgXeNg2o20l7n5kKfDNQ62Ret7NmDM3Nb/456A2g+wStLYRUTw6IBB5aDQRGABeTge+Hq+KDFjd3uFnyYAmpBzfZ71vKvZTjPbxLeqCI0z3XRINaGwe1dj2tGVDsIOSmRUZG2vU/yqBW0RjaJhq5eRY8PW074lMuwiGIwVDWOCXFXKa2pEhgVGvgnoWFho3gE6jtl4ys4xsKDZueT2qGjTVtPaIFkBYPzHpESzWfcmt+VeVwuEk8UGh9uCUfAxaUEqAsxQrfbQZ82g1IT7SHAtUGI55rokGtjYNam1tr3lUdyc7OxuzZs9Xanrx6XSuE+nthz6kLGPrhP1ix/yycDv+awL2LgQdXAmGNS+6XuJ1R32pVk4VOdwH9/1XUeLrxa83zsn8u8HkPzRPkEwzcMQPZEa2xJmosLHDTgpOlpYSV9V9pU145GcD5I8Dv92pZWMSpn2tCrY2EWptbaxo3OmNEqltkkC+mPdANzaODVHr42G/XY9LcPcjOdbLqwZJ9VVa/K6FJf2266pp3tKKCxY+Nbg30f0V7nXgY8PTTApdrtVOb4v2bIq/LA9p+8e6Ih2bx68CcpyVCGWh1vfaZQ4uBFe+U/PnSFX3ZW8Dyd1h5+TIwXdY4qLVxUGvzak3jxkVpGhWEP8b3KMig+mL5YYz6fA2OJbpY/6emA4Cr7te6l5eG1NZpcR3gEwLc8hNQv1uR3Xl9XgLCmgKpp4HPumvVlYW+L2nFBId/oL0XI+bAosIPSnf0bwYAyyYBS/8NzH9By9gihBDi8tC4cWF8vTzw75Ft8NmYjgj29cS2Y0m49n8rsdwZp6kqi8zRSkXkZw5ohlBxZPrq+s+16a2UU1q6+fCPgN7Pap6gdrfmZ19ZtOrLSXHAjulavywpRCgtJwQJXrYaRrZIMcG/HgOmjgHSztl/vIQQQqoMs6XsUKgoKCgIbpeajrEDx8+nY/yULcrAkR/91MAr8HCfJnB3N/Y6jKKE1tLgc8PXwKB/A82GlMze+naw1jfLP1yrvizU76nF9UhV5XnPa9uGfwh0Gqe9PrgY+HMCkHJSex/dBhg7S4snKk7sGuDMTu2zHl4wE458rqsb1No4qLXraV2R728aNzoiUsq8oqenp0P+s2Tm5OLVWbvxy/o49X5gyyi8d3M7BPua68u2UlqfjwW+7J3f1sEN6PUM0Ps5rTChsOg1YOX7mgdo5OfA8fWasSTUbKwVI5TMrei2wNg/Cw2cnCxgyURg9Ufae+mtdeM3hee1RWKCxFvU4OqyM82cEEc/19UJam0c1Nr1tGYquIOQmzdnzhyHBalJm4ZJN7RRrRq8PdyxcPcZXPe/lVh72HzTKRXWukZ94NZftNYSd8wE+r1U1ACRTK0Od2jtIWbeX2jYSBd1yfi68y+tcOHp7cCP12tGksTtfDuo0LCRKTHxAv35cMnsrNjVwKddgR+uA+Y+61LxPY5+rqsT1No4qLW5taZxY0Ju7RKDaQ92Q+0QXxw9l45bv1yLZ6dvw/m0LFRrJBhZ6us07ltyn/w1ce0HmvEjBNUGbp8BDH0H8PYHIptrBo5Ma53aqvW+krgdmeqSej1SeVlig8TA2f6r1nNLMrDEiFn9MTD5WiD1jHbuDV8Bq/IDnYtzeLk2FZZw0I5CEEKIuSnFd07MQLt6oZj7WC/8Z/5eTFkXpxpuLtoTj5evbYGR7evQDVsaqnfWZODIcqDOlYBfaNH9kS2AO2dpVZKl95VQvwdww5dASF3t/Y1faXV1pPaO9N2SqSjx5ghtbgKiWmnd0WUJqqUFPAvi6ZF0dcnqkuBnMXLuXQQERRmpACGEmAJ6bkxMiL8X3ry+DaY/2A1XRAUiMS0LT/y6DXdP3oCE1ExHX55zIsHATQaUNGysiHEiQcUNe2s1eMSbYzVshNY3AiM+1eJ6Nn6rGTbuXsDQd4EbvgJ6PgF0y6/C/Od4re+W9Mv66UYtLV0MGylUKI1Jf7lVq8xcHJkOW/JvbU0IIaQEDCiuJgFqWTl5+Oqfw6rhprwOD/RRwca9r4iAK+LMWis2TdZSyGV66+bvgXpdCvfJdJWkpe/8HfAOAnyCtIwsKTh47X+1Y78eAGQkatNkMt0ldYDkv+qm74D5LwHZ6UBgNHDPfKBGg+qttYmg1sZBrc0dUEzjppqlFu47nYJHftmM/WdS1ft7ezbEM0OaqWBkV8IVtEbiESAwEvAOKLlP0tPFW2Ptah5+BXDT90BUy8LUcgk+lu7pXcdrnddnTQAO5LeZEENI2ktIG4u7F2iNRW1JPqEZQs2GAnU6ml9rk0CtjYNamzsVnNNSOiKW6dKlS506+r5ZdBBmTeiJsd3qq/dfrzyCGz5djS1xkiLtOriC1qjZsHTDxtpcVCouS/XlK+8B7ltaaNhYg59Hfqa9XvsJ8L9OmmEjndgHvwk8sgkIidHaUvx0A3Dxgnas8u5M1jKzJIZHApnj1plfa5NArY2DWptbaxo31bSy8esjWuOrsVeihr8Xdp28gOs/XY0nft2KU8kZjr686oPE9dzyI3Dt+1qn9OK0GVXYTDQrBYhqA9y/DOg2HgipA4z9Q8vekvT0qbcB8Xu1YGeZDsu8oMXuZKcBP48CTmwuef59c4FPugJznmVvLUKIqaBxU42RIn/zH++FUZ20gNiZW06g37vL8eGiA8jIYhdtp6Dnk1pj0YETgfsWF/XuSLf12/PjdmR669OrtLVMWYl358ndWjaXGDpSm0cKCAqSwTXjfi1g+eweYP0XWrPR0mao8/LgtmcWQtMYvEwIcR1o3OiMBEy5EpHBvnj3pnaYNaEHrqxfAxnZufjvov3o994y/L7pOPLynDcky9W0rhQyPy2NRXs8qk1lFad2e2D0FMDDW3sv1Y8fXq15dyRQ+bZfgbqdgYtJwA8jteKEn3bTavFINWbpnK4yu74BFr1S1MBJPau8Pp4z7kbPA2/ALW61ceOuxlSL59pJoNbm1ZoBxaQAeRRm7ziFSXP24kSSNj3Vuk4wXhraEt0ahzn68silOLUNuHASuGKIZhDZkiGGzQit+KAVCWCWlPV6nYGN32lFB4W+/wf0fgY4vEzz7lgLDwpSrFBq74Q3LXr+1HhgzjOa8XXdx4BnvqFFCCE6wmwpBxk3eXl5SEhIQHh4ONxdqHdQcS5m5+K7VUfx6dKDSMnUAsAGtIjEhH5N0b5eGfVfDMYsWhuGTEVJ9tWZXVqdnb4vah3Vraz5BJj/ovZaDKT987WaOxEtkDfiE+T+9SS8zmwFQusD9y4uzM46vgn49fbC5qKd7wWGldJdnZQLPtfGQa1dT2tmSzmI3NxcrFmzRq1dPeD4oT6NseyZPrija314uLup6sYjP1mFmz5fjfm7TiPXwdNVZtHaMKTRp2RkPbUfGDSxqGEjyDRWn3zjZv88zbCRDuf3LUFuVFssirgXltAGQFIs8MstWnHBzT8C3w3RDJvQGG16S6a9tvxc8udnpQF/PwH8eofWhJSUCp9r46DW5taaE46kTMICfTBxZGvc2b0BPlt2CLO2ncCGo+ex4egm1A/zx13dG+DGTnURZMKu46atvly8Ho4tvZ/V1jt+A/q+BLS+QXufnY0sr2Dk3DoVXt9fA5zYBHzWDTh/VNsvhQYlbX3tZ8CyNzUjRgKfa3fQ9icdA6aOLgxolvigG78uOX1GCCE64VDPzaRJk9C5c2dV2CcyMhIjR47Evn37LvmZyZMnqyJAtouvr69h11wdaRIZqKoZr3yuHx7u0xghfl6IPZeOV//ajW6TluCVP3fi0FmtKCBxYcTY6POcVkPHatjYEtZE66wutXaUYeOmxejc/CPgGwz0ega44hogN1Pz0EhbCSlG+GUfzbDxD9Mai+6crhUYLI09fwFLJwHZF+0+XEKIeXGocbN8+XKMHz8ea9euxcKFC5GdnY1BgwYhLS3tkp+TubZTp04VLLGxsXAGxNAyc7XLqGBfPDukOda80A8TR7RC44gApGbm4Ps1sej/3nLc8c06/Ln1hNpmb8yutTNRRGspLijtJCQr67bftOBj6xy6rG/4AqjZGEg+phUQlLo76QlAtNToWQ4MeEU7du7zWhC0FWkcuuBlLX5n+VuF8T/VDD7XxkGtza21UwUUnz17VnlwxOjp1atXmZ6bxx9/HElJSZX6GcyW0g95dFYdPIfJq49i8d4zBVnEPp7u6N8iEte2rY1+zSNVDA+pRpzZrfXGkgKCQssR2rSVVGuWYoEyRSVxPTUaAg8s17w5M+4D9s0peh7p0K5S1YshDUOPrQNaj2JmFiHViAsV+P52qpgbuWChZs2alzwuNTUV9evXVxHYHTt2xJtvvolWrVqVemxmZqZabMURxEskiyDR2x4eHirYSc5pxbpdSkbb2oCyTfYV3y5W6YkTJxAdHV0kItya31+89HRZ2728vNR12AZfybnl+LK2l3XtVR2TdbtVq+LXflWDEFzVoB2OnU/H75tPYvaO0zh6Lh1zdpxWi7+3B3o3DcfQtrXR+4pw+Hm66TImuU7Ruk6dOupYPcdkxvtUlTHJzxEPqWhd/HkvdUzhzeBx41ewzHsBee1uQ16PJ1RNHffcXG1Mwz+Gx1d94Hb+CPKm3wO3lJNwO7MLFg8f5F77Idzid8NjzUewzHoEbrU7IDuwTuHPPLwMHr/fBbesFOSe2IK8QW+a6j5lZWUVPNdynBnG5Kz/n2T/yZMnC75LzDAmZ71P2dnZOHbsWMFzXZUxuZznRgZ43XXXKY/MypUryzxOIq4PHDiAtm3bKmPo3XffxYoVK7Br1y7UratV2rXl1VdfxWuvvVZi+5QpU+Dv769ex8TEoEOHDtiyZQvi4uIKjmnWrBmaN2+O1atXK6+Slfbt26v/EEuWLFHNwKxI/NCGDRvUzbS9CX379oWfnx/mzCn6l+nQoUORkZGhem5Ykc8OGzYM8fHxaqxWxKXXr18/NQW3dWthvZKIiAh0794de/fuLRKvpNeYunXrprxps2fPLteYrrnmGmw5moAv523ClnNuSMwsNGa8PdxwRXAumoVY0CjYgmZRgRjQv7/Tj8mM96kiYwoMDFR/ULRp0wY7duzQZUw5R9ei54F/w92S/4swIBIbmz6FE2614GbJQc8Db6Jm2kGgTifMiX4M2XlAvXP/oH3ct3BH4S/PNY2eQnxIuxJj8sxJQ1jafiTW7Iih115XLe4Tx1TxMVmv559//jHNmJzxPu3atQsHDx6s8pj++usvZSe4VJ2bhx56CHPnzlWGTWlGSlmIRdiiRQuMHj0aEydOLJfnpl69eirn3iqOXpaxfHbevHkYOHCgsm6ru7Uv59l58gLm74rHgj3xOJJQNJYqyNcTnerXUJWRO9cPRevawfD2dC/XmOSeSpyWaO3j4+Myf8E443263JjkmAULFmDIkCFFPJJVHZP7hq/gseAFWKJaw230VOQE1iocU/IxeH7dB24Xk5F71cOqT5bHirfULotMR/mGwG3jN7AERCLnvuVAQEThmBJj4fnzDXBLPIS89nfAfeTHLnOf5MvE+lzLvajuz549xyTXK1rLl7iczwxjctb7dPHiRcyfP7/gua7smBITExEWFuY601ITJkzA33//rTwwFTFsBBFKLEBbq9AW+eKTpbTP2RogVgFlKW/Z6OLbrQ9Naee2bi9rDMWxuu7Ku72sa6/qmCpz7bbbOzYIV8vzQ1tg35kULN4Tj3VHErE59jxSLuZg2b6zarHG6nSMqYEuDWuibd0QNK8VjNohviWC0GQ81vPL2jo+o8ZkxvtUnmuXbaUdX+kxdX8YaD4EbiH1VJp6kRGFN9IqKP86Bh7rPi3c3uNxuPV/BcjNAuLWqCksr9mPa20m5Dk5dwhe0mYiWftr0H3rj0DrkXBvMqD0MaWegXtwLf3GVM7tl7sfxX+H8NnjmFx9TKU913qNqdRj4UDEMnvkkUcwc+ZMLFu2DA0bNqzwOcTyE1e5WN+ORr6ExQ3H6PuSiCbNo4PVMr4vkJObh72nU5Shs+FIItYfTURiWhbWHD6nFlvvTvPoILSqHYLujcNUGwipq0OtjcOuWtdsVPa+FtcCXR7QGntKH6xr3ga63Kftc/fVauV82Rc4MF8rHihNQn8cqbWMkIytuldqPbT+fAR4eI3Whd2K/LUoLSc2fw90f1QrbOgE8Lk2Dmptbq0dOi318MMPq9iXP//8U821WZFoaJkDFMaOHauCkKQmjvD666+ja9euaNKkiYrPeeedd/DHH39g06ZNaNnSpmNyGTBbyjmRx1Bq5ViNnT2nUtT7nGKVkKVacseYUPRsEoGeTcPRrm4IPD1YaNu05GQC678EarUHGl5dcr8UDpz3PODpq1VdzjgPRLYCxv4BeAcCn/cAEg8D7W8HRn5iY9g8Bmz+If8kbsA9C7U+W4QQp8VlekuVZcV99913GDdunHrdp08fNGjQQKWAC0888QRmzJiB06dPo0aNGujUqRP+/e9/q6mp8mBP40a8SBLs3LRp01JdbaRiZOXkKQNn7+kL2BR7HisPJKhMLFsCfTzQtVEYujcOR68rwtEkMshh12tWnPq5ll9fP48CDi7S3tfpBIyZrrWbEOLWAt8O0dpJSF2eJgMLPTbiDRKj6eRm1UMLD6womVqecABY9hbQ4Xagcd/qrbXJoNaup7XLGDeOwJ7GjcTcSMS5TJGVNX9JqsaxxHT8cyABK/bHY8W+00jPKWogt6wVjFGd6mJE+9qqfQSpBs91yhlgys1AaD2tno5PMQN3/kvAmo+BwGigSX9g68+aYXP9F0CTAcDHnbVCg9JywtqCwlpP57uhQOppwCcEmLABCIqq3lqbCGrtelqzcSYxLfVq+uO2q2Lwv1vb4Y0rczHzwa54/prmuLppOLw83LD71AW8/vduXPXmYtz/w0bM23lKdTknJkYMDikGeMtPJQ0bod//AWFNNSPFatiM/Bxoe7Pm4bnmP9pxK94Bzuan4Ep7ie+v0z4jZCZr019lkXIayC2ahUIIcRw0bojL4u4GtK4TjAd7N8aP91yF9S8OwOsjWqlMK4nVWbD7DB78aTM6TVyIR3/ZorqZ09CphkgszvWfa0aNxNeIYdPulsL9rW8Emg7SMrBmPQokxWltIy4cB8KvAMb8rn121wzgwMKS59/4HfBec+CHEVobCUKIw3GKVHCzIClwUpyotFQ4Yn+tawR4Y2y3BmrZdzoFMzYfx9/bT+FEUgZmbTuplkAfTwxpHY0bOtRRsTruYiER8z/Xkjl172LNSKndvug+if0b9j7wyVXAsbXAZz2AzAtaxtWdfwFB0UDXh7Wprb+fBMav1VpJCFt+1mJ4hNhVWtbWVQ9Ub61dBGptbq0Zc0NMjTzeW48lYfb2U5iz4xROJhd2m64V4osR7euo+BxJN2dKaDVn3RfA3PyYmxoNgHFzgJD81g+ZqcCn3bT6Od0mAIPfALZP03piSbCyBDKf2KRlaI1fB4QUq9clWVzzXgSiWgLdHzF+bISYAAYUOzBbavv27ao1BKPv7UtltM7Ls2BT3HnM2HwCs7efxIWLhZU364T6YWDLKAxoEaWKCEqlZFLNnmuZUhJjRaalRn0LhMYU3b9/ATDlJs370/s5YPnbgLSPuPJuYOi7WvCxeH6uGAKMnqp5hITMFEAKC57YqL2/fYYW2FydtXYCqLXrac2AYgchZaSlT4ZtOWniPFrLFFTnBjUx6YY2WP/SAHw2pqMyaKQyskxdSXfz279Zp2J0xv+8WU1rSWHB6k61ea7dPTSj5t5FJQ0b4YpBWpdySx6wbJJm2Ej9nKHvaZ8d/iHg7qV1PN/9h/aZrHRgyi2Fho3w9xNAVtFWJFYsh5chZfdi82vtBFSb57qaas2YG1It8fXywDVtaqklIysXKw8mYPGeM1i0Jx4JqZmYveOUWiQkR1pC9G0eia6NaqJNnVB6daozQ/4DHFyiZU+1uRm47iOxmrV9kc2Bq58Clr8FzHkWiOkOzHxAi8XxCQZG/wLMeABIitWMo0H/Lnru9V/Bc87T6CmtQU/3Bep1csgQCTEDNG5ItcfP20N5cGSRqavtJ5KxJN/QkdTyjbHn1SL4ermjQz2t/5UsHWJC4e/N/0bVKu38rjnAyS1Au9Gax8aWq5/UsqoS9gOfdAEuJgFeAVphwZirgGHvAb/cAqz5BJAGoNbg5m2/AnOeVi/dkQfMfgK4f2nJ81unz3IuFgY1E0JKwJgbHWHFS+MwSuuTSRlYvDceqw8mYP2RRJwrNk3l6e6GVnVC0KVBDXSqXxNt6oaU2uzTleFzXUFiVwPfXaO9lrYQY6YBDXsV7p82Dtg1E4huC9y3VOuN9esdaporr91oWHb/BY/sVGDwJKDbw0XPnXxcS1OXaa2yps9IueBzbRysUGwAzJYiVe1/tfZwojJ0NhxNxCmb7CsrNfy9VKPPVnWC0aZOCNrWCUW9mn6mMnjIZVj6JrD5R+C6/wFNB5SsqPxJZ+CiTG3dBOz+U6ux0+42YMQnWmsISS8Xj49kXknlZSEtQWslce6A9r7p4MJu6IRUAy7QuHGMcZOTk4P169ejS5cuFWrNTlxTa/mvc/x8BjbGirFzHlvizuNgfMlmn0KIn5cqLti6Tgha15Z1MGJq+ruEweMMWrsk8qu1rPsrTTtn2aSEtxgOjJqMHAuwft1adNs7EW6SeWU1YCTj6vtrgVPbgKDaQNpZIC8buOl7oNXIkuff+ot2bP+XOX1VBnyuXU/rinx/847q/GV39uxZtSbm11oME2kHIcv1HbS6JlIB+cCZVOw8mYwdJ5Kx60Sy6nCenJGtemLJYiXI1xOtagejXb1QdK5fE53q11CFCJ0NZ9DaJbmU4drhDmD7b8DRf4DG/YAbvwE8PGHJzsbZhHPIGfo+vL7qrU1ZbZsKbPlRM1b8w4E7ZwE7pgHL/wPMfU5r6OkbUnjudV8Cc5/RXkvMjtTkISXgc21urWncEKJzFpbE3cgy2qa7+f4zKdh+XAyeJOw6eQF7T6cg5WKOmuKS5QscVsc2jQzElQ1qoltj6XQehnA2/zSv4SO1cA4v05p3eha7z9L2QYKTxYD540Ftm2Rc3f47EN4U6PkksGM6kHgIWPy6Fqhs9dhYDRth7WdaD61a7UpeQ06WVtMnvIk9R0qIQ6BxQ4idkdRxNR1VR/661gJAs3Pz1BSWeHdkOktieA6dTcOB+FS1/LI+Th3XLCoI3ZuEoWeTcGXwMDPLRPgEAi2uLXu/GDA7Z2gxNhKYLMaQNbvKyxe49r/AD9cBG74B2t6qNfn8Mz8A+aqHtPcSuPzXY1rrCdvMq/REYPK1QPwurTt6u1vtPFhCjIUxNzoiBYqOHTuGevXqsV+JnTGj1udSM7Ep9jzWHUnE6kPnsOfUhSL7vT3cVfp5n2YRamkcEWhIzI4ZtXZWSmh9egewdBJw1f1Aoz4lPzDzIWDbFC1rSnUmz9IKC0ogs8TlfNxZq8kz5C2g60PaZy5e0Jp8ntysvferAYzfAARGoDrB59r1tGZA8SVgthRxJWNHpqxWHUrAiv1nVfCyLRKQ3K95JFtGVGfSzgEfXwlkJGrvW44ARn1X6KXZ+K1WEdna88qvJvDTjUDcau11QASQsE+ruTPqm5Lnl89vmqy1l6jXxdixEVIMGjcOzJZasWIFevXqxeh7O1PdtNbS0NOwbF88lu8/q7w7EstjJcjHE1dfEY4+V0Si1xURiA7x1e1nVzetHUmltJbYmxn3a7E7t/xYNH5Hyt1LzR1r5lVeDnBosRa/Ix3PpZXE1/21tRQabDqw8LNi1MiUllCjIfDQasDbH2aBz7Xrac1sKQd+AaWkpDD63gCqm9Yy/dQkMlAt917dCGmZOQUtI5bsPataRszZcVotgnQ5790sAr2viMCV9avm1aluWjuSSmndZhTQqC/gX7NkhpZMAQz/APj8ai3zSvDy1wwZa/yOxOes/UTz8Dy8VosFEoPpr8e1/R4+wPkjWluJga+X/PlSWFACmTuMAYJrw1Xgc21urWncEOKCBPh4YnCraLVIy4htx5OwbN9Z5dWR15KNJcsXyw8jwNsD3ZuEK0NHFkldJyYjIKzsfZEtgB6PAf+8qxkq0uNKWkFY6fsisOcvIDlOKz7YoKfmCYIF6Hyv5hH65VZg9cdA6xuLZl4ln9A8Q5J1tW+OVjW5tJYRhBgMjRtCXBzpdt4hpoZanhh4hepk/s+Bs1i+7yxWHBCvThYW7j6jFqFOqB+uyu+NdVWjMDQIc41igqQK9H4OCAgH6nYG6l5ZdJ94aiTz6ucbgXWfARu+0jqeSwbWNe9o3h/phi6ZV1J48N4lqiYPUs8CP47UDBtBApTXfVGyZYQVOS64bmGjUULsCGNudI4IT0hIQHh4OKPv7Qy1Lh/i1ZHmn+LRkXidLXFJJSooRwX7oFujMHRtFKbSzYtXTqbWxuFQrX+/VysOaFMxWRkxxVtGDJwIdByrVUyWbK7gOkD724AV7+S3jFhbsufV4oma50g8P6O+hTPA59r1tGZA8SVgthSpzqRn5WBzbBLWHTmHdYcTsfVYErJyCwOThehgX7SvF4q29ULQrm6oKkgY7OvlsGsmBiGemKm3AWGNgeEfliwsKL2yZk0APP2AiGbAqa1attVd84CajYDJw7QsrCYDtWahVgN5xbvAkomF57nlJ814IqSC0LhxkHGTnZ2NBQsWYNCgQfDy4peBPaHW+iDtIjbHncfaQ+ew5vA5Zexk55b8lVDLH+jbui66No5A14Y1ERmsXzYWcZHnWr4qpCO5tIwQfEOBcbOB6Nba+7P7gc97aLV2pJ2EBDqv/RyY95y2v3ZHbeoqMBqYsL5oywjh3CFg3gtaYUPxDFVnrU1Gtk5aM1vKwSlvxBiotT7tIro3DleLkJGVqwKStx9PwrZjyeq11Nc5lQ5MWX9cLUL9MH+0rRuK1rWDVeVl6ZEV6u98fbFcEad9rsUTIx6dL3prwcbSCsJq2AgRVwC9ngGWvgHMfRa4cBJY+LK2r88LWlDzZz20lhGLXtXifGzjcaSwYPIx4OAiLWi5tJYR1UVrE5JjsNY0bgghBfh5e6jYG1msnE5Kw5czFiMvrCE2xCapGJ7Yc+lq+WvbyYLjGoUHqBo7Uj1ZPi+GEzEZMmU1YYM2ZSWp58Xp8bjWMuLsnkLDpvsjWkCz1TiSWB0pDtjmJqB+d+DCKeD76zTDxs1dC2a2DVwu7j3a/ScQ1qSoYUVIMWjcEEIuSViAN9qFWTB0aHPlUpYO5zJ9tfNEMnafvKA6oIuhczghTS2TVx+Fr5e7MnA6N6iJDjGhyssT6MNfN6YguFbZ+zy9ges+Ar4ZpHl3rrxbC0C2xt80vFqbctr8g1Yg8I6ZwI/Xa3V0QusDN38P/DBS64AutXfE22Nr2Mi0lWR0ScVlqckTWs/+4yUuCWNu7FCoKCgoiKm1doZaO5fWyenZWHM4QdXakeX0hYtF9ru7AVdEBan082ta11JrD9lIzPlcS90c6XV15T0lU78zzgOfXAWkntGMlKxULePqrrlAjfrAlp+AP8drzUKlKrJ4iwTpfv5Pfvdzoekg4LbfShYuFHIyNWNIGoyaXWsXwKKT1gwodqBxI/OKUl6a/1nsC7V2Xq3l+H1nUrDyQIJKPRcvz4mkon2xwgN9MLRNNIa2qYUr69eApwdTcavVc73rD2DandrrwCjNsLEaMfKVJPE3R5YDDa7W2kRIGvmSf2v7uz8KrPu8aOCyLeL1+fEGwC9U64Yu6+qstROgl9Y0bhyYLTVnzhwMHTqU0fd2hlq7ltZnLlzElrjzWLI3HvN3nVFTW1b8vT3U1FWn+jWVodOxfo1qO4VVbZ5rNcX0PHB0FXDjV1oVZVsSjwCfdgNyMjQPzYEF2naZ4urxKLD8bS1w2T9M62hurdAcvwf4bmhhI9GOd2rTZNVZaydAL62ZLUUIcSqign0xpHUttfx7ZJ7qdD57+ylVNVkMnVUHz6lF8PJwQ+8rIjGyQ230bx6lgpyJyZC/3q/5T9n7azYE+r0ELPi/QsOmz4uaYWMNXJaKyfG7gfkvADd8CSQc1AKTxbAJawqcOwBs/l4LXJZYH1tys+G+6GW0j90J5PQHaNyYDho3hBBDkSaefZtFqkUqKO+PT8HGo+exKfY8NsYm4lhiBhbtOaMW6Ysl/bP6NI9Eh3qhqFvDj1MI1QVp6CkGzIlNmjHT+9ligcsfA98MALb/CsR01YoFpsUDUa21qSyJ0dn0HfDXo1rsjpef9tm8XGDmA/DY+Tvqi52z+kOg/0sOGyaxDzRuCCEO7YvVPDpYLbd3la8aYN/pFMzadgJ/bj2pauzM2HJCLdbMLameLFNXQ1pHo3FEoINHQOyGpIFLkcCE/UB025KBw3U7Fe1oLoRfAdzxh5amPvA1YP88IPEwsGyS1tE8L09LM9/5OyxwgxsscF/1X6DNDSWnxgRpLyGfb3Fd6YHLxGlhzI2OMEDNOKi1+bWWnyvVk//efgqbY8+r+jrFqye3rBWM4e1q49q2tUzR7ZzPdQXJStNic5JigRoNtcBk21T1vXOAqaMBNw/gvsVaC4mN36j3llHfwrLlZ7gfXKA1FL17ftGO5oeWAlNuAXIzgev+Z0jVZLNiYUCx/WEquDmg1tVPa2kVIQbO1rgk1e1csrFsm4A2iQxEi1riBQpSRo9UTXa1NhHOorVLEb8X2PozcNUDQEjdkvunjdOmt7yDgKwU+dpTMTqWNjch9eR+BH7fH26y/Zq3tXMIsWuAn24AstO19z4hWsuIoOiS55ev0ItJgF8NOw/UdbEwFdz+MFvKHFBr43BWrc+nZWHertOqSrL0xSrtN1m7eqEYIZ6ddrUQGeT8ho6zau3SpMYDn3TR6usI+V4Yq9bXRp2Gx7xnCzuap50Fvh+hGUKN+2sByie3aFNTt/xY0nP0883A8Q3ArVOApgMcMkRnJ5vZUoQQUj5qBHhjdJcYtSSkZmLHiWTsOXUBe0+lqPWhs6nYdkx6ZCXh37N3o0eTcBXE3DQqUHl5pPs5vSPVgMBIYMQnWnXjno+XmF7K6zgOHrtnAnFrgOn3aDE+YthIjR3pYC69sL7sA+yZpRUntHY0z74I/DIaiF2pvZeKy2Ic+QQ5YJCkODRuCCEujxQFtGZgWTmbkonZ20/iz20nVTHBfw4kqMWK1NJpHBmIwa2iMKpjXZebwiIVoPkwbSkN6Wc1/COto/nx9dq2ul2A0b8A3v5AdButDYRUR579tGb0ePkDv43VCg1KlWXpcH7hOLB4IjD07ZI/Q2J9tvyoTX3Vbm/fsRIFjRudkYApYgzU2jhcUeuIIB+M69FQLXHS5HP7SeXFOXg2VfXCSs3MKfDsvLdgvzKMbu1cTzX+dGTFZFfU2lUp0Fo6mvd5Xksfl27kY6YV9cD0elZr2HnuILDgJSAzFTgwX2sRcduvqm4OfhwJrP9Sq5hcr0vhZ7f8DMyaoL2ecT/w4D9a49FqhqfBzzVjbggh1Y6snDzEnktT2VjTNh7HxtjzRT06EQEqzbxR/rpH03AE+zIGxtTIV+GprUBEi9J7Ukk15clDC9+7ewGjpxbG2fzxsBbYHNEceEAMGG+tzcT0uwBLHuDuCeTlAH1e0Ayp4khV5q1TgE7jgJA6dhyo68KAYgcZN3l5eUhISEB4eDjcizeLI7pCrY2jOmh9MD4Fv244hhmbT+BcWlaJ/dIiYlSnuhjXvQEa2bG2TnXQ2lmolNZ/Pa4VBpTUculgbo2/EdITtcBlCUiWasp1OmoxOXnZWpxPw97A7/cAHt7AgyuBiGaFn006Bnw7RJvaqtMJuGdh0bR0FydPp+e6It/f/N+jI7m5uVizZo1aE/tCrY2jOmjdJDIILw1ribUv9sfCJ3rh89s74pnBzXBDxzrKi5OelYsf1sSi33vLcdd367Fg12kcS0xXFZb1pDpo7SxUSutBE4GeTwJjfitq2AhSONDaUmLFO8Cvt2uGTasbgGs/AFrfCDQdrDX8nPWoVlBQSD2rTWmJYSNIReYNX5dx0TnAkX+A7KKNaJ2dXAc815zcJYSQfLw83NE0KkgtVsS5vebQOXy76ggW743H0n1n1SL4eLqjYXiAWiRWZ0T7OvD1Ms9f3KQYEocz4JWy94shs/03rTKyGDZizEjfK6sXZth7wKergGNrNQ+QGDw/Xa/F8oTEAO1uBVa8rcX+SAC0bd0eMYZmPgDsnA407AWMncWqyZeAnhtCCLkEki7evUk4vr6zM5Y+1Qd39WigUsm9PdyRmZOHvadTMHfnaTz3+w70/M9SfLzkgKrBQ6ohYmyIASNxO1IXR6auPGxitULrAf1e1l4vehX4eZTW4iEgEhj7hxaPU+8qICtVy8yyRo2oLurPaYaNcGQFsO2Xsq8jK63ws9UUem50/iXIyqLGQK2Ng1oX0iA8AK8Mb6Ve5+ZZcOJ8Bg4lpGLXiWRMWReHk8kX8e6C/fhk6SHV1VwqJdet4Y96Nf1QJ9T/sh3OqbVx2E1r8bY8vKZsr0qX+4Ad04ATG7Xif1L9+I4ZQFhjbf/wD4HPrwb2z9Vq67QcASz/j5aJJdWVmw7UOqXPf0nzDAWEFT3/zhlacHOLa4EbvnIK744jnmsGFBNCiA5k5+Zhzo5T+GL5YdUmojTa1Q3BPVc3wtDW0Q5NNycO5swu4Mu+Wo0d8dhIV3Nblvxbi9sJjNZaQix+Tdt+zTvAlXcBX/QC4ncD7ccAIz8t/Nzh5Zo3KDffc3jzD5pxZBKYLeXAbKljx46hXr16zHSwM9TaOKh1xZBfqasPncPiPfE4dj5ddTY/npiOlMycgmPqhPqp6a1bu8So1HMr1No4HK61dBuXOjnBtUvuk+rHn3XXqiNb6f080PcF7fWx9cA3g+RpA+78G2h4NXBqG/DdMK26clBtIOUkEFQLGL8e8C32XXc+Fpj5IFCvs9Yt3UW0ZvsFByGR4Fu3bkXt2rX5i8nOUGvjoNYVQ1zv0upBFluDRyom/7L+GH5YcxQnkjLw79l7VPHAOjX8EB7oraos1/D3Ql7CEbwwJhqBftWv0Fu1eq5rNip7n9TZkemp76/V3ne+r2htHCkSeOXdWofzvx8HbvkZ+GlU0bYRX/XVDKilbxRmcVlT1sW7I20m4lYDMd2BZkNMpzV/UxFCiAEGj7R3eGxAU6x6vh8m3dBGFQjMyM7FwfhUrD2ciL+3n8KPa+Pw80EP9H//H3yx/BBSLmY7+tKJoxBvjMTMDJ6ktW0oHq8iWVuBUVqmlUxTpcUDUW2AW38G/EKBYe9rx0msjjT+FCSFXGrviGEjtXqEuc8AWfndz22RqssS17Pyv3BF6LkhhBADkVRxafZ5y5X1VHPP+JRM1fgzITULJ8+nYfr6oziTkolJc/fi4yUHcdtVMWhRK1hNXwX6eqp1vRr+CPFnxWTT0/bmsvdJPyvxyEwbB+RmAqExwO3Tte1C475Am5u04GUpPiiFAWfcp6WhyzG3z9T6YyXFafE9tinuEq3y9xNaPyxBjCYX63hO40bnv84iIiKY6WAA1No4qLV9cHd3K1FTJycnB71rJOOkV118veqo8up8seJwic96e7qrPlgP9WmMWiF+Bl+5OTDFc91yJNDlfuDYOuDGb4Gg6KL7B70B7F+gtZX4qh9wZodWIfnWKUDdTppx9OsYYPX/gLa3AJHNtc+teLfQsBHmPA08vLb0thT75mqp59JTy4m0ZkAxIYQ4IVL9eMneeNXVPCk9Cxcu5iD1YjaSM3KUp0eQWju35Bs5tUNp5JBS2PANMPvJ/DduwKhvgdY3aG/l61+mqSTtvH5PYNzfWhHCmfdr+we8Bqz7HEg5pbWU6PNc0XPvmql5joTbZwBN+tt1KMyWcpBxI0FTBw4cQNOmTeHhwSql9oRaGwe1di6tVcXkw+fwwaIDWH8kUW3z8nBTHhw/Lw/4envAz8td1dW5v1cjNIu26W5Nqt9znZcHfD8ciF2pxe90e7hk5tQnVwE5GUDne4FN32vVlbs/qrWb2Pk7MP1uwMMHGL+2MBD62AYt4DnnovY+rAnw0OpSO57rpbXL9JaaNGkSOnfurIr7REZGYuTIkdi3b99lPzdt2jQ0b94cvr6+aNOmDebMmQNnQNLd5PplTewLtTYOau1cWquKyY3D8dsD3fDLfV3RtVFNZOdaEJeYjn1nUrDtWJIKUP5983EM+XAFnvxtK46fLyVgtJpTbZ5r9/xaOo9uLWnYCDXqA72f1V5LTyvVD+t6zWtjbSnRqI8W1zP3Oc3bc/4o8MutmmHTdJBWYVkCm9d87DRaOzTmZvny5Rg/frwycGSu+cUXX8SgQYOwe/duBAQElPqZ1atXY/To0cowuvbaazFlyhRlFG3evBmtW7c2fAyEEOIoujUOQ7fG3XAkIQ3n07NwMStXZWBJo8+5O09hzo7TqtP539tOYUzXGPRtFqniddTi4Y6wQG/G7FQHPLyAmg3L3t9tArD9V+DsXiCmGzDyc80oEiROZui7wKfdtMrIW38GVn0EpCcA0W2BUd8Be2drU1nL3wHa3Ky1mXAwDjVu5s2bV+T95MmTlQdn06ZN6NWrV6mf+fDDDzFkyBA888wz6v3EiROxcOFCfPzxx/j8888NuW5CCHEmVPNOFP2DcHi72sqL8/b8vVh18By+W3VULcUZ1rYWnh3cDPXDSv+DklQDPPODjHfN0KamigcOhzcFejwG/PMu8Od4bVtwHeC23wCfQC2ra9NkrW7O/Be0OjsOxqmypWQeTahZs2aZx0jb9CeftAZHaQwePBh//PFHqcdnZmaqxXbOTsjOzlaLIEWFZB5Q5gVt3WbW7eJVsg1Nkm2yr/h2ISYmpkRbd09PTWY5vjzbvby81HXYnkdc0XJ8WdvLuvaqjsm63aqVs4xJlrp166q1WcbkrPdJ3stzLdie35XH5Kz3yfa51mNMLaMD8P24K7H2SBK+WHFIFRLMyslDVm4esnPyEJ+aidnbT2HBrtO4rUs9jO/TCGGBvtXiPskx1oq5ZhmT7bXnVHRMwTFAt8e1jdnZJcfU7VF4bv8VbsnHYPEORM7NUk8nXB2rrn3Yu7B8fjXc9vyFnL3zYGncv2BMch22z3VVxuRyxo0M8PHHH0ePHj0uOb10+vRpREVFFdkm72V7acj01Wuv5c8d2rBgwQL4+/ur1/KLu0OHDti+fTvi4uIKjmnWrJmK7Vm/fj3Onj1bsL19+/aoX78+VqxYgZSUlILt3bp1U+eZPXt2kZvQt29f+Pn5lYgNGjp0KDIyMrB06dKCbfIgDBs2DAkJCcqQsyJxSf369VMlrKXSoxVJr+vevbsK1rKNV9JzTOJNE72ccUzHjx833Zic9T7FxsaabkzOdp/mz59f8FzrOaae3bsjPDehxJh8ohrjpd/WY8vpTHy/Jg6/rY9Fx7qBCA4KQsK5c+oPQx93oEd0Hq6/2pz3Sb44lyxZYqox1bfTfYqsNQ7dguYhqcPDWLFJriWuyJhSWo5B8K4fcHHmo1ja/E2ERdVWYzp8+LB6pq3PdWXHtGrVKpQXp8mWeuihhzB37lysXLlSWXhl4e3tje+//17F3Vj59NNPlQFz5syZcnluxFqXB84aba2n52bnzp1o0aJFkYhwU1v7DhqTXM+uXbvQqlUrdW4zjMlZ75O8lzi44n90uPKYnPU+ye8q63Mtxxo1phX7z+I/8/dj7+nCL8PiDGsTjeevaYFawd6muE9yjDzX7dq1U9vMMCaH/3/KSILbJ13glnoGub1fhOXqp9T2rKws7Nixo+C5ruyYEhMTERYW5jq9pSZMmIC///5bWZqXMmyE6OjoEkaMvJftpeHj46OW4sgNksUWEbC0NDXrTb7cdnloxAqVL4Hi57b+zNIobbvcyNJ6cJS1vaxrr+qYKnPtRoxJ/kPIXwFt27YtOMbVx+Ss9+lyz7Urjuly2x01Jjm39bm2PcbeY+rbIhq9m0Vh8d54nE7O0Ha4uUlVFGw/noRpm45j9o7TWLg7XjX8HNWprpraupgfvCx0blBTVV92pfsk3hPJuNXjGXP1Z89LjzFJ24fBbwK/3wOPk5vkoguMn9Kea73GVOqxcCBimT3yyCOYOXMmli1bhoYNLxHNbeNaW7x4sZrCsiIBxbKdEEJI5SsmD2xZdMpfoz7GdW+IN+fswcqDCapicmlVk+vV9MPLw1qqc7h01V9SNVrfqPW2aty/ZD8sA3GocSNp4JLK/eeff6o5O2vcjBTpkTlAYezYsahTp46KnREee+wx9O7dG++9956az5w6dSo2btyIL7/80pFDIYQQ09KydjB+vKcLlu07i3cX7FM1dfxVsUAP5a2RisnHEjNw/4+b0OuKCLwyvCUaRwQ6+rKJIxCDponj+1A51Lj57LPP1LpPnz5Ftn/33XcYN04r6SzucFv3lwQniUH0f//3f6oujlQ8lEwpZ6hxI9cpAVFGtXSvzlBr46DWxuHMWos3pm/zSLUUJy0zB58sPYiv/zmi4neGfLBC1dSRqavkDGkZkY3M7DwMaR2NJwZeoZp/Ohpn1tpsuDtAa6cJKDYK9pYihBD7IMUEX/9rF5buK8x0KU6tEF+8dl0rDGpVepwkIWXB3lIOMm4kwltS2Lp06VKhwCdScai1cVBr4zCL1qsOJmDPqQsI9vNCSP5yPi0Lb87do6avBInNeXpQM+TmWXAuLROJaVm4kJGtqi43ibR/PyyzaO0K5OikdUW+v3lHdUTsRMnNr2b2okOg1sZBrY3DLFr3aBKuluL0aRaJ/y05gC9XHMbC3WfUUhxPdzfV5XxCvybw8bRfQ0uzaO0KWBygNScbCSGEGIKftweeHdIccx67WjX8FEMmPNAHzaKC0K1RGDo3qIGcPAv+t+Qghn20Eptizzv6komLQs8NIYQQQ7kiKghT7++m/pIvnjY+d8cpvPznLhyMT8Woz1djRLva8HB3R3zKRZy5cBHnUrPQISYUrwxvhXo1tSrzhBSHMTc6IoXlpCiUtV8JsR/U2jiotXFQa42k9CxM/HsPft+slesvjQBvDzx/TXOMuaq+qtFTUai1ceilNQOKLwGzpQghxHUCk5fti0eovzeign0RFeyj6uq8M28f1h9NVMfI9NZ/bmwLf29PHD+fjuPnM3AyKQNNIgPRr3kkCwqaCBo3DsyWkhYSvXr1YvS9naHWxkGtjYNal4+8PAt+WHMU/5m3DxnZhT2OijOoZRTeuL4NIoJKtuCh1sahl9YV+f6mL05HxE6ULqzVzF50CNTaOKi1cVDr8iHTUON6NMT8x3upQGS1zQ2oHeKrgpKHtIqGl4cbFuw+g0H/XY6/t58scY6c3DxcuECtzfpc01wlhBDiksSE+WPKfVepGjlBvl7w9iz8e333yQt4ato2VW9nwpQtmLX1pJraik1MR9y5NDV9FejpAb8mZzG4dW2HjoPoD40bQgghLovE1IQF+pTaD+vP8T3w8ZID+GTZIeXFKU5Slhse+GkLbu2cgP+7tqVTtIUg+sCYG50jwhMSEhAeHs7oeztDrY2DWhsHtbYP248n4beNx5R3p35Nf+XxkSmsL5fuxS+bz0C+BaWr+fs3t0fz6CDEnktXy9FzaSor69YuMSqQmTj2uWZA8SVgthQhhBAraw6dw9PTtuFEktYWojQk8+qDW9qjdZ0QQ6+NFIUBxQ4iOzsbs2fPVmtiX6i1cVBr46DWxmt9ZUww5j5+NUZ1qluwLyzAGx1jQnF9hzoq00oKCo78ZJWa4pJAZFvEPyD9sYhzPdecYLRDyhsxBmptHNTaOKi18VoH+3rh3Zva4bkhzeHj5a7eW5Fg5Zdm7sDcnafx7oL9WLI3Hl0bhakpqyMJMn2VBqmk8/iAK3BPz4aVKihYHcgx+LmmcUMIIYQApdbDqRngjU/HdMTMLSfwyp+7sDkuSS3FeWPOHizee0YZSXVrsC2Eo6FxQwghhFwmI+uGjnVxVaMwfLH8EPIsFjQMD0TDcH80CAvA2sOJ+Pfs3Wp9zQf/4NXrWuHadrUQdy4dh86KhydNFRu8tXM91A71c/RwqgUMKLZDoaKgoCCW/LYz1No4qLVxUGvX1Vqmp574dWuBV0dOWfzbNcjXE6+PaIWR7etUq/tr0UlrBhQ7ED8/WuVGQa2Ng1obB7V2Ta3rhwXgtwe64ZnBzeDp7qYMG6mb07ZuCEa0r412dUOQcjEHT/y6DeOnbMb5tKwin5dA5eQM8waS+xn8XNNzoyMSCT5nzhwMHToUXl6FAWlEf6i1cVBr46DW5tA6OT0bmbm5iAj0KfBUiPHy2bJD+HDxAeTkWVR8z3XtaiMuMR2Hz6aqdXauBde0jlb9sCTWxyxk66R1Rb6/GXNDCCGE6EiIv3yBF/0S9/RwxyP9m6JPs0g88dtWlV7+zcojJT4rWVkbjp7HWze0wYCWUQZetbmgcUMIIYQYRJu6Ifj7kZ74btVRnE7OQKOIQDSKCFDrc6mZeOq3bTgQn4p7f9iIW66sh0f6N8Gp5IvKuyPByWdTMjGsTS0aPpeBxg0hhBBiINLK4aE+jUtsrxPqh78e6Yn3FuzD1yuP4NeNx9RSHElLv6FjHbwyvBVC/Dh9WRqMudERkVIKFXl6elarSHhHQK2Ng1obB7U2DmfXeu3hc3ju9+0qFqd2iJ/y7jSOCEROXh6mrIuDFEWuFeKLt0e1xdVNIwrGdOZCpmol0Sw6yGkageqlNXtLXQKmgpsDam0c1No4qLVxuILWco1ZuXnw8SzatHNTbKKavjp6Ll29v7ppuKqkLPV00rNy1bbIIB+8dWMb9Gvu+OkrpoK7OGKZLl26lOXTDYBaGwe1Ng5qbRyuoLUYAsUNG6FT/ZqY89jVGNutvnr/z4EE7Dp5QRk2Hu5uCPb1RHxKJu6evBHPTNuGCxezq53WzuGzIoQQQki58feWgoCtVQ2drceSEVPTHw3DA9Q6z2LBu/P34ZtVRzBt03GsOpiAZ4c0R2ZOruqHdTQhDceT0tG+XiieGdzclHE7NG4IIYQQF0W8OLIU5/+ubYlBraLxzPRtiD2Xjsd/3VrimJ0nLmDh7jN464a26Ns8EmaCxo3OSMAUMQZqbRzU2jiotXGYXesuDWti7mNX4935+7HiwFkVgCzeHemHVSPACx8tPqjidO6avAGjOtXFy9e2VEHIp5IzlEEkwcxNIgPRuUFJ48nZtWZAMSGEEFINycjKVWnnMn1lbReRlZOngphtuaFDHfxreEuE+ju2ajIDih1EXl4e4uPj1ZrYF2ptHNTaOKi1cVBrwM/bQ01fTXugm/LopGbmKMPG28MdjSMC0L1xGNzdgBlbTmDA+yswd8epEufIzs1T2VDOprW5fXIGk5ubizVr1qj+Ge7utBvtCbU2DmptHNTaOKh1IVc20Kav9p5OQXigN2qF+KmsK2FL3Hk8M327ahfx0M+bMaBFJMIDfdSUlSwnkzJUn6x/XdsKQ9tEl5rq7QitadwQQggh1RxfLw+VPVWcDjE1MPvRnvjf4oP4bPkhLNoTX+IYKRwonc4HtYzCxJGtERXsC0dD44YQQgghZSK1dp4e3AxDWkdjxuYTCPbzVCnn9cP8UTvUD1PXH8MnSw9iwe4zWHP4HF4a2gK3dK7n0OKING50RG6kM1e7NBPU2jiotXFQa+Og1hWndZ0QtRTniYFX4Jo20Xhu+nZsO56M52fswPxdp/HtuM5KX0dozWwpQgghhFSZ3DwLvlt1BO8u2IdH+jXF+L5NoCfMlnIQEgkeGxtbraPvjYJaGwe1Ng5qbRzUWn8kCPneqxth4RO9cX+vRg7VmsaNjkhE+NatW9Wa2BdqbRzU2jiotXFQa/tRr6Y/vDzcHao1jRtCCCGEmAoaN4QQQggxFTRudEQiwSMiIhh9bwDU2jiotXFQa+Og1ubWmtlShBBCCHF6mC3lICRYau/evQxQMwBqbRzU2jiotXFQa3NrTeNGRyTNbd++fUwtNABqbRzU2jiotXFQa3NrTeOGEEIIIaaCxg0hhBBCTAWNGx2RVu4xMTGGtXSvzlBr46DWxkGtjYNam1trZksRQgghxOlhtpSDkEjwLVu2MPreAKi1cVBr46DWxkGtza01jRsdkUjwuLg4Rt8bALU2DmptHNTaOKi1ubWmcUMIIYQQU+GJaoY1xEjm7vQmOzsb6enp6txeXl66n58UQq2Ng1obB7U2Dmrtelpbv7fLEypc7YyblJQUta5Xr56jL4UQQgghlfgel8DiS1HtsqVkzu/kyZMICgrSvYmXWJViNB07doyZWHaGWhsHtTYOam0c1Nr1tBZzRQyb2rVrXzatvNp5bkSQunXr2vVnyM3jfxZjoNbGQa2Ng1obB7V2La0v57GxwoBiQgghhJgKGjeEEEIIMRU0bnTEx8cHr7zyiloT+0KtjYNaGwe1Ng5qbW6tq11AMSGEEELMDT03hBBCCDEVNG4IIYQQYipo3BBCCCHEVNC4IYQQQoipoHGjE5988gkaNGgAX19fXHXVVVi/fr2jL8nlmTRpEjp37qyqSUdGRmLkyJHYt29fkWMuXryI8ePHIywsDIGBgbjxxhtx5swZh12zWXjrrbdUBe/HH3+8YBu11o8TJ07g9ttvV1r6+fmhTZs22LhxY8F+yfP417/+hVq1aqn9AwYMwIEDBxx6za5Ibm4uXn75ZTRs2FDp2LhxY0ycOLFIbyJqXXlWrFiB4cOHq4rB8vvijz/+KLK/PNomJiZizJgxqrhfaGgo7rnnHqSmplbhqgp/OKkiU6dOtXh7e1u+/fZby65duyz33XefJTQ01HLmzBlHX5pLM3jwYMt3331n2blzp2Xr1q2WoUOHWmJiYiypqakFxzz44IOWevXqWRYvXmzZuHGjpWvXrpbu3bs79LpdnfXr11saNGhgadu2reWxxx4r2E6t9SExMdFSv359y7hx4yzr1q2zHD582DJ//nzLwYMHC4556623LCEhIZY//vjDsm3bNst1111nadiwoSUjI8Oh1+5qvPHGG5awsDDL33//bTly5Ihl2rRplsDAQMuHH35YcAy1rjxz5syxvPTSS5YZM2aItWiZOXNmkf3l0XbIkCGWdu3aWdauXWv5559/LE2aNLGMHj3aUlVo3OhAly5dLOPHjy94n5uba6ldu7Zl0qRJDr0usxEfH6/+Ay1fvly9T0pKsnh5ealfWFb27NmjjlmzZo0Dr9R1SUlJsTRt2tSycOFCS+/evQuMG2qtH88995ylZ8+eZe7Py8uzREdHW955552CbaK/j4+P5ZdffjHoKs3BsGHDLHfffXeRbTfccINlzJgx6jW11o/ixk15tN29e7f63IYNGwqOmTt3rsXNzc1y4sSJKl0Pp6WqSFZWFjZt2qTcbbb9q+T9mjVrHHptZiM5OVmta9asqdaie3Z2dhHtmzdvjpiYGGpfSWTaadiwYUU0Fai1fsyaNQtXXnklbrrpJjXd2qFDB3z11VcF+48cOYLTp08X0Vr66ch0N7WuGN27d8fixYuxf/9+9X7btm1YuXIlrrnmGvWeWtuP8mgra5mKkv8PVuR4+Q5dt25dlX5+tWucqTcJCQlqXjcqKqrIdnm/d+9eh12XGbu5S/xHjx490Lp1a7VN/uN4e3ur/xzFtZd9pGJMnToVmzdvxoYNG0rso9b6cfjwYXz22Wd48skn8eKLLyq9H330UaXvnXfeWaBnab9TqHXFeP7551VHajHEPTw81O/qN954Q8V4CNTafpRHW1mLgW+Lp6en+gO2qvrTuCEu41HYuXOn+quL6M+xY8fw2GOPYeHChSoontjXUJe/VN988031Xjw38mx//vnnyrgh+vHbb7/h559/xpQpU9CqVSts3bpV/ZEkAbDU2txwWqqKhIeHq78IimeNyPvo6GiHXZeZmDBhAv7++28sXboUdevWLdgu+sq0YFJSUpHjqX3FkWmn+Ph4dOzYUf3lJMvy5cvx0Ucfqdfy1xa11gfJHGnZsmWRbS1atEBcXJx6bdWTv1OqzjPPPKO8N7feeqvKSLvjjjvwxBNPqExMgVrbj/JoK2v5vWNLTk6OyqCqqv40bqqIuJI7deqk5nVt/zKT9926dXPotbk6EqMmhs3MmTOxZMkSlc5pi+ju5eVVRHtJFZcvCWpfMfr3748dO3aov2yti3gXxH1vfU2t9UGmVouXNJCYkPr166vX8pzLL3ZbrWVqRWIQqHXFSE9PV/Ebtsgfo/I7WqDW9qM82spa/mCSP66syO96uT8Sm1MlqhSOTApSwSUCfPLkySr6+/7771ep4KdPn3b0pbk0Dz30kEojXLZsmeXUqVMFS3p6epH0ZEkPX7JkiUpP7tatm1pI1bHNlhKotX6p9p6enipN+cCBA5aff/7Z4u/vb/npp5+KpNDK75A///zTsn37dsuIESOYnlwJ7rzzTkudOnUKUsElZTk8PNzy7LPPFhxDrauWXbllyxa1iDnx/vvvq9exsbHl1lZSwTt06KDKIqxcuVJlazIV3In43//+p37xS70bSQ2XnH1SNeQ/S2mL1L6xIv9JHn74YUuNGjXUF8T111+vDCCiv3FDrfXjr7/+srRu3Vr9UdS8eXPLl19+WWS/pNG+/PLLlqioKHVM//79Lfv27XPY9boqFy5cUM+w/G729fW1NGrUSNVlyczMLDiGWleepUuXlvo7WozK8mp77tw5ZcxI/aHg4GDLXXfdpYymquIm/1TN90MIIYQQ4jww5oYQQgghpoLGDSGEEEJMBY0bQgghhJgKGjeEEEIIMRU0bgghhBBiKmjcEEIIIcRU0LghhBBCiKmgcUMIqfYsW7YMbm5uJXpnEUJcExo3hBBCCDEVNG4IIYQQYipo3BBCHI50AZ40aZLqJOzn54d27dph+vTpRaaMZs+ejbZt28LX1xddu3bFzp07i5zj999/R6tWreDj44MGDRrgvffeK7I/MzMTzz33HOrVq6eOadKkCb755psix0h3YumA7u/vj+7du5fo3k0IcQ1o3BBCHI4YNj/88AM+//xz7Nq1C0888QRuv/12LF++vOCYZ555RhksGzZsQEREBIYPH47s7OwCo+Tmm2/Grbfeih07duDVV1/Fyy+/jMmTJxd8fuzYsfjll1/w0UcfYc+ePfjiiy8QGBhY5Dpeeukl9TM2btwIT09P3H333QaqQAjRCzbOJIQ4FPGo1KxZE4sWLUK3bt0Ktt97771IT0/H/fffj759+2Lq1Km45ZZb1L7ExETUrVtXGS9i1IwZMwZnz57FggULCj7/7LPPKm+PGEv79+9Hs2bNsHDhQgwYMKDENYh3SH6GXEP//v3Vtjlz5mDYsGHIyMhQ3iJCiOtAzw0hxKEcPHhQGTEDBw5UnhTrIp6cQ4cOFRxna/iIMSTGinhgBFn36NGjyHnl/YEDB5Cbm4utW7fCw8MDvXv3vuS1yLSXlVq1aql1fHy8bmMlhBiDp0E/hxBCSiU1NVWtxctSp06dIvskNsbWwKksEsdTHry8vApeS5yPNR6IEOJa0HNDCHEoLVu2VEZMXFycCvK1XST418ratWsLXp8/f15NNbVo0UK9l/WqVauKnFfeX3HFFcpj06ZNG2Wk2MbwEELMCz03hBCHEhQUhKeffloFEYsB0rNnTyQnJyvjJDg4GPXr11fHvf766wgLC0NUVJQK/A0PD8fIkSPVvqeeegqdO3fGxIkTVVzOmjVr8PHHH+PTTz9V+yV76s4771QBwhJQLNlYsbGxaspJYnYIIeaCxg0hxOGIUSIZUJI1dfjwYYSGhqJjx4548cUXC6aF3nrrLTz22GMqjqZ9+/b466+/4O3trfbJsb/99hv+9a9/qXNJvIwYQ+PGjSv4GZ999pk638MPP4xz584hJiZGvSeEmA9mSxFCnBprJpNMRYnRQwghl4MxN4QQQggxFTRuCCGEEGIqOC1FCCGEEFNBzw0hhBBCTAWNG0IIIYSYCho3hBBCCDEVNG4IIYQQYipo3BBCCCHEVNC4IYQQQoipoHFDCCGEEFNB44YQQgghpoLGDSGEEEJgJv4fQkxUFmWXi0kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 손실곡선\n",
    "plt.title(\"RNN train | val loss\")\n",
    "plt.plot(history.epoch, history.history[\"loss\"])\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c77cafe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 정확도 곡선\n",
    "plt.title(\"RNN train | val accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"accuracy\"])\n",
    "plt.plot(history.epoch, history.history[\"val_accuracy\"])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbadbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dfce7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 128)               24704     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " repeat_vector_6 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 7, 128)            32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,654\n",
      "Trainable params: 72,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 4.4187 - accuracy: 0.0082\n",
      "Epoch 2/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.8980 - accuracy: 0.3929\n",
      "Epoch 3/80\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.1768 - accuracy: 0.4148\n",
      "Epoch 4/80\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7875 - accuracy: 0.4176\n",
      "Epoch 5/80\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7047 - accuracy: 0.4368\n",
      "Epoch 6/80\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6228 - accuracy: 0.4231\n",
      "Epoch 7/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.5122 - accuracy: 0.4588\n",
      "Epoch 8/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.4181 - accuracy: 0.4396\n",
      "Epoch 9/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3578 - accuracy: 0.4615\n",
      "Epoch 10/80\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2823 - accuracy: 0.4505\n",
      "Epoch 11/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.2201 - accuracy: 0.4973\n",
      "Epoch 12/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2056 - accuracy: 0.4643\n",
      "Epoch 13/80\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1260 - accuracy: 0.5192\n",
      "Epoch 14/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0581 - accuracy: 0.5027\n",
      "Epoch 15/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9917 - accuracy: 0.5769\n",
      "Epoch 16/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9133 - accuracy: 0.5412\n",
      "Epoch 17/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8637 - accuracy: 0.5769\n",
      "Epoch 18/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8012 - accuracy: 0.5604\n",
      "Epoch 19/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7104 - accuracy: 0.6016\n",
      "Epoch 20/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6579 - accuracy: 0.5962\n",
      "Epoch 21/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6183 - accuracy: 0.6319\n",
      "Epoch 22/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5872 - accuracy: 0.6209\n",
      "Epoch 23/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5044 - accuracy: 0.6319\n",
      "Epoch 24/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4684 - accuracy: 0.6593\n",
      "Epoch 25/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4383 - accuracy: 0.6264\n",
      "Epoch 26/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3903 - accuracy: 0.7335\n",
      "Epoch 27/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3709 - accuracy: 0.6456\n",
      "Epoch 28/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2702 - accuracy: 0.7253\n",
      "Epoch 29/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2275 - accuracy: 0.6841\n",
      "Epoch 30/80\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2410 - accuracy: 0.7280\n",
      "Epoch 31/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2471 - accuracy: 0.6786\n",
      "Epoch 32/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1257 - accuracy: 0.7857\n",
      "Epoch 33/80\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0817 - accuracy: 0.7253\n",
      "Epoch 34/80\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0210 - accuracy: 0.8104\n",
      "Epoch 35/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9755 - accuracy: 0.8214\n",
      "Epoch 36/80\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9802 - accuracy: 0.7995\n",
      "Epoch 37/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9649 - accuracy: 0.8132\n",
      "Epoch 38/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9456 - accuracy: 0.8132\n",
      "Epoch 39/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8773 - accuracy: 0.8736\n",
      "Epoch 40/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8665 - accuracy: 0.8187\n",
      "Epoch 41/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8536 - accuracy: 0.8379\n",
      "Epoch 42/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8591 - accuracy: 0.8297\n",
      "Epoch 43/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7936 - accuracy: 0.8819\n",
      "Epoch 44/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7179 - accuracy: 0.8819\n",
      "Epoch 45/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7567 - accuracy: 0.9011\n",
      "Epoch 46/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7880 - accuracy: 0.8352\n",
      "Epoch 47/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7187 - accuracy: 0.8681\n",
      "Epoch 48/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6770 - accuracy: 0.8819\n",
      "Epoch 49/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6227 - accuracy: 0.9038\n",
      "Epoch 50/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5971 - accuracy: 0.9148\n",
      "Epoch 51/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5844 - accuracy: 0.9313\n",
      "Epoch 52/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5538 - accuracy: 0.9286\n",
      "Epoch 53/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5514 - accuracy: 0.9313\n",
      "Epoch 54/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5402 - accuracy: 0.9423\n",
      "Epoch 55/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5245 - accuracy: 0.9231\n",
      "Epoch 56/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5111 - accuracy: 0.9423\n",
      "Epoch 57/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5007 - accuracy: 0.9451\n",
      "Epoch 58/80\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4538 - accuracy: 0.9286\n",
      "Epoch 59/80\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4406 - accuracy: 0.9478\n",
      "Epoch 60/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4487 - accuracy: 0.9203\n",
      "Epoch 61/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4280 - accuracy: 0.9396\n",
      "Epoch 62/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3869 - accuracy: 0.9615\n",
      "Epoch 63/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3912 - accuracy: 0.9423\n",
      "Epoch 64/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3682 - accuracy: 0.9643\n",
      "Epoch 65/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3449 - accuracy: 0.9808\n",
      "Epoch 66/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3625 - accuracy: 0.9725\n",
      "Epoch 67/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3708 - accuracy: 0.9396\n",
      "Epoch 68/80\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3625 - accuracy: 0.9643\n",
      "Epoch 69/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3365 - accuracy: 0.9533\n",
      "Epoch 70/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2900 - accuracy: 0.9780\n",
      "Epoch 71/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2730 - accuracy: 0.9725\n",
      "Epoch 72/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2668 - accuracy: 0.9780\n",
      "Epoch 73/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2544 - accuracy: 0.9780\n",
      "Epoch 74/80\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2434 - accuracy: 0.9835\n",
      "Epoch 75/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2526 - accuracy: 0.9725\n",
      "Epoch 76/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2202 - accuracy: 0.9945\n",
      "Epoch 77/80\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2282 - accuracy: 0.9863\n",
      "Epoch 78/80\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2362 - accuracy: 0.9698\n",
      "Epoch 79/80\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2517 - accuracy: 0.9725\n",
      "Epoch 80/80\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2310 - accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "model = Sequential([\n",
    "    ### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "    # - input_dim : 말뭉치 갯수\n",
    "    # - 출력갯수 : 64개\n",
    "    # - input_length => 질문의 특성 갯수\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=64,\n",
    "        input_length=questions_train.shape[1]\n",
    "    ),\n",
    "    ### 은닉계층 추가 : SimpleRNN, 출력:128, 활성화함수:tanh\n",
    "    # - 질문을 담당하는 계층\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"tanh\"\n",
    "    ),\n",
    "    Dropout(0.3),\n",
    "    ### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "    # - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "    RepeatVector(answers_train.shape[1]),\n",
    "    ### 은닉계층 : simpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "    # - return_sequences=True : 후련결과(단어)를 다음 계층으로 넘겨주기\n",
    "    #                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행합니다.\n",
    "    SimpleRNN(\n",
    "        units=128,\n",
    "        activation=\"tanh\",\n",
    "        return_sequences=True\n",
    "    ),\n",
    "    Dropout(0.2),\n",
    "    ### 단어조합 계층과 출력계층 정의하기\n",
    "    # - TimeDistributed\n",
    "    # - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "    # - 다음에 올 단어들이 있는지 체크\n",
    "    # - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "    # - 출력계층을 감싸서 사용하빈다.\n",
    "    # ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환 \n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=vocab_size,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - RMSprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 100회, 배치사이즈 : 64\n",
    "history = model.fit(\n",
    "    questions_padded,\n",
    "    answers_padded,\n",
    "    epochs=80,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a135454",
   "metadata": {},
   "source": [
    "### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67ffa3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 157ms/step\n",
      "[59 60 61  4  0  0  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'전기요금이 계속 인상되고 있어요'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 예측을 위한 임의 질문 정의하기\n",
    "user_input = \"전기요금 어때?\"\n",
    "\n",
    "### 텍스트 문장 내에 단어를 추출하여 -> 말뭉치 인덱스 번호로 변환하기\n",
    "# - 1차원 리스트로 넣어주기 -> 2차원 데이터로 반환해줍니다.\n",
    "input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "\n",
    "### 데이터 스케일링 처리하기\n",
    "# - 훈련시 사용한 질문의 특성 갯수로 스케일링해야 합니다.\n",
    "# - maxlen 속성을 정의해야 합니다.\n",
    "#  -> 외부 파일에서 모델을 사용하여 예측할 경우에는 maxlen의 값을 알고 있어야 합니다.\n",
    "# - truncating 속성을 정의해야 합니다. : 질문이 길게 입력될 수 있기 때문에...\n",
    "padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\",\n",
    "                           maxlen=questions_padded.shape[1])\n",
    "\n",
    "### 예측하기\n",
    "# - 말뭉치의 숫자로 예측을 해줍니다.\n",
    "pred = model.predict(padded_seq)\n",
    "# print(pred)\n",
    "\n",
    "### 문자로 변환하기\n",
    "# 예측 결과 값 중에 가장 큰 값이 있는 열단위 번호 추출하기\n",
    "pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "print(pred_index)\n",
    "\n",
    "\n",
    "# 답변 문자(텍스트)로 변환하기\n",
    "# - 리스트를 2차원으로 넣어줍니다.\n",
    "a_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "a_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2274977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[20 53 54 55  0  0  0]\n",
      "좋아하는 음악 장르가 있나요?? : 저는 다양한 음악을 즐겨듣습니다\n"
     ]
    }
   ],
   "source": [
    "### 예측을 위한 임의 질문 정의하기\n",
    "user_input = \"좋아하는 음악 장르가 있나요??\"\n",
    "\n",
    "### 텍스트 문장 내에 단어를 추출하여 -> 말뭉치 인덱스 번호로 변환하기\n",
    "# - 1차원 리스트로 넣어주기 -> 2차원 데이터로 반환해줍니다.\n",
    "input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "\n",
    "### 데이터 스케일링 처리하기\n",
    "# - 훈련시 사용한 질문의 특성 갯수로 스케일링해야 합니다.\n",
    "# - maxlen 속성을 정의해야 합니다.\n",
    "#  -> 외부 파일에서 모델을 사용하여 예측할 경우에는 maxlen의 값을 알고 있어야 합니다.\n",
    "# - truncating 속성을 정의해야 합니다. : 질문이 길게 입력될 수 있기 때문에...\n",
    "padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\",\n",
    "                           maxlen=questions_padded.shape[1])\n",
    "\n",
    "### 예측하기\n",
    "# - 말뭉치의 숫자로 예측을 해줍니다.\n",
    "pred = model.predict(padded_seq)\n",
    "# print(pred)\n",
    "\n",
    "### 문자로 변환하기\n",
    "# 예측 결과 값 중에 가장 큰 값이 있는 열단위 번호 추출하기\n",
    "pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "print(pred_index)\n",
    "\n",
    "\n",
    "# 답변 문자(텍스트)로 변환하기\n",
    "# - 리스트를 2차원으로 넣어줍니다.\n",
    "chatbot_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "print(f\"{user_input} : {chatbot_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849c74a",
   "metadata": {},
   "source": [
    "### 챗봇과 대화하는 프로그램 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed19b01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<함수 정의하기>\\n - 함수명 : get_Answer\\n - 기능 : 질문을 받아서 예측 후 -> 텍스트로 답변을 반환하는 기능\\n \\n<실행 프로그램 정의하기>\\n - 무한 반복\\n - 받은 질문을 출력하기\\n - 답변을 출력하기\\n - \"Q\" 문자를 입력하면 무한반복 종료\\n  -> 종료시 챗봇은 \"안녕히 가세요~\"라고 답변하기\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<함수 정의하기>\n",
    " - 함수명 : get_Answer\n",
    " - 기능 : 질문을 받아서 예측 후 -> 텍스트로 답변을 반환하는 기능\n",
    " \n",
    "<실행 프로그램 정의하기>\n",
    " - 무한 반복\n",
    " - 받은 질문을 출력하기\n",
    " - 답변을 출력하기\n",
    " - \"Q\" 문자를 입력하면 무한반복 종료\n",
    "  -> 종료시 챗봇은 \"안녕히 가세요~\"라고 답변하기\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "513367cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Answer(user_input=None):\n",
    "    input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "    \n",
    "    padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\",\n",
    "                                    maxlen=questions_padded.shape[1])\n",
    "    pred = model.predict(padded_seq)\n",
    "\n",
    "    pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "\n",
    "    chatbot_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "    \n",
    "    return(f\"사용자 : {user_input}\", f\"보키봇 : {chatbot_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6c7eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('사용자 : 좋아하는 음악 장르가 있나요??', '보키봇 : 저는 다양한 음악을 즐겨듣습니다')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Answer(\"좋아하는 음악 장르가 있나요??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ff53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 : 안녕\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m사용자 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_input)\n\u001b[1;32m---> 18\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_Answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m보키봇 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m, in \u001b[0;36mget_Answer\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_Answer\u001b[39m(user_input):\n\u001b[1;32m----> 2\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtexts_to_sequences([user_input])\n\u001b[0;32m      3\u001b[0m     padded_seq \u001b[38;5;241m=\u001b[39m pad_sequences(input_seq, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxlen\u001b[38;5;241m=\u001b[39mquestions_padded\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(padded_seq, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def get_Answer(user_input):\n",
    "    input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "    padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\", maxlen=questions_padded.shape[1])\n",
    "    pred = model.predict(padded_seq, verbose=0)\n",
    "    pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "    chatbot_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "    return chatbot_text\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"질문을 입력하세요 (종료는 'Q'): \")\n",
    "    \n",
    "    if user_input.strip().upper() == \"Q\":\n",
    "        print(\"보키봇 : 안녕히 가세요~\")\n",
    "        break\n",
    "    \n",
    "    print(\"사용자 :\", user_input)\n",
    "    answer = get_Answer(user_input)\n",
    "    print(\"보키봇 :\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784594a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc726a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0862df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81e8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
