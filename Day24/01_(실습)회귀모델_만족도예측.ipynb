{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine Running library install\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "### 선형, 다중, 다항 회귀모델 라이브러리 정의\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### 앙상블 모델\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "### visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definition of the NumPy library\n",
    "import numpy as np\n",
    "\n",
    "### Definition of Library (Preprocessing Library)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### 평가 라이브러리 정의\n",
    "# 평균절대오차(MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# 평균제곱오차(MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 결정계수(R2-score)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# - 변환기 모델(클래스) 라이브러리 정의하기\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "### 라이브러리 정의\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "### 라이브러리 정의\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "### 하이퍼파라미터 튜닝 모델(클래스) 정의하기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "### 경고 메시지 없애기\n",
    "# - 사이킷런 버전에 따라 오류가 아니니 안내(경고)메시지가 자주 나타남\n",
    "# - 안내(경고) 메시지 없이 실행할 수 있도록 처리\n",
    "from sklearn import set_config\n",
    "set_config(display=\"text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 불러들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 264 entries, 0 to 263\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   친밀도     264 non-null    int64\n",
      " 1   적절성     264 non-null    int64\n",
      " 2   만족도     264 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 6.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>친밀도</th>\n",
       "      <th>적절성</th>\n",
       "      <th>만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   친밀도  적절성  만족도\n",
       "0    3    4    3\n",
       "1    3    3    2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 불러들이기\n",
    "file_path = \"./data/04_(실습)_회귀모델_drinking_water.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.info()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>친밀도</th>\n",
       "      <th>적절성</th>\n",
       "      <th>만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.928030</td>\n",
       "      <td>3.132576</td>\n",
       "      <td>3.094697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.970345</td>\n",
       "      <td>0.859657</td>\n",
       "      <td>0.828744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              친밀도         적절성         만족도\n",
       "count  264.000000  264.000000  264.000000\n",
       "mean     2.928030    3.132576    3.094697\n",
       "std      0.970345    0.859657    0.828744\n",
       "min      1.000000    1.000000    1.000000\n",
       "25%      2.000000    3.000000    3.000000\n",
       "50%      3.000000    3.000000    3.000000\n",
       "75%      4.000000    4.000000    4.000000\n",
       "max      5.000000    5.000000    5.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>친밀도</th>\n",
       "      <th>적절성</th>\n",
       "      <th>만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>친밀도</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499209</td>\n",
       "      <td>0.467145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>적절성</th>\n",
       "      <td>0.499209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>만족도</th>\n",
       "      <td>0.467145</td>\n",
       "      <td>0.766853</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          친밀도       적절성       만족도\n",
       "친밀도  1.000000  0.499209  0.467145\n",
       "적절성  0.499209  1.000000  0.766853\n",
       "만족도  0.467145  0.766853  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 상관관계 표: corr() 함수 사용(데이터프레임에 포함되어 있음)\n",
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"만족도 예측을 위한 특성들간 상관관계 매트릭스\")\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".3f\", cmap=\"summer\", linewidths=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 산점행렬도: 모든 특성들간의 관계를 산점도로 표현한 그래프\n",
    "sns.pairplot(df)\n",
    "plt.suptitle(\"만족도 예측을 위한 특성들간의 선형형태 분석 시각화(산점행렬도)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### (해석)\n",
    "# - 만족도를 기준으로 친밀도, 적절성 각각의 특성간의 선형관계를 확인한 결과\n",
    "# - 친밀도와의 관계는 고른 우상향 관계를 나타내고 있으며,\n",
    "# - 적절성과의 관계의 경우에도 친밀도와 비슷하게 고른 우상향 관계를 나타내고 있다.\n",
    "# - 만족도를 예측하기 위한 특성들로 만족도와 친밀도를를 이용하여\n",
    "#   분석을 진행할 경우, 모든 관계성이 선형분포를 나타내고 있으며,\n",
    "#   종속변수로 사용한 주택가격의 데이터 형태가 연속형 데이터로,\n",
    "#  -> 회귀분석으로 진행하는 것을 추천함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   친밀도  적절성\n",
      "0    3    4\n",
      "1    3    3\n",
      "0    3\n",
      "1    2\n",
      "Name: 만족도, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### 독립변수와 종속변수로 분리하기\n",
    "# 독립변수명: X(대문자)\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "# 종속변수명: y(소문자)\n",
    "y = df[\"만족도\"]\n",
    "\n",
    "print(X.head(2))\n",
    "print(y.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    독립변수(친밀도)와 종속변수(만족도)의 상관관계 계수는 0.501이고, \n",
      "    p-value의 값은 3.383407076477574e-18임. 따라서 p-value < 0.05에 대하여 유의미 함\n",
      "    \n",
      "\n",
      "    독립변수(적절성)와 종속변수(만족도)의 상관관계 계수는 0.749이고, \n",
      "    p-value의 값은 1.1877299204509877e-48임. 따라서 p-value < 0.05에 대하여 유의미 함\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "### 독립변수 이름 추출하기\n",
    "X_columns_nm = X.columns\n",
    "\n",
    "### 독립변수 \"친밀도\"과 종속변수 \"만족도\"과의 상관관계 검증(유의미성 확인)\n",
    "X[X_columns_nm[0]]\n",
    "\n",
    "spearmanr(X[X_columns_nm[0]], y)\n",
    "\n",
    "### (해석)\n",
    "# - 결과값: 상관관계 계수(statistic), 유의미계수(pvalue)\n",
    "# - 해석: 독립변수 \"친밀도\"과 종속변수 \"만족도\" 간의 스피어만 상관관계 검증 결과\n",
    "#         p-value의 값이 0.000000000000000003383를 나타내고 있음\n",
    "#         이는 p-value > 0.05 만족하므로 유의미한 특성이라고 판단됨\n",
    "\n",
    "### 모든 독립변수 각각에 대하여 종속변수와의 상관관계 유의미성을 확인\n",
    "for col in X_columns_nm:\n",
    "    stat, p_value = spearmanr(X[col], y)\n",
    "    p_msg = \"유의미 하지 않음\"\n",
    "\n",
    "    if p_value < 0.5 :\n",
    "        p_msg = \"유의미 함\"\n",
    "\n",
    "\n",
    "    msg = f\"\"\"\n",
    "    독립변수({col})와 종속변수(만족도)의 상관관계 계수는 {stat:.3f}이고, \n",
    "    p-value의 값은 {p_value}임. 따라서 p-value < 0.05에 대하여 {p_msg}\n",
    "    \"\"\"\n",
    "\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 독립변수/종속변수(198, 2)/(198,)\n",
      "테스트 독립변수/종속변수(66, 2)/(66,)\n"
     ]
    }
   ],
   "source": [
    "### 훈련 : 테스트 = 7.5 : 2.5 비율로 분류\n",
    "# <사용 변수명>\n",
    "# - 훈련 독립변수 / 종속변수 = X_train / y_train\n",
    "# - 테스트 독립변수 / 종속변수 = X_val / y_val\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"훈련 독립변수/종속변수{X_train.shape}/{y_train.shape}\")\n",
    "print(f\"테스트 독립변수/종속변수{X_test.shape}/{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 적용 전 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.32929292929292925\n",
      "검증 데이터 평균절대오차: 0.3636363636363637\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2581818181818182\n",
      "검증 데이터 평균제곱오차: 0.26666666666666666\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6251894093686355\n",
      "검증 데이터 결정계수: 0.5909859154929575\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0342 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3846911927147498\n",
      "검증 데이터 평균절대오차: 0.3769073246868923\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28295828329792594\n",
      "검증 데이터 평균제곱오차: 0.2610530426786978\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.5995961077787295\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38543144666585627\n",
      "검증 데이터 평균절대오차: 0.37781081538933814\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28297719439184527\n",
      "검증 데이터 평균제곱오차: 0.2610270809628289\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5891931890783966\n",
      "검증 데이터 결정계수: 0.5996359279316609\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34675690622569866\n",
      "검증 데이터 평균절대오차: 0.4045771953393962\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22839544414566765\n",
      "검증 데이터 평균제곱오차: 0.2886210298259285\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6684312167270227\n",
      "검증 데이터 결정계수: 0.5573122514360052\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4016651032266241\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28319804180168107\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5656300457436186\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1031 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34973410729169646\n",
      "검증 데이터 평균절대오차: 0.40423839779520876\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22833897639854847\n",
      "검증 데이터 평균제곱오차: 0.2890692374648368\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6685131927151011\n",
      "검증 데이터 결정계수: 0.556624789296891\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1119 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37814107386294843\n",
      "검증 데이터 평균절대오차: 0.3964414343969845\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2703749286531729\n",
      "검증 데이터 평균제곱오차: 0.30441578505402167\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6074882909491208\n",
      "검증 데이터 결정계수: 0.5330862113748878\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0744 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859595953816\n",
      "검증 데이터 평균절대오차: 0.4062898303523208\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2282196582476271\n",
      "검증 데이터 평균제곱오차: 0.2884243639760002\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865091323853\n",
      "검증 데이터 결정계수: 0.5576138496398926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_org_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_org = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_org[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_org_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_org = pd.DataFrame(df_org_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3293</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3293     0.2582    0.6252   0.3636   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3854     0.2830    0.5892   0.3778   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3468     0.2284    0.6684   0.4046   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4017   \n",
       "6      GradientBoostingRegressor     0.3497     0.2283    0.6685   0.4042   \n",
       "7  HistGradientBoostingRegressor     0.3781     0.2704    0.6075   0.3964   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2667  0.5910           0.0342  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2886  0.5573           0.1111  \n",
       "5   0.2832  0.5656           0.1031  \n",
       "6   0.2891  0.5566           0.1119  \n",
       "7   0.3044  0.5331           0.0744  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 새로운 특성(198, 5) \n",
      "테스트 새로운 특성(66, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['친밀도', '적절성', '친밀도^2', '친밀도 적절성', '적절성^2'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "print(f\"훈련 새로운 특성{X_train_poly.shape} \\n테스트 새로운 특성{X_test_poly.shape}\")\n",
    "\n",
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3222222222222222\n",
      "검증 데이터 평균절대오차: 0.37272727272727274\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.25191919191919193\n",
      "검증 데이터 평균제곱오차: 0.27090909090909093\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6342810590631365\n",
      "검증 데이터 결정계수: 0.5844788732394364\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0498 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35417540283850035\n",
      "검증 데이터 평균절대오차: 0.3619008508380416\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24632614429751631\n",
      "검증 데이터 평균제곱오차: 0.2387768225108109\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221505\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36576166947513905\n",
      "검증 데이터 평균절대오차: 0.36101583417768063\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24839155185696113\n",
      "검증 데이터 평균제곱오차: 0.23320695791207693\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6394022440659025\n",
      "검증 데이터 결정계수: 0.642306511033448\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0029 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.455334525041473\n",
      "검증 데이터 평균절대오차: 0.4539927718830634\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.35219411453333593\n",
      "검증 데이터 평균제곱오차: 0.33270072076086743\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.4887088292477356\n",
      "검증 데이터 결정계수: 0.48970269731185245\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.001 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3478884898635766\n",
      "검증 데이터 평균절대오차: 0.4034865017451955\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22857392128863918\n",
      "검증 데이터 평균제곱오차: 0.2867285395134372\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6681721158970633\n",
      "검증 데이터 결정계수: 0.5602149584082632\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4037093901396414\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28650175022233204\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5605628084618033\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1081 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492322255667011\n",
      "검증 데이터 평균절대오차: 0.40501226759805975\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22822274201450718\n",
      "검증 데이터 평균제곱오차: 0.28854735144584753\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686819337923815\n",
      "검증 데이터 결정계수: 0.5574252595429182\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1113 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3700804160362178\n",
      "검증 데이터 평균절대오차: 0.39347024284529586\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26164397628153513\n",
      "검증 데이터 평균제곱오차: 0.3018675821648784\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6201632865713276\n",
      "검증 데이터 결정계수: 0.5369946521442921\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0832 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821969668302822\n",
      "검증 데이터 평균제곱오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_poly_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_poly = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_poly[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_poly)\n",
    "    test_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_poly_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_poly = pd.DataFrame(df_poly_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.6394</td>\n",
       "      <td>0.3610</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>-0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.3327</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>-0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3222     0.2519    0.6343   0.3727   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.3658     0.2484    0.6394   0.3610   \n",
       "3                          Lasso     0.4553     0.3522    0.4887   0.4540   \n",
       "4          RandomForestRegressor     0.3479     0.2286    0.6682   0.4035   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4037   \n",
       "6      GradientBoostingRegressor     0.3492     0.2282    0.6687   0.4050   \n",
       "7  HistGradientBoostingRegressor     0.3701     0.2616    0.6202   0.3935   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2709  0.5845           0.0498  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2332  0.6423          -0.0029  \n",
       "3   0.3327  0.4897          -0.0010  \n",
       "4   0.2867  0.5602           0.1080  \n",
       "5   0.2865  0.5606           0.1081  \n",
       "6   0.2885  0.5574           0.1113  \n",
       "7   0.3019  0.5370           0.0832  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardscaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 2) (198,)\n",
      "(66, 2) (66,)\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train)\n",
    "\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "print(X_train_scaled.shape, y_train.shape)\n",
    "print(X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3353535353535354\n",
      "검증 데이터 평균절대오차: 0.3757575757575758\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26828282828282823\n",
      "검증 데이터 평균제곱오차: 0.27999999999999997\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6105254582484727\n",
      "검증 데이터 결정계수: 0.5705352112676056\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.04 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38469119271474944\n",
      "검증 데이터 평균절대오차: 0.3769073246868921\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.282958283297926\n",
      "검증 데이터 평균제곱오차: 0.2610530426786976\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5892206429027258\n",
      "검증 데이터 결정계수: 0.5995961077787298\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38524420143648225\n",
      "검증 데이터 평균절대오차: 0.37758457954350977\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.282968718067045\n",
      "검증 데이터 평균제곱오차: 0.26103687508463147\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589205494423239\n",
      "검증 데이터 결정계수: 0.599620905680051\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34748857350072154\n",
      "검증 데이터 평균절대오차: 0.4045771953393962\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22861969207766578\n",
      "검증 데이터 평균제곱오차: 0.2886210298259285\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6681056690163745\n",
      "검증 데이터 결정계수: 0.5573122514360052\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4016651032266241\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28319804180168107\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5656300457436186\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1031 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34973410729169646\n",
      "검증 데이터 평균절대오차: 0.40423839779520876\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22833897639854847\n",
      "검증 데이터 평균제곱오차: 0.2890692374648368\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6685131927151011\n",
      "검증 데이터 결정계수: 0.556624789296891\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1119 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37814107386294843\n",
      "검증 데이터 평균절대오차: 0.3964414343969845\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2703749286531729\n",
      "검증 데이터 평균제곱오차: 0.30441578505402167\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6074882909491208\n",
      "검증 데이터 결정계수: 0.5330862113748878\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0744 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859595953816\n",
      "검증 데이터 평균절대오차: 0.4062898303523208\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2282196582476271\n",
      "검증 데이터 평균제곱오차: 0.2884243639760002\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865091323853\n",
      "검증 데이터 결정계수: 0.5576138496398926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_ss_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_ss = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_ss[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_scaled)\n",
    "    test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_ss_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_ss = pd.DataFrame(df_ss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3354     0.2683    0.6105   0.3758   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3852     0.2830    0.5892   0.3776   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3475     0.2286    0.6681   0.4046   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4017   \n",
       "6      GradientBoostingRegressor     0.3497     0.2283    0.6685   0.4042   \n",
       "7  HistGradientBoostingRegressor     0.3781     0.2704    0.6075   0.3964   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2800  0.5705           0.0400  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2886  0.5573           0.1108  \n",
       "5   0.2832  0.5656           0.1031  \n",
       "6   0.2891  0.5566           0.1119  \n",
       "7   0.3044  0.5331           0.0744  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxscaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 2) (198,)\n",
      "(66, 2) (66,)\n"
     ]
    }
   ],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "mm.fit(X_train)\n",
    "\n",
    "X_train_mm = mm.transform(X_train)\n",
    "X_test_mm = mm.transform(X_test)\n",
    "\n",
    "print(X_train_mm.shape, y_train.shape)\n",
    "print(X_test_mm.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.32929292929292925\n",
      "검증 데이터 평균절대오차: 0.3636363636363637\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2581818181818182\n",
      "검증 데이터 평균제곱오차: 0.26666666666666666\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6251894093686355\n",
      "검증 데이터 결정계수: 0.5909859154929575\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0342 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3846911927147496\n",
      "검증 데이터 평균절대오차: 0.37690732468689214\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28295828329792594\n",
      "검증 데이터 평균제곱오차: 0.26105304267869767\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.5995961077787297\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3951690128953438\n",
      "검증 데이터 평균절대오차: 0.3898014147468761\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2866489471109991\n",
      "검증 데이터 평균제곱오차: 0.2641128735371734\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5838627912408959\n",
      "검증 데이터 결정계수: 0.5949029305887579\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.011 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34675690622569866\n",
      "검증 데이터 평균절대오차: 0.4045771953393962\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22839544414566765\n",
      "검증 데이터 평균제곱오차: 0.2886210298259285\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6684312167270227\n",
      "검증 데이터 결정계수: 0.5573122514360052\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4016651032266241\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28319804180168107\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5656300457436186\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1031 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34973410729169646\n",
      "검증 데이터 평균절대오차: 0.40423839779520876\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22833897639854847\n",
      "검증 데이터 평균제곱오차: 0.2890692374648368\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6685131927151011\n",
      "검증 데이터 결정계수: 0.556624789296891\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1119 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37814107386294843\n",
      "검증 데이터 평균절대오차: 0.3964414343969845\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2703749286531729\n",
      "검증 데이터 평균제곱오차: 0.30441578505402167\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6074882909491208\n",
      "검증 데이터 결정계수: 0.5330862113748878\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0744 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859595953816\n",
      "검증 데이터 평균절대오차: 0.4062898303523208\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2282196582476271\n",
      "검증 데이터 평균제곱오차: 0.2884243639760002\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865091323853\n",
      "검증 데이터 결정계수: 0.5576138496398926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_mm_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_mm = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_mm, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_mm[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_mm)\n",
    "    test_pred = model.predict(X_test_mm)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_mm_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_mm = pd.DataFrame(df_mm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3293</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.3898</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>-0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3293     0.2582    0.6252   0.3636   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3952     0.2866    0.5839   0.3898   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3468     0.2284    0.6684   0.4046   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4017   \n",
       "6      GradientBoostingRegressor     0.3497     0.2283    0.6685   0.4042   \n",
       "7  HistGradientBoostingRegressor     0.3781     0.2704    0.6075   0.3964   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2667  0.5910           0.0342  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2641  0.5949          -0.0110  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2886  0.5573           0.1111  \n",
       "5   0.2832  0.5656           0.1031  \n",
       "6   0.2891  0.5566           0.1119  \n",
       "7   0.3044  0.5331           0.0744  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustscaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 2) (198,)\n",
      "(66, 2) (66,)\n"
     ]
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "\n",
    "rs.fit(X_train)\n",
    "\n",
    "X_train_rs = rs.transform(X_train)\n",
    "X_test_rs = rs.transform(X_test)\n",
    "\n",
    "print(X_train_rs.shape, y_train.shape)\n",
    "print(X_test_rs.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.32929292929292925\n",
      "검증 데이터 평균절대오차: 0.3636363636363637\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2581818181818182\n",
      "검증 데이터 평균제곱오차: 0.26666666666666666\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6251894093686355\n",
      "검증 데이터 결정계수: 0.5909859154929575\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0342 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3846911927147496\n",
      "검증 데이터 평균절대오차: 0.3769073246868922\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2829582832979259\n",
      "검증 데이터 평균제곱오차: 0.26105304267869767\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.5995961077787297\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38543144666585644\n",
      "검증 데이터 평균절대오차: 0.37781081538933825\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28297719439184527\n",
      "검증 데이터 평균제곱오차: 0.261027080962829\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5891931890783966\n",
      "검증 데이터 결정계수: 0.5996359279316608\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34675690622569866\n",
      "검증 데이터 평균절대오차: 0.4045771953393962\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22839544414566765\n",
      "검증 데이터 평균제곱오차: 0.2886210298259285\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6684312167270227\n",
      "검증 데이터 결정계수: 0.5573122514360052\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4016651032266241\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28319804180168107\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5656300457436186\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1031 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34973410729169646\n",
      "검증 데이터 평균절대오차: 0.40423839779520876\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22833897639854847\n",
      "검증 데이터 평균제곱오차: 0.2890692374648368\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6685131927151011\n",
      "검증 데이터 결정계수: 0.556624789296891\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1119 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37814107386294843\n",
      "검증 데이터 평균절대오차: 0.3964414343969845\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2703749286531729\n",
      "검증 데이터 평균제곱오차: 0.30441578505402167\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6074882909491208\n",
      "검증 데이터 결정계수: 0.5330862113748878\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0744 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859595953816\n",
      "검증 데이터 평균절대오차: 0.4062898303523208\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2282196582476271\n",
      "검증 데이터 평균제곱오차: 0.2884243639760002\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865091323853\n",
      "검증 데이터 결정계수: 0.5576138496398926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_rs_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_rs = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_rs, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_mm[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_rs)\n",
    "    test_pred = model.predict(X_test_rs)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_rs_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_rs = pd.DataFrame(df_rs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3293</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.0342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3293     0.2582    0.6252   0.3636   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3854     0.2830    0.5892   0.3778   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3468     0.2284    0.6684   0.4046   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4017   \n",
       "6      GradientBoostingRegressor     0.3497     0.2283    0.6685   0.4042   \n",
       "7  HistGradientBoostingRegressor     0.3781     0.2704    0.6075   0.3964   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2667  0.5910           0.0342  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2886  0.5573           0.1111  \n",
       "5   0.2832  0.5656           0.1031  \n",
       "6   0.2891  0.5566           0.1119  \n",
       "7   0.3044  0.5331           0.0744  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.54731\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3489439853076216\n",
      "검증 데이터 평균절대오차: 0.38567493112947654\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2647967276066449\n",
      "검증 데이터 평균절대오차: 0.28600050087653395\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6155863392301091\n",
      "검증 데이터 결정계수: 0.5613316261203583\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0543 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53933\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38469119271474944\n",
      "검증 데이터 평균절대오차: 0.376907324686892\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.28295828329792594\n",
      "검증 데이터 평균절대오차: 0.2610530426786975\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.59959610777873\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53927\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3854307186564242\n",
      "검증 데이터 평균절대오차: 0.37780977162685264\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2829771684248765\n",
      "검증 데이터 평균절대오차: 0.26102665427295024\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5891932267754543\n",
      "검증 데이터 결정계수: 0.5996365823897987\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': False, 'positive': True}\n",
      "최적의 성능(결정계수): 0.31678\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5517667154288293\n",
      "검증 데이터 평균절대오차: 0.6202335011947022\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.41536058973637946\n",
      "검증 데이터 평균절대오차: 0.5215934524880408\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.3970080888715046\n",
      "검증 데이터 결정계수: 0.19997849329651185\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.197 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.58004\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35661447707120675\n",
      "검증 데이터 평균절대오차: 0.4038299000284551\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2350939801399895\n",
      "검증 데이터 평균절대오차: 0.28421324639406254\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6587067432916813\n",
      "검증 데이터 결정계수: 0.5640729220800926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0946 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.56633\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37317222980771053\n",
      "검증 데이터 평균절대오차: 0.3945457452511291\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2532750728231032\n",
      "검증 데이터 평균절대오차: 0.2697540963051377\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6323126845044645\n",
      "검증 데이터 결정계수: 0.5862504072164859\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0461 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.53103\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3503404210050292\n",
      "검증 데이터 평균절대오차: 0.4030603739138646\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.228722902270128\n",
      "검증 데이터 평균절대오차: 0.2878079584676237\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.667955835563855\n",
      "검증 데이터 결정계수: 0.558559342575715\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1094 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 100}\n",
      "최적의 성능(결정계수): 0.55009\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3737995491989893\n",
      "검증 데이터 평균절대오차: 0.3952886073005379\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26873327822359155\n",
      "검증 데이터 평균절대오차: 0.30160098968458954\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6098715260330427\n",
      "검증 데이터 결정계수: 0.5374035524415238\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0725 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.51680\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492047323120965\n",
      "검증 데이터 평균절대오차: 0.40467550537802954\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22824504176723612\n",
      "검증 데이터 평균절대오차: 0.2882790979655903\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686496138572693\n",
      "검증 데이터 결정계수: 0.5578367114067078\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_hp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_hp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_hp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train)\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_hp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_hp = pd.DataFrame(df_hp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.5613</td>\n",
       "      <td>0.0543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.0461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3489     0.2648    0.6156   0.3857   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3854     0.2830    0.5892   0.3778   \n",
       "3                          Lasso     0.5518     0.4154    0.3970   0.6202   \n",
       "4          RandomForestRegressor     0.3566     0.2351    0.6587   0.4038   \n",
       "5            ExtraTreesRegressor     0.3732     0.2533    0.6323   0.3945   \n",
       "6      GradientBoostingRegressor     0.3503     0.2287    0.6680   0.4031   \n",
       "7  HistGradientBoostingRegressor     0.3738     0.2687    0.6099   0.3953   \n",
       "8                   XGBRegressor     0.3492     0.2282    0.6686   0.4047   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2860  0.5613           0.0543  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.5216  0.2000           0.1970  \n",
       "4   0.2842  0.5641           0.0946  \n",
       "5   0.2698  0.5863           0.0461  \n",
       "6   0.2878  0.5586           0.1094  \n",
       "7   0.3016  0.5374           0.0725  \n",
       "8   0.2883  0.5578           0.1108  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학 & StandardScaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 새로운 특성(198, 5) \n",
      "테스트 새로운 특성(66, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['친밀도', '적절성', '친밀도^2', '친밀도 적절성', '적절성^2'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "print(f\"훈련 새로운 특성{X_train_poly.shape} \\n테스트 새로운 특성{X_test_poly.shape}\")\n",
    "\n",
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 5) (198,)\n",
      "(66, 5) (66,)\n"
     ]
    }
   ],
   "source": [
    "polyss = StandardScaler()\n",
    "\n",
    "polyss.fit(X_train_poly)\n",
    "\n",
    "X_train_polyscaled = polyss.transform(X_train_poly)\n",
    "X_test_polyscaled = polyss.transform(X_test_poly)\n",
    "\n",
    "print(X_train_polyscaled.shape, y_train.shape)\n",
    "print(X_test_polyscaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3252525252525253\n",
      "검증 데이터 평균절대오차: 0.38484848484848494\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26060606060606056\n",
      "검증 데이터 평균제곱오차: 0.29393939393939394\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6216700610997965\n",
      "검증 데이터 결정계수: 0.5491549295774647\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0725 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3541754028385007\n",
      "검증 데이터 평균절대오차: 0.3619008508380418\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24632614429751631\n",
      "검증 데이터 평균제곱오차: 0.23877682251081095\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221504\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3650893259581184\n",
      "검증 데이터 평균절대오차: 0.3617152575119077\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.25002146383170004\n",
      "검증 데이터 평균제곱오차: 0.23299998702934155\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6370360500626563\n",
      "검증 데이터 결정계수: 0.6426239635564042\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0056 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3483235320575121\n",
      "검증 데이터 평균절대오차: 0.4034865017451955\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.2287103918100577\n",
      "검증 데이터 평균제곱오차: 0.2867285395134372\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6679739973885761\n",
      "검증 데이터 결정계수: 0.5602149584082632\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1078 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4037093901396414\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28650175022233204\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5605628084618033\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1081 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492322255667011\n",
      "검증 데이터 평균절대오차: 0.40501226759805975\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22822274201450718\n",
      "검증 데이터 평균제곱오차: 0.28854735144584753\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686819337923815\n",
      "검증 데이터 결정계수: 0.5574252595429182\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1113 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3700804160362178\n",
      "검증 데이터 평균절대오차: 0.39347024284529586\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26164397628153513\n",
      "검증 데이터 평균제곱오차: 0.3018675821648784\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6201632865713276\n",
      "검증 데이터 결정계수: 0.5369946521442921\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0832 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821969668302822\n",
      "검증 데이터 평균제곱오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polyss_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polyss = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_polyscaled, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polyss[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_polyscaled)\n",
    "    test_pred = model.predict(X_test_polyscaled)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_polyss_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_polyss = pd.DataFrame(df_polyss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>-0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3253     0.2606    0.6217   0.3848   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.3651     0.2500    0.6370   0.3617   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3483     0.2287    0.6680   0.4035   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4037   \n",
       "6      GradientBoostingRegressor     0.3492     0.2282    0.6687   0.4050   \n",
       "7  HistGradientBoostingRegressor     0.3701     0.2616    0.6202   0.3935   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2939  0.5492           0.0725  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2330  0.6426          -0.0056  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2867  0.5602           0.1078  \n",
       "5   0.2865  0.5606           0.1081  \n",
       "6   0.2885  0.5574           0.1113  \n",
       "7   0.3019  0.5370           0.0832  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polyss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학 & MinMaxScaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 새로운 특성(198, 5) \n",
      "테스트 새로운 특성(66, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['친밀도', '적절성', '친밀도^2', '친밀도 적절성', '적절성^2'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "print(f\"훈련 새로운 특성{X_train_poly.shape} \\n테스트 새로운 특성{X_test_poly.shape}\")\n",
    "\n",
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 5) (198,)\n",
      "(66, 5) (66,)\n"
     ]
    }
   ],
   "source": [
    "polymm = MinMaxScaler()\n",
    "\n",
    "polymm.fit(X_train_poly)\n",
    "\n",
    "X_train_polymm= polymm.transform(X_train_poly)\n",
    "X_test_polymm = polymm.transform(X_test_poly)\n",
    "\n",
    "print(X_train_polymm.shape, y_train.shape)\n",
    "print(X_test_polymm.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3222222222222222\n",
      "검증 데이터 평균절대오차: 0.37272727272727274\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.25191919191919193\n",
      "검증 데이터 평균제곱오차: 0.27090909090909093\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6342810590631365\n",
      "검증 데이터 결정계수: 0.5844788732394364\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0498 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.354175402838501\n",
      "검증 데이터 평균절대오차: 0.3619008508380422\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24632614429751631\n",
      "검증 데이터 평균제곱오차: 0.23877682251081153\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221495\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.4080993314381282\n",
      "검증 데이터 평균절대오차: 0.38918748586434965\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28770987094107137\n",
      "검증 데이터 평균제곱오차: 0.25650932189131054\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5823226150574428\n",
      "검증 데이터 결정계수: 0.6065652795216376\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0242 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.6888327721661056\n",
      "검증 데이터 평균제곱오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3478884898635766\n",
      "검증 데이터 평균절대오차: 0.4038152664148693\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22857392128863918\n",
      "검증 데이터 평균제곱오차: 0.2874225429007744\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6681721158970633\n",
      "검증 데이터 결정계수: 0.5591504940578262\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.109 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4037093901396414\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28650175022233204\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5605628084618033\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1081 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492322255667011\n",
      "검증 데이터 평균절대오차: 0.4048849954696954\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22822274201450718\n",
      "검증 데이터 평균제곱오차: 0.2882686280021436\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686819337923815\n",
      "검증 데이터 결정계수: 0.5578527663460078\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3700804160362178\n",
      "검증 데이터 평균절대오차: 0.39347024284529586\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26164397628153513\n",
      "검증 데이터 평균제곱오차: 0.3018675821648784\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6201632865713276\n",
      "검증 데이터 결정계수: 0.5369946521442921\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0832 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821969668302822\n",
      "검증 데이터 평균제곱오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polymm_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polymm = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_polymm, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polymm[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_polymm)\n",
    "    test_pred = model.predict(X_test_polymm)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_polymm_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_polymm = pd.DataFrame(df_polymm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>-0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.5592</td>\n",
       "      <td>0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5579</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3222     0.2519    0.6343   0.3727   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.4081     0.2877    0.5823   0.3892   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3479     0.2286    0.6682   0.4038   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4037   \n",
       "6      GradientBoostingRegressor     0.3492     0.2282    0.6687   0.4049   \n",
       "7  HistGradientBoostingRegressor     0.3701     0.2616    0.6202   0.3935   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2709  0.5845           0.0498  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2565  0.6066          -0.0242  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2874  0.5592           0.1090  \n",
       "5   0.2865  0.5606           0.1081  \n",
       "6   0.2883  0.5579           0.1108  \n",
       "7   0.3019  0.5370           0.0832  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polymm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학 & Robustscaler 스케일링 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 5) (198,)\n",
      "(66, 5) (66,)\n"
     ]
    }
   ],
   "source": [
    "polyrs = RobustScaler()\n",
    "\n",
    "polyrs.fit(X_train_poly)\n",
    "\n",
    "X_train_polyrs= polyrs.transform(X_train_poly)\n",
    "X_test_polyrs = polyrs.transform(X_test_poly)\n",
    "\n",
    "print(X_train_polyrs.shape, y_train.shape)\n",
    "print(X_test_polyrs.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ KNeighborsRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3636363636363636\n",
      "검증 데이터 평균절대오차: 0.35757575757575755\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.28888888888888886\n",
      "검증 데이터 평균제곱오차: 0.24848484848484848\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5806109979633403\n",
      "검증 데이터 결정계수: 0.6188732394366196\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0383 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ LinearRegression ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35417540283850074\n",
      "검증 데이터 평균절대오차: 0.36190085083804174\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24632614429751626\n",
      "검증 데이터 평균제곱오차: 0.23877682251081103\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221503\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Ridge ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36955596332290536\n",
      "검증 데이터 평균절대오차: 0.36296416776937024\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.24985371154150027\n",
      "검증 데이터 평균제곱오차: 0.23202006419707405\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.637279581289651\n",
      "검증 데이터 결정계수: 0.6441269719568821\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0068 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ Lasso ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.536623561568802\n",
      "검증 데이터 평균절대오차: 0.5427715580802102\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.5488998961315739\n",
      "검증 데이터 평균제곱오차: 0.5074617326795202\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.20314491657314515\n",
      "검증 데이터 결정계수: 0.22165376494648215\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0185 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ RandomForestRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3478884898635766\n",
      "검증 데이터 평균절대오차: 0.4034865017451955\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22857392128863918\n",
      "검증 데이터 평균제곱오차: 0.2867285395134372\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6681721158970633\n",
      "검증 데이터 결정계수: 0.5602149584082632\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ ExtraTreesRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.34924810376743487\n",
      "검증 데이터 평균절대오차: 0.4037093901396414\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821953047919613\n",
      "검증 데이터 평균제곱오차: 0.28650175022233204\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686865960782669\n",
      "검증 데이터 결정계수: 0.5605628084618033\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1081 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ GradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492322255667011\n",
      "검증 데이터 평균절대오차: 0.40501226759805975\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22822274201450718\n",
      "검증 데이터 평균제곱오차: 0.28854735144584753\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686819337923815\n",
      "검증 데이터 결정계수: 0.5574252595429182\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1113 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ HistGradientBoostingRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3700804160362178\n",
      "검증 데이터 평균절대오차: 0.3958540739710911\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.26164397628153513\n",
      "검증 데이터 평균제곱오차: 0.3082077456409859\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6201632865713276\n",
      "검증 데이터 결정계수: 0.5272700915450228\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0929 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "================ XGBRegressor ================\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균제곱오차: 0.22821969668302822\n",
      "검증 데이터 평균제곱오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polyrs_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polyrs = {}\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [kn_reg, lr_reg, ridge, lasso, rf_reg, et_reg, gb_reg, hb_reg, xg_reg]\n",
    "\n",
    "# 각 모델에 대해 훈련, 예측, 성능 평가를 수행\n",
    "for model in models:\n",
    "    # 모델 훈련\n",
    "    model.fit(X_train_polyrs, y_train)\n",
    "    \n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polyrs[model.__class__.__name__] = model\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 예측\n",
    "    train_pred = model.predict(X_train_polyrs)\n",
    "    test_pred = model.predict(X_test_polyrs)\n",
    "    \n",
    "    # 평가 지표 출력\n",
    "    print(f\"================ {model.__class__.__name__} ================\") \n",
    "    \n",
    "    # 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    # 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 평균제곱오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균제곱오차: {test_mse}\")\n",
    "    \n",
    "    # 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if abs(train_r2 - test_r2) < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    else:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # 결과를 리스트에 저장\n",
    "    df_polyrs_list.append({\n",
    "        \"best_model_nm\": model.__class__.__name__,\n",
    "        \"train_mae\": round(train_mae, 4),\n",
    "        \"train_mse\": round(train_mse, 4),\n",
    "        \"train_r2\": round(train_r2, 4),\n",
    "        \"val_mae\": round(test_mae, 4),\n",
    "        \"val_mse\": round(test_mse, 4),\n",
    "        \"val_r2\": round(test_r2, 4),\n",
    "        \"train_r2-val_r2\": round(train_r2 - test_r2, 4)\n",
    "    })\n",
    "\n",
    "# 데이터프레임에 결과 저장\n",
    "df_polyrs = pd.DataFrame(df_polyrs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.5806</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.2485</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>-0.0383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.2499</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>-0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>-0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3636     0.2889    0.5806   0.3576   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.3696     0.2499    0.6373   0.3630   \n",
       "3                          Lasso     0.5366     0.5489    0.2031   0.5428   \n",
       "4          RandomForestRegressor     0.3479     0.2286    0.6682   0.4035   \n",
       "5            ExtraTreesRegressor     0.3492     0.2282    0.6687   0.4037   \n",
       "6      GradientBoostingRegressor     0.3492     0.2282    0.6687   0.4050   \n",
       "7  HistGradientBoostingRegressor     0.3701     0.2616    0.6202   0.3959   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2485  0.6189          -0.0383  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2320  0.6441          -0.0068  \n",
       "3   0.5075  0.2217          -0.0185  \n",
       "4   0.2867  0.5602           0.1080  \n",
       "5   0.2865  0.5606           0.1081  \n",
       "6   0.2885  0.5574           0.1113  \n",
       "7   0.3082  0.5273           0.0929  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polyrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.56720\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3303030303030303\n",
      "검증 데이터 평균절대오차: 0.38181818181818183\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2507070707070707\n",
      "검증 데이터 평균절대오차: 0.28606060606060607\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.636040733197556\n",
      "검증 데이터 결정계수: 0.5612394366197182\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0748 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': False, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59868\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3570489713112211\n",
      "검증 데이터 평균절대오차: 0.36328512701544535\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.24639313871166255\n",
      "검증 데이터 평균절대오차: 0.23745891359176793\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.642303402701277\n",
      "검증 데이터 결정계수: 0.6357848494345981\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0065 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': False, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59552\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3597324008655629\n",
      "검증 데이터 평균절대오차: 0.35817231248826564\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2479254694978313\n",
      "검증 데이터 평균절대오차: 0.23561802278592173\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6400788703501952\n",
      "검증 데이터 결정계수: 0.6386084129382128\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0015 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.45003\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.455334525041473\n",
      "검증 데이터 평균절대오차: 0.4539927718830634\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35219411453333593\n",
      "검증 데이터 평균절대오차: 0.33270072076086743\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.4887088292477356\n",
      "검증 데이터 결정계수: 0.48970269731185245\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.001 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57110\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35723051500472597\n",
      "검증 데이터 평균절대오차: 0.39979555677325357\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.23463285809774842\n",
      "검증 데이터 평균절대오차: 0.27981526233901755\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6593761685293786\n",
      "검증 데이터 결정계수: 0.5708185624124082\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0886 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57394\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36361483358926533\n",
      "검증 데이터 평균절대오차: 0.4003305344049141\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2401233229374387\n",
      "검증 데이터 평균절대오차: 0.27905193030858494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6514054896337957\n",
      "검증 데이터 결정계수: 0.5719893632309168\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0794 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.52758\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3505224541810225\n",
      "검증 데이터 평균절대오차: 0.4046541465145009\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22846046961392527\n",
      "검증 데이터 평균절대오차: 0.2870448967837406\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6683368172285011\n",
      "검증 데이터 결정계수: 0.5597297287359244\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1086 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 50}\n",
      "최적의 성능(결정계수): 0.52528\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36993074043252233\n",
      "검증 데이터 평균절대오차: 0.3933663918882634\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26139076549519924\n",
      "검증 데이터 평균절대오차: 0.30122759494496193\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6205308805601263\n",
      "검증 데이터 결정계수: 0.5379762663449807\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0826 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': None, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.51242\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22821969668302822\n",
      "검증 데이터 평균절대오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polyhp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polyhp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polyhp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_poly)\n",
    "    test_pred = best_model.predict(X_test_poly)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_polyhp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_polyhp = pd.DataFrame(df_polyhp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.2861</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.0748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3597</td>\n",
       "      <td>0.2479</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.6386</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.3327</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>-0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3303     0.2507    0.6360   0.3818   \n",
       "1               LinearRegression     0.3570     0.2464    0.6423   0.3633   \n",
       "2                          Ridge     0.3597     0.2479    0.6401   0.3582   \n",
       "3                          Lasso     0.4553     0.3522    0.4887   0.4540   \n",
       "4          RandomForestRegressor     0.3572     0.2346    0.6594   0.3998   \n",
       "5            ExtraTreesRegressor     0.3636     0.2401    0.6514   0.4003   \n",
       "6      GradientBoostingRegressor     0.3505     0.2285    0.6683   0.4047   \n",
       "7  HistGradientBoostingRegressor     0.3699     0.2614    0.6205   0.3934   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2861  0.5612           0.0748  \n",
       "1   0.2375  0.6358           0.0065  \n",
       "2   0.2356  0.6386           0.0015  \n",
       "3   0.3327  0.4897          -0.0010  \n",
       "4   0.2798  0.5708           0.0886  \n",
       "5   0.2791  0.5720           0.0794  \n",
       "6   0.2870  0.5597           0.1086  \n",
       "7   0.3012  0.5380           0.0826  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polyhp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler 스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.57207\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3303030303030303\n",
      "검증 데이터 평균절대오차: 0.37575757575757585\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2462626262626263\n",
      "검증 데이터 평균절대오차: 0.27515151515151515\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424928716904277\n",
      "검증 데이터 결정계수: 0.5779718309859154\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0645 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53933\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38469119271474944\n",
      "검증 데이터 평균절대오차: 0.37690732468689203\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.282958283297926\n",
      "검증 데이터 평균절대오차: 0.26105304267869767\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5892206429027258\n",
      "검증 데이터 결정계수: 0.5995961077787297\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.53931\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.38524420143648225\n",
      "검증 데이터 평균절대오차: 0.37758457954350977\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.282968718067045\n",
      "검증 데이터 평균절대오차: 0.26103687508463147\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589205494423239\n",
      "검증 데이터 결정계수: 0.599620905680051\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): -0.05728\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.6888327721661056\n",
      "검증 데이터 평균절대오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57865\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3570247365873218\n",
      "검증 데이터 평균절대오차: 0.4038299000284551\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.23543187339216218\n",
      "검증 데이터 평균절대오차: 0.28421324639406254\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6582162131284457\n",
      "검증 데이터 결정계수: 0.5640729220800926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0941 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.56633\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37317222980771053\n",
      "검증 데이터 평균절대오차: 0.3945457452511291\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2532750728231032\n",
      "검증 데이터 평균절대오차: 0.2697540963051377\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6323126845044645\n",
      "검증 데이터 결정계수: 0.5862504072164859\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0461 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.52855\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3503404210050292\n",
      "검증 데이터 평균절대오차: 0.4030603739138646\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.228722902270128\n",
      "검증 데이터 평균절대오차: 0.2878079584676237\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.667955835563855\n",
      "검증 데이터 결정계수: 0.558559342575715\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1094 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 100}\n",
      "최적의 성능(결정계수): 0.55009\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3737995491989893\n",
      "검증 데이터 평균절대오차: 0.3952886073005379\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26873327822359155\n",
      "검증 데이터 평균절대오차: 0.30160098968458954\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6098715260330427\n",
      "검증 데이터 결정계수: 0.5374035524415238\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0725 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.51680\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492047323120965\n",
      "검증 데이터 평균절대오차: 0.40467550537802954\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22824504176723612\n",
      "검증 데이터 평균절대오차: 0.2882790979655903\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686496138572693\n",
      "검증 데이터 결정계수: 0.5578367114067078\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_sshp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_sshp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_sshp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_scaled)\n",
    "    test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_sshp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_sshp = pd.DataFrame(df_sshp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.0645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3852</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.0461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3303     0.2463    0.6425   0.3758   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3852     0.2830    0.5892   0.3776   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3570     0.2354    0.6582   0.4038   \n",
       "5            ExtraTreesRegressor     0.3732     0.2533    0.6323   0.3945   \n",
       "6      GradientBoostingRegressor     0.3503     0.2287    0.6680   0.4031   \n",
       "7  HistGradientBoostingRegressor     0.3738     0.2687    0.6099   0.3953   \n",
       "8                   XGBRegressor     0.3492     0.2282    0.6686   0.4047   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2752  0.5780           0.0645  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2842  0.5641           0.0941  \n",
       "5   0.2698  0.5863           0.0461  \n",
       "6   0.2878  0.5586           0.1094  \n",
       "7   0.3016  0.5374           0.0725  \n",
       "8   0.2883  0.5578           0.1108  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sshp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler 스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.55908\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.33434343434343433\n",
      "검증 데이터 평균절대오차: 0.37575757575757585\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2535353535353535\n",
      "검증 데이터 평균절대오차: 0.27151515151515154\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6319348268839104\n",
      "검증 데이터 결정계수: 0.5835492957746478\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0484 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53933\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3846911927147496\n",
      "검증 데이터 평균절대오차: 0.3769073246868922\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2829582832979259\n",
      "검증 데이터 평균절대오차: 0.26105304267869767\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.5995961077787297\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.53105\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3951690128953438\n",
      "검증 데이터 평균절대오차: 0.3898014147468761\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2866489471109991\n",
      "검증 데이터 평균절대오차: 0.2641128735371734\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5838627912408959\n",
      "검증 데이터 결정계수: 0.5949029305887579\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.011 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): -0.05728\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.6888327721661056\n",
      "검증 데이터 평균절대오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.58004\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35661447707120675\n",
      "검증 데이터 평균절대오차: 0.4038299000284551\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2350939801399895\n",
      "검증 데이터 평균절대오차: 0.28421324639406254\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6587067432916813\n",
      "검증 데이터 결정계수: 0.5640729220800926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0946 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.56633\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37317222980771053\n",
      "검증 데이터 평균절대오차: 0.3945457452511291\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2532750728231032\n",
      "검증 데이터 평균절대오차: 0.2697540963051377\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6323126845044645\n",
      "검증 데이터 결정계수: 0.5862504072164859\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0461 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.53103\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3503404210050292\n",
      "검증 데이터 평균절대오차: 0.4030603739138646\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.228722902270128\n",
      "검증 데이터 평균절대오차: 0.2878079584676237\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.667955835563855\n",
      "검증 데이터 결정계수: 0.558559342575715\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1094 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 100}\n",
      "최적의 성능(결정계수): 0.55009\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3737995491989893\n",
      "검증 데이터 평균절대오차: 0.3952886073005379\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26873327822359155\n",
      "검증 데이터 평균절대오차: 0.30160098968458954\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6098715260330427\n",
      "검증 데이터 결정계수: 0.5374035524415238\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0725 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.51680\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492047323120965\n",
      "검증 데이터 평균절대오차: 0.40467550537802954\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22824504176723612\n",
      "검증 데이터 평균절대오차: 0.2882790979655903\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686496138572693\n",
      "검증 데이터 결정계수: 0.5578367114067078\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_mmhp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_mmhp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_mm, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_mmhp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_mm)\n",
    "    test_pred = best_model.predict(X_test_mm)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_mmhp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_mmhp = pd.DataFrame(df_mmhp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.3898</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>-0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.0461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3343     0.2535    0.6319   0.3758   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3952     0.2866    0.5839   0.3898   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3566     0.2351    0.6587   0.4038   \n",
       "5            ExtraTreesRegressor     0.3732     0.2533    0.6323   0.3945   \n",
       "6      GradientBoostingRegressor     0.3503     0.2287    0.6680   0.4031   \n",
       "7  HistGradientBoostingRegressor     0.3738     0.2687    0.6099   0.3953   \n",
       "8                   XGBRegressor     0.3492     0.2282    0.6686   0.4047   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2715  0.5835           0.0484  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2641  0.5949          -0.0110  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2842  0.5641           0.0946  \n",
       "5   0.2698  0.5863           0.0461  \n",
       "6   0.2878  0.5586           0.1094  \n",
       "7   0.3016  0.5374           0.0725  \n",
       "8   0.2883  0.5578           0.1108  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmhp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler 스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.55908\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.33434343434343433\n",
      "검증 데이터 평균절대오차: 0.37575757575757585\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2535353535353535\n",
      "검증 데이터 평균절대오차: 0.27151515151515154\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6319348268839104\n",
      "검증 데이터 결정계수: 0.5835492957746478\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0484 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53933\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3846911927147496\n",
      "검증 데이터 평균절대오차: 0.3769073246868922\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2829582832979259\n",
      "검증 데이터 평균절대오차: 0.26105304267869767\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.589220642902726\n",
      "검증 데이터 결정계수: 0.5995961077787297\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.53927\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3854307186564242\n",
      "검증 데이터 평균절대오차: 0.37780977162685264\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2829771684248765\n",
      "검증 데이터 평균절대오차: 0.26102665427295024\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5891932267754543\n",
      "검증 데이터 결정계수: 0.5996365823897987\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0104 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): -0.05728\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.6888327721661056\n",
      "검증 데이터 평균절대오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.58004\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35661447707120675\n",
      "검증 데이터 평균절대오차: 0.4038299000284551\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2350939801399895\n",
      "검증 데이터 평균절대오차: 0.28421324639406254\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6587067432916813\n",
      "검증 데이터 결정계수: 0.5640729220800926\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0946 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.56633\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.37317222980771053\n",
      "검증 데이터 평균절대오차: 0.3945457452511291\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2532750728231032\n",
      "검증 데이터 평균절대오차: 0.2697540963051377\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6323126845044645\n",
      "검증 데이터 결정계수: 0.5862504072164859\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0461 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.53103\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3503404210050292\n",
      "검증 데이터 평균절대오차: 0.4030603739138646\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.228722902270128\n",
      "검증 데이터 평균절대오차: 0.2878079584676237\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.667955835563855\n",
      "검증 데이터 결정계수: 0.558559342575715\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1094 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 100}\n",
      "최적의 성능(결정계수): 0.55009\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3737995491989893\n",
      "검증 데이터 평균절대오차: 0.3952886073005379\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26873327822359155\n",
      "검증 데이터 평균절대오차: 0.30160098968458954\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6098715260330427\n",
      "검증 데이터 결정계수: 0.5374035524415238\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0725 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.51680\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492047323120965\n",
      "검증 데이터 평균절대오차: 0.40467550537802954\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22824504176723612\n",
      "검증 데이터 평균절대오차: 0.2882790979655903\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686496138572693\n",
      "검증 데이터 결정계수: 0.5578367114067078\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1108 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_rshp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_rshp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_rs, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_rshp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_rs)\n",
    "    test_pred = best_model.predict(X_test_rs)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_rshp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_rshp = pd.DataFrame(df_rshp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>-0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.3945</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.0461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3343     0.2535    0.6319   0.3758   \n",
       "1               LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
       "2                          Ridge     0.3854     0.2830    0.5892   0.3778   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3566     0.2351    0.6587   0.4038   \n",
       "5            ExtraTreesRegressor     0.3732     0.2533    0.6323   0.3945   \n",
       "6      GradientBoostingRegressor     0.3503     0.2287    0.6680   0.4031   \n",
       "7  HistGradientBoostingRegressor     0.3738     0.2687    0.6099   0.3953   \n",
       "8                   XGBRegressor     0.3492     0.2282    0.6686   0.4047   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2715  0.5835           0.0484  \n",
       "1   0.2611  0.5996          -0.0104  \n",
       "2   0.2610  0.5996          -0.0104  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2842  0.5641           0.0946  \n",
       "5   0.2698  0.5863           0.0461  \n",
       "6   0.2878  0.5586           0.1094  \n",
       "7   0.3016  0.5374           0.0725  \n",
       "8   0.2883  0.5578           0.1108  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rshp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학, StandardScaler스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.56681\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3253968253968254\n",
      "검증 데이터 평균절대오차: 0.3658008658008658\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2528344671201814\n",
      "검증 데이터 평균절대오차: 0.27365491651205937\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6329523255330647\n",
      "검증 데이터 결정계수: 0.5802673181948834\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0527 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59784\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3541754028385007\n",
      "검증 데이터 평균절대오차: 0.3619008508380418\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.24632614429751631\n",
      "검증 데이터 평균절대오차: 0.23877682251081095\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221504\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59030\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3650893259581184\n",
      "검증 데이터 평균절대오차: 0.3617152575119077\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.25002146383170004\n",
      "검증 데이터 평균절대오차: 0.23299998702934155\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6370360500626563\n",
      "검증 데이터 결정계수: 0.6426239635564042\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0056 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): -0.05728\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.6888327721661056\n",
      "검증 데이터 평균절대오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57021\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3574800663069911\n",
      "검증 데이터 평균절대오차: 0.39979555677325357\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.23484777449303942\n",
      "검증 데이터 평균절대오차: 0.27981526233901755\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6590641677013473\n",
      "검증 데이터 결정계수: 0.5708185624124082\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0882 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57394\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36361483358926533\n",
      "검증 데이터 평균절대오차: 0.4003305344049141\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2401233229374387\n",
      "검증 데이터 평균절대오차: 0.27905193030858494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6514054896337957\n",
      "검증 데이터 결정계수: 0.5719893632309168\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0794 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.52580\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3505224541810225\n",
      "검증 데이터 평균절대오차: 0.4046541465145009\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22846046961392527\n",
      "검증 데이터 평균절대오차: 0.2870448967837406\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6683368172285011\n",
      "검증 데이터 결정계수: 0.5597297287359244\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1086 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 50}\n",
      "최적의 성능(결정계수): 0.52528\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36993074043252233\n",
      "검증 데이터 평균절대오차: 0.3933663918882634\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26139076549519924\n",
      "검증 데이터 평균절대오차: 0.30122759494496193\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6205308805601263\n",
      "검증 데이터 결정계수: 0.5379762663449807\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0826 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': None, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.51242\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22821969668302822\n",
      "검증 데이터 평균절대오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polysshp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polysshp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_polyscaled, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polysshp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_polyscaled)\n",
    "    test_pred = best_model.predict(X_test_polyscaled)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_polysshp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_polysshp = pd.DataFrame(df_polysshp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.2528</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.5803</td>\n",
       "      <td>0.0527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>-0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3254     0.2528    0.6330   0.3658   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.3651     0.2500    0.6370   0.3617   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3575     0.2348    0.6591   0.3998   \n",
       "5            ExtraTreesRegressor     0.3636     0.2401    0.6514   0.4003   \n",
       "6      GradientBoostingRegressor     0.3505     0.2285    0.6683   0.4047   \n",
       "7  HistGradientBoostingRegressor     0.3699     0.2614    0.6205   0.3934   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2737  0.5803           0.0527  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2330  0.6426          -0.0056  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2798  0.5708           0.0882  \n",
       "5   0.2791  0.5720           0.0794  \n",
       "6   0.2870  0.5597           0.1086  \n",
       "7   0.3012  0.5380           0.0826  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polysshp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학, MinMaxScaler스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.56611\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3303030303030303\n",
      "검증 데이터 평균절대오차: 0.38181818181818183\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2507070707070707\n",
      "검증 데이터 평균절대오차: 0.28606060606060607\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.636040733197556\n",
      "검증 데이터 결정계수: 0.5612394366197182\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0748 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59784\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.354175402838501\n",
      "검증 데이터 평균절대오차: 0.3619008508380422\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.24632614429751631\n",
      "검증 데이터 평균절대오차: 0.23877682251081153\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221495\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.52707\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.4080993314381282\n",
      "검증 데이터 평균절대오차: 0.38918748586434965\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.28770987094107137\n",
      "검증 데이터 평균절대오차: 0.25650932189131054\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5823226150574428\n",
      "검증 데이터 결정계수: 0.6065652795216376\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0242 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): -0.05728\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5937149270482603\n",
      "검증 데이터 평균절대오차: 0.5925925925925926\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.6888327721661056\n",
      "검증 데이터 평균절대오차: 0.6764870931537598\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.0\n",
      "검증 데이터 결정계수: -0.03759780907668264\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0376 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57262\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35723051500472597\n",
      "검증 데이터 평균절대오차: 0.40054217796814173\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.23463285809774842\n",
      "검증 데이터 평균절대오차: 0.2815949837482246\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6593761685293786\n",
      "검증 데이터 결정계수: 0.5680888207016666\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0913 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57394\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36361483358926533\n",
      "검증 데이터 평균절대오차: 0.4003305344049141\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2401233229374387\n",
      "검증 데이터 평균절대오차: 0.27905193030858494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6514054896337957\n",
      "검증 데이터 결정계수: 0.5719893632309168\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0794 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.52735\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3505224541810225\n",
      "검증 데이터 평균절대오차: 0.4046541465145009\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22846046961392527\n",
      "검증 데이터 평균절대오차: 0.2870448967837406\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6683368172285011\n",
      "검증 데이터 결정계수: 0.5597297287359244\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1086 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 50}\n",
      "최적의 성능(결정계수): 0.52528\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36993074043252233\n",
      "검증 데이터 평균절대오차: 0.3933663918882634\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26139076549519924\n",
      "검증 데이터 평균절대오차: 0.30122759494496193\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6205308805601263\n",
      "검증 데이터 결정계수: 0.5379762663449807\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0826 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': None, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.51242\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22821969668302822\n",
      "검증 데이터 평균절대오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polymmhp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polymmhp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_polymm, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polymmhp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_polymm)\n",
    "    test_pred = best_model.predict(X_test_polymm)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_polymmhp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_polymmhp = pd.DataFrame(df_polymmhp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.2861</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.0748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>-0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-0.0376</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.0826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3303     0.2507    0.6360   0.3818   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.4081     0.2877    0.5823   0.3892   \n",
       "3                          Lasso     0.5937     0.6888    0.0000   0.5926   \n",
       "4          RandomForestRegressor     0.3572     0.2346    0.6594   0.4005   \n",
       "5            ExtraTreesRegressor     0.3636     0.2401    0.6514   0.4003   \n",
       "6      GradientBoostingRegressor     0.3505     0.2285    0.6683   0.4047   \n",
       "7  HistGradientBoostingRegressor     0.3699     0.2614    0.6205   0.3934   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2861  0.5612           0.0748  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2565  0.6066          -0.0242  \n",
       "3   0.6765 -0.0376           0.0376  \n",
       "4   0.2816  0.5681           0.0913  \n",
       "5   0.2791  0.5720           0.0794  \n",
       "6   0.2870  0.5597           0.1086  \n",
       "7   0.3012  0.5380           0.0826  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polymmhp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성공학, RobustScaler스케일링 & 하이퍼파라미터 적용 후 훈련 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================KNeighborsRegressor===============\n",
      "최적의 하이퍼파라미터: {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "최적의 성능(결정계수): 0.49261\n",
      "최적의 모델: KNeighborsRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3477633477633478\n",
      "검증 데이터 평균절대오차: 0.354978354978355\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.28777571634714494\n",
      "검증 데이터 평균절대오차: 0.25293753865182433\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.5822270252296438\n",
      "검증 데이터 결정계수: 0.6120436907157228\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0298 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================LinearRegression===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59784\n",
      "최적의 모델: LinearRegression\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35417540283850074\n",
      "검증 데이터 평균절대오차: 0.36190085083804174\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.24632614429751626\n",
      "검증 데이터 평균절대오차: 0.23877682251081103\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6424006605798991\n",
      "검증 데이터 결정계수: 0.6337634370221503\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0086 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Ridge===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': False}\n",
      "최적의 성능(결정계수): 0.59105\n",
      "최적의 모델: Ridge\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36955596332290536\n",
      "검증 데이터 평균절대오차: 0.36296416776937024\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.24985371154150027\n",
      "검증 데이터 평균절대오차: 0.23202006419707405\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.637279581289651\n",
      "검증 데이터 결정계수: 0.6441269719568821\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0068 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================Lasso===============\n",
      "최적의 하이퍼파라미터: {'fit_intercept': True, 'positive': True}\n",
      "최적의 성능(결정계수): 0.13552\n",
      "최적의 모델: Lasso\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.536623561568802\n",
      "검증 데이터 평균절대오차: 0.5427715580802102\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.5488998961315739\n",
      "검증 데이터 평균절대오차: 0.5074617326795202\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.20314491657314515\n",
      "검증 데이터 결정계수: 0.22165376494648215\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value -0.0185 < 0.05 이므로 유의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================RandomForestRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57110\n",
      "최적의 모델: RandomForestRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.35723051500472597\n",
      "검증 데이터 평균절대오차: 0.39979555677325357\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.23463285809774842\n",
      "검증 데이터 평균절대오차: 0.27981526233901755\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6593761685293786\n",
      "검증 데이터 결정계수: 0.5708185624124082\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0886 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================ExtraTreesRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': 3, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.57394\n",
      "최적의 모델: ExtraTreesRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36361483358926533\n",
      "검증 데이터 평균절대오차: 0.4003305344049141\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.2401233229374387\n",
      "검증 데이터 평균절대오차: 0.27905193030858494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6514054896337957\n",
      "검증 데이터 결정계수: 0.5719893632309168\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.0794 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================GradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "최적의 성능(결정계수): 0.52758\n",
      "최적의 모델: GradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3505224541810225\n",
      "검증 데이터 평균절대오차: 0.4046541465145009\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22846046961392527\n",
      "검증 데이터 평균절대오차: 0.2870448967837406\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6683368172285011\n",
      "검증 데이터 결정계수: 0.5597297287359244\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1086 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================HistGradientBoostingRegressor===============\n",
      "최적의 하이퍼파라미터: {'learning_rate': 0.2, 'max_depth': None, 'max_iter': 50}\n",
      "최적의 성능(결정계수): 0.52528\n",
      "최적의 모델: HistGradientBoostingRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.36993074043252233\n",
      "검증 데이터 평균절대오차: 0.39570059245886424\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.26139076549519924\n",
      "검증 데이터 평균절대오차: 0.3074068097969576\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6205308805601263\n",
      "검증 데이터 결정계수: 0.5284985691987508\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.092 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "================XGBRegressor===============\n",
      "최적의 하이퍼파라미터: {'max_depth': None, 'n_estimators': 100}\n",
      "최적의 성능(결정계수): 0.51242\n",
      "최적의 모델: XGBRegressor\n",
      "---------- mean_absolute_error ----------\n",
      "훈련 데이터 평균절대오차: 0.3492859126341463\n",
      "검증 데이터 평균절대오차: 0.4062849391590465\n",
      "---------- mean_squared_error ----------\n",
      "훈련 데이터 평균절대오차: 0.22821969668302822\n",
      "검증 데이터 평균절대오차: 0.28842174854809494\n",
      "--------------- r2_score ---------------\n",
      "훈련 데이터 결정계수: 0.6686863899230957\n",
      "검증 데이터 결정계수: 0.5576179027557373\n",
      "-------------- 유의미 판단 --------------\n",
      "p_value 0.1111 > 0.05 이므로 무의미하다고 판단됨\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 생성\n",
    "df_polyrshp_list = []\n",
    "\n",
    "# 딕셔너리 대표 변수 정의\n",
    "results_polyrshp= {}\n",
    "\n",
    "# KNeighborsRegressor의 하이퍼파라미터 설정\n",
    "gridParams_kn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11, 13],  # 이웃의 개수 (홀수로 설정)\n",
    "    \"weights\": [\"uniform\", \"distance\"],   # 가중치 설정\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],  # 알고리즘 선택\n",
    "    \"leaf_size\": [10, 20, 30]  # BallTree/KDTree에서 사용할 leaf 크기\n",
    "}\n",
    "\n",
    "\n",
    "# LinearRegression, Ridge, Lasso의 하이퍼파라미터 설정\n",
    "gridParams = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "\n",
    "# GradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_gb = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# HistGradientBoostingRegressor의 하이퍼파라미터 설정\n",
    "gridParams_hb = {\n",
    "    \"max_iter\"      : [50, 100],\n",
    "    \"max_depth\"     : [None, 3, 10],\n",
    "    \"learning_rate\" : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# RandomForestRegressor, XGBRegressor, ExtraTree의 하이퍼파라미터 설정\n",
    "gridParams_rfxe = {\n",
    "    \"n_estimators\" : [50, 100],\n",
    "    \"max_depth\"    : [None, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "### GridSearchCV 튜닝 모델에 대한 속성 정의하기\n",
    "scoring = [\"neg_mean_squared_error\", \"r2\"]\n",
    "\n",
    "# 모델 선정 기준 정의하기: 평가방법 중에 선정 기준으로 사용할 평가방법을 선정()\n",
    "refit = \"r2\"\n",
    "\n",
    "### GridSearchCV 튜닝 모델에서 교차검증에 사용할 그룹(Fold)의 갯수 지정\n",
    "cv = 5\n",
    "\n",
    "# CPU Core(코어) 사용 갯수 정의하기\n",
    "n_jobs = -1\n",
    "\n",
    "\n",
    "# 모델 리스트\n",
    "kn_reg = KNeighborsRegressor() \n",
    "lr_reg = LinearRegression()\n",
    "ridge  = Ridge()\n",
    "lasso  = Lasso()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "et_reg = ExtraTreesRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "hb_reg = HistGradientBoostingRegressor(random_state=42)\n",
    "xg_reg = XGBRegressor()\n",
    "\n",
    "models = [\n",
    "    (kn_reg, gridParams_kn),\n",
    "    (lr_reg, gridParams),\n",
    "    (ridge, gridParams), \n",
    "    (lasso, gridParams),\n",
    "    (rf_reg, gridParams_rfxe),\n",
    "    (et_reg, gridParams_rfxe),\n",
    "    (gb_reg, gridParams_gb), \n",
    "    (hb_reg, gridParams_hb),\n",
    "    (xg_reg, gridParams_rfxe),\n",
    "     ]\n",
    "\n",
    "for model, params in models:\n",
    "    ### 튜닝 모델(클래스) 생성하기 (모델 생성과 같음)\n",
    "    grid_search_model = GridSearchCV(\n",
    "        # 튜닝에 사용할 모델 설정\n",
    "        estimator = model,\n",
    "        # 위에서 정의한 하이퍼파라미터터 설정\n",
    "        param_grid = params,\n",
    "        # 모델 평가방법 설정\n",
    "        scoring = scoring,\n",
    "        # 모델 선정 기준 설정\n",
    "        refit = refit,\n",
    "        # 교차검증에 사용할 Fold 갯수 설정\n",
    "        cv = cv,\n",
    "        # CPU Core(코어) 갯수 설정\n",
    "        n_jobs = n_jobs\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### 튜닝 모델 훈련시키기\n",
    "    grid_search_model.fit(X_train_polyrs, y_train)\n",
    "\n",
    "    ### 튜닝 결과 확인하기\n",
    "    ### 최적의 하이퍼파라미터 확인하기\n",
    "    best_params = grid_search_model.best_params_\n",
    "    \n",
    "    ### 최적의 성능(결정계수) 확인하기\n",
    "    best_score = grid_search_model.best_score_\n",
    "    \n",
    "    ### 최적의 모델 확인하기\n",
    "    best_model = grid_search_model.best_estimator_\n",
    "\n",
    "    # 모델명을 키로 하여 results에 저장\n",
    "    results_polyrshp[best_model.__class__.__name__] = best_model\n",
    "\n",
    "    train_pred = best_model.predict(X_train_polyrs)\n",
    "    test_pred = best_model.predict(X_test_polyrs)\n",
    "    \n",
    "    ### 평가 지표 출력\n",
    "    print(f\"================{best_model.__class__.__name__}===============\")\n",
    "\n",
    "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
    "    print(f\"최적의 성능(결정계수): {best_score:.5f}\")\n",
    "    print(f\"최적의 모델: {best_model.__class__.__name__}\")\n",
    "\n",
    "    \n",
    "    ### 평균절대오차(MAE)\n",
    "    print(\"---------- mean_absolute_error ----------\")\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    test_mae   = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mae}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mae}\")\n",
    "    \n",
    "    \n",
    "    ### 평균제곱오차(MSE)\n",
    "    print(\"---------- mean_squared_error ----------\")\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse   = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 평균절대오차: {train_mse}\")\n",
    "    print(f\"검증 데이터 평균절대오차: {test_mse}\")\n",
    "    \n",
    "    ### 결정계수(R2)\n",
    "    print(\"--------------- r2_score ---------------\")\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2   = r2_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"훈련 데이터 결정계수: {train_r2}\")\n",
    "    print(f\"검증 데이터 결정계수: {test_r2}\")\n",
    "    \n",
    "    # 결정계수 차이가 0.05 이하일 경우 유의미하다고 판단\n",
    "    print(\"-------------- 유의미 판단 --------------\")\n",
    "    if train_r2 - test_r2 < 0.05:\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} < 0.05 이므로 유의미하다고 판단됨\")\n",
    "    \n",
    "    else :\n",
    "        print(f\"p_value {round(train_r2 - test_r2, 4)} > 0.05 이므로 무의미하다고 판단됨\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "    df_polyrshp_list.append({\n",
    "        \"best_model_nm\"  : best_model.__class__.__name__,\n",
    "        \"train_mae\"      : (round(train_mae, 4)),\n",
    "        \"train_mse\"      : (round(train_mse, 4)),\n",
    "        \"train_r2\"       : (round(train_r2, 4)),\n",
    "        \"val_mae\"        : (round(test_mae, 4)),\n",
    "        \"val_mse\"        : (round(test_mse, 4)),\n",
    "        \"val_r2\"         : (round(test_r2, 4)),\n",
    "        \"train_r2-val_r2\": (round(train_r2 - test_r2, 4))\n",
    "    })\n",
    "\n",
    "### 데이터프레임에 저장하기\n",
    "df_polyrshp = pd.DataFrame(df_polyrshp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_nm</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>train_r2-val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>-0.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.2499</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>-0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>-0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
       "0            KNeighborsRegressor     0.3478     0.2878    0.5822   0.3550   \n",
       "1               LinearRegression     0.3542     0.2463    0.6424   0.3619   \n",
       "2                          Ridge     0.3696     0.2499    0.6373   0.3630   \n",
       "3                          Lasso     0.5366     0.5489    0.2031   0.5428   \n",
       "4          RandomForestRegressor     0.3572     0.2346    0.6594   0.3998   \n",
       "5            ExtraTreesRegressor     0.3636     0.2401    0.6514   0.4003   \n",
       "6      GradientBoostingRegressor     0.3505     0.2285    0.6683   0.4047   \n",
       "7  HistGradientBoostingRegressor     0.3699     0.2614    0.6205   0.3957   \n",
       "8                   XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
       "\n",
       "   val_mse  val_r2  train_r2-val_r2  \n",
       "0   0.2529  0.6120          -0.0298  \n",
       "1   0.2388  0.6338           0.0086  \n",
       "2   0.2320  0.6441          -0.0068  \n",
       "3   0.5075  0.2217          -0.0185  \n",
       "4   0.2798  0.5708           0.0886  \n",
       "5   0.2791  0.5720           0.0794  \n",
       "6   0.2870  0.5597           0.1086  \n",
       "7   0.3074  0.5285           0.0920  \n",
       "8   0.2884  0.5576           0.1111  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polyrshp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    best_model_nm  train_mae  train_mse  train_r2  val_mae  \\\n",
      "0             KNeighborsRegressor     0.3293     0.2582    0.6252   0.3636   \n",
      "1                LinearRegression     0.3847     0.2830    0.5892   0.3769   \n",
      "2                           Ridge     0.3854     0.2830    0.5892   0.3778   \n",
      "3                           Lasso     0.5937     0.6888    0.0000   0.5926   \n",
      "4           RandomForestRegressor     0.3468     0.2284    0.6684   0.4046   \n",
      "..                            ...        ...        ...       ...      ...   \n",
      "4           RandomForestRegressor     0.3572     0.2346    0.6594   0.3998   \n",
      "5             ExtraTreesRegressor     0.3636     0.2401    0.6514   0.4003   \n",
      "6       GradientBoostingRegressor     0.3505     0.2285    0.6683   0.4047   \n",
      "7   HistGradientBoostingRegressor     0.3699     0.2614    0.6205   0.3957   \n",
      "8                    XGBRegressor     0.3493     0.2282    0.6687   0.4063   \n",
      "\n",
      "    val_mse  val_r2  train_r2-val_r2  \n",
      "0    0.2667  0.5910           0.0342  \n",
      "1    0.2611  0.5996          -0.0104  \n",
      "2    0.2610  0.5996          -0.0104  \n",
      "3    0.6765 -0.0376           0.0376  \n",
      "4    0.2886  0.5573           0.1111  \n",
      "..      ...     ...              ...  \n",
      "4    0.2798  0.5708           0.0886  \n",
      "5    0.2791  0.5720           0.0794  \n",
      "6    0.2870  0.5597           0.1086  \n",
      "7    0.3074  0.5285           0.0920  \n",
      "8    0.2884  0.5576           0.1111  \n",
      "\n",
      "[144 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([df_org, df_poly, df_ss, df_mm, df_rs, df_hp,\n",
    "                    df_polyss, df_polymm, df_polyrs, df_polyhp, \n",
    "                    df_sshp, df_mmhp, df_rshp, df_polysshp, df_polymmhp, df_polyrshp], axis=0)\n",
    "\n",
    "print(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 파일이 ./data/만족도_총합본.xlsx 경로에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "output_file = './data/만족도_총합본.xlsx'\n",
    "\n",
    "df_all.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"엑셀 파일이 {output_file} 경로에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(모델 선정을 위한 해석)\n",
    "<모델 선정 기준>\n",
    " 1. 객관적 선정 기준(평가 결과값으로 구분이 가능한 경우)\n",
    "   - 과소적합, 즉 훈련-검증이 마이너스(-)인 경우 무조건 제외\n",
    "   - 과대적합, 훈련이 검증보다 0.1 이상 차이 나는 경우 -> 제외 보다는 튜닝 대상\n",
    "              훈련이 1인 경우 -> 무조건 제외              \n",
    "   - 비교할 모델들의 훈련정확도 및 과적합여부의 차이가 급격하게 차이가 나는 경우\n",
    "      --> 훈련정확도의 차이가 많고, 과적합여부는 차이가 없는 경우 : 훈련정확도 기준으로 선정\n",
    "      --> 훈련정확도의 차이가 없고, 과적합여부는 차이가 많은 경우 : 과적합여부 기준으로 선정\n",
    "   \n",
    " 2. 주관적 선정 기준(분석가의 객관적이면서도 주관적인 판단 기준을 의미함)\n",
    "   - 여러 모델 중에 1번에 대한 객관적 선정 기준을 통과한 모델들 중에서 최종 모델을 선정하게됨\n",
    "   - 비교할 모델들의 훈련정확도 및 과적합여부의 차이가 거의 없는 경우\n",
    "      --> 오차값(MAE or MSE)의 차이가 많이 나는 경우 : 오차값 기준으로 선정\n",
    "      --> 오차값의 차이가 많지 않은 경우(분석가 주관에 따름)\n",
    "            : 훈련정확도를 중시할 경우 훈련정확도가 높은 기준으로 선정\n",
    "            : 일반화를 중시할 경우 과적합의 차이가 낮은 기준으로 선정\n",
    "            \n",
    "(최종 모델 선정)\n",
    " - 최종 모델: Ridge (특성공학, RobustScaler, 하이퍼파라미터 튜닝 적용)\n",
    " - val_r2 = 0.624로 검증 데이터에 대한 비율이 다른 모델들의 비하여 우수.\n",
    " - 과적합 여부: train_r2 - val_r2 = 0.02로 과적합이 매우 낮아 일반화 성능이 우수.\n",
    " - 예측 오차: val_mae = 0.3701, val_mse = 0.2452로 오차가 낮아 예측 성능이 안정적.\n",
    " - 추가 고려: val_r2 = 0.641인 Ridge (하이퍼파라미터 미적용)는 오차와 검증데이터가 더 우수하지만, \n",
    "   하이퍼파라미터 튜닝을 포함한 버전이 모델 최적화 관점에서 더 적합하다고 판단.\n",
    " - 비교 우위:\n",
    "  - ExtraTreesRegressor와 KNeighborsRegressor는 val_r2가 0.5863~0.591로 Ridge보다 낮고, 과적합 정도도 약간 더 큼.\n",
    "  - 다른 Ridge 모델(val_r2 = 0.641)은 하이퍼파라미터 튜닝 없이도 다른 모델에 비하여 우수, \n",
    "    튜닝 적용 모델이 안정성과 실용성을 더 보장.\n",
    "\n",
    "(결론)\n",
    "최종 선정 모델: Ridge (특성공학, RobustScaler, 하이퍼파라미터 튜닝 적용)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mae: 0.363, test_mse: 0.232, test_r2: 0.6441\n"
     ]
    }
   ],
   "source": [
    "final_model = results_polyrshp[\"Ridge\"]\n",
    "\n",
    "# 최종 테스트 데이터로 예측 및 평가 진행\n",
    "test_pred = final_model.predict(X_test_polyrs)\n",
    "\n",
    "# 예측 결과로 평가하기\n",
    "test_mae = round(mean_absolute_error(y_test, test_pred), 4)\n",
    "test_mse = round(mean_squared_error(y_test, test_pred), 4)\n",
    "test_r2  = round(r2_score(y_test, test_pred), 4)\n",
    "\n",
    "print(f\"test_mae: {test_mae}, test_mse: {test_mse}, test_r2: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./final_model/ridge_model.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "save_path = \"./final_model/ridge_model.pkl\"\n",
    "joblib.dump(final_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "file_path =\"./final_model/ridge_model.pkl\"\n",
    "load_ridge_model = joblib.load(file_path)\n",
    "load_ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 만족도: 2.9255 점\n"
     ]
    }
   ],
   "source": [
    "best_ridge_model = load_ridge_model\n",
    "\n",
    "new_data = {\n",
    "    \"친밀도\": [4],\n",
    "    \"적절성\": [2]\n",
    "}\n",
    "\n",
    "new_data_df = pd.DataFrame(new_data)\n",
    "\n",
    "\n",
    "new_data_poly = poly.transform(new_data_df)\n",
    "new_data_scaled = rs.transform(new_data_poly)\n",
    "\n",
    "predicted_satisfaction = best_ridge_model.predict(new_data_scaled)\n",
    "predicted_satisfaction_answer = predicted_satisfaction[0]\n",
    "\n",
    "print(f\"예측된 만족도: {predicted_satisfaction_answer:.4f} 점\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_202503_kernel",
   "language": "python",
   "name": "pk_dl_202503"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
